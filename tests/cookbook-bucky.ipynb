{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook for running BUCKy in parallel in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the *Pedicularis* example data set from the first empirical ipyrad tutorial. Here I show how to run BUCKy on a large set of loci parsed from the output file with the `.loci` ending. All code in this notebook is Python. You can simply follow along and execute this same code in a Jupyter notebook of your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software requirements for this notebook\n",
    "\n",
    "    + BUCKy\n",
    "    + mbsum (distributed with BUCKy)\n",
    "    + mrBayes\n",
    "    + ipyrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import some Python libraries\n",
    "import ipyparallel as ipp\n",
    "import ipyrad as ip\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster setup\n",
    "To execute code in parallel we will use the `ipyparallel` Python library. A quick guide to using starting a parallel cluster locally can be found [here](link), and instructions for setting up a remote cluster on a HPC is available [here](http://ipyrad.readthedocs.io/HPC_Tunnel.html). In either case, this notebook assumes you are running an `ipcluster` that this notebook can find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 engines found\n"
     ]
    }
   ],
   "source": [
    "## look for running ipcluster instance\n",
    "ipyclient = ipp.Client()\n",
    "print \"{} engines found\".format(len(ipyclient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up some tests\n",
    "List the names of the samples you wish to include in your analysis in the dictionary. You can map them to simpler names if you wish. BUCKy generally doesn't starts to perform less well when the number of tips is >10 or so, so you might want to try analyses with different numbers of tips. In this case I make one fully sampled tree and one that has just one representative from each clade/species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loading Assembly: pedic\n",
      "  from saved path: ~/pedicularis-test/pedicularis/pedic.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'29154_superba': '29154_superba',\n",
       " '30556_thamno': '30556_thamno',\n",
       " '30686_cyathophylla': '30686_cyathophylla',\n",
       " '32082_przewalskii': '32082_przewalskii',\n",
       " '33413_thamno': '33413_thamno',\n",
       " '33588_przewalskii': '33588_przewalskii',\n",
       " '35236_rex': '35236_rex',\n",
       " '35855_rex': '35855_rex',\n",
       " '38362_rex': '38362_rex',\n",
       " '39618_rex': '39618_rex',\n",
       " '40578_rex': '40578_rex',\n",
       " '41478_cyathophylloides': '41478_cyathophylloides',\n",
       " '41954_cyathophylloides': '41954_cyathophylloides'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I load in the ipyrad object here, although this isn't required, \n",
    "## it has the sample's names easy to access. We then store the names\n",
    "## in a dictionary as keys and matching values.\n",
    "data = ip.load_json(\"/ysm-gpfs/home/de243/pedicularis-test/pedicularis/pedic.json\")\n",
    "fullsamples = {sample.name: sample.name for sample in data.samples.values()}\n",
    "\n",
    "## alternatively, you can just enter all the names by hand, \n",
    "## here a subset of samples is mapped to simpler names in a dictionary\n",
    "subsamples = {\"superba\": \"29154_superba\", \n",
    "              \"cyathophylla\": \"30686_cyathophylla\", \n",
    "              \"cyathophylloides\": \"41478_cyathophylloides\", \n",
    "              \"thamno_cupul\": \"33413_thamno\", \n",
    "              \"thamno_thamno\": \"30556_thamno\",\n",
    "              \"rex_rockii\": \"35236_rex\",\n",
    "              \"rex_rex\": \"40578_rex\", \n",
    "              \"rex_lipskyana\": \"38362_rex\", \n",
    "              \"przewalskii\": \"33588_przewalskii\"}\n",
    "        \n",
    "## print the fullsamples dict \n",
    "fullsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an output directory for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we group them into a dir called analysis_bucky\n",
    "DIR1 = \"analysis_bucky/test1\"   \n",
    "DIR2 = \"analysis_bucky/test2\"\n",
    "\n",
    "## make the directories if they doesn't exist\n",
    "for dirs in [DIR1, DIR2]:\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to write NEXUS blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEXBLOCK = \"\"\"\\\n",
    "#NEXUS\n",
    "begin data;\n",
    "dimensions ntax={} nchar={};\n",
    "format datatype=dna interleave=yes gap=- missing=N;\n",
    "matrix\n",
    "{}\n",
    "    ;\n",
    "\n",
    "begin mrbayes;\n",
    "set autoclose=yes nowarn=yes;\n",
    "lset nst=6 rates=gamma;\n",
    "mcmc ngen=2000000 samplefreq=2000 printfreq=20000000;\n",
    "sump burnin=1000000;\n",
    "sumt burnin=1000000;\n",
    "end;\n",
    "\"\"\"\n",
    "\n",
    "def nexmake(mdict, nlocus, dirs):\n",
    "    \"\"\" \n",
    "    function that takes a dictionary mapping names to \n",
    "    sequences, and a locus number, and writes it as a NEXUS\n",
    "    file with a mrbayes analysis block.\n",
    "    \"\"\"\n",
    "    ## create matrix as a string\n",
    "    matrix = \"\"\n",
    "    for i in mdict.items():\n",
    "        matrix += \"{:<10} {}\\n\".format(i[0][:10], i[1])\n",
    "    \n",
    "    ## write nexus block\n",
    "    handle = os.path.join(dirs, \"{}.nex\".format(nlocus))\n",
    "    with open(handle, 'w') as outnex:\n",
    "        outnex.write(NEXBLOCK.format(len(mdict), \n",
    "                                     len(mdict.values()[0]),\n",
    "                                     matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a dictionary mapping ambiguous characters\n",
    "AMBIGS = {\"R\": (\"G\", \"A\"),\n",
    "          \"K\": (\"G\", \"T\"),\n",
    "          \"S\": (\"G\", \"C\"),\n",
    "          \"Y\": (\"T\", \"C\"),\n",
    "          \"W\": (\"T\", \"A\"),\n",
    "          \"M\": (\"C\", \"A\"), \n",
    "          \"A\": (\"A\", \"A\"), \n",
    "          \"T\": (\"T\", \"T\"), \n",
    "          \"G\": (\"G\", \"G\"), \n",
    "          \"C\": (\"C\", \"C\"), \n",
    "          \"-\": (\"-\", \"-\"), \n",
    "          \"N\": (\"N\", \"N\")}\n",
    "            \n",
    "\n",
    "def resolveambig(subseq):\n",
    "    \"\"\" Randomly resolves iupac hetero codes. This is a shortcut\n",
    "    for now, we could instead use the phased alleles in RAD loci.\"\"\"\n",
    "    N = []\n",
    "    for col in subseq:\n",
    "        rand = np.random.binomial(1, 0.5)\n",
    "        N.append([AMBIGS[i][rand] for i in col])\n",
    "    return np.array(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newPIS(seqsamp, N):\n",
    "    \"\"\" filters for loci with >= N PIS \"\"\"\n",
    "    counts = [Counter(col) for col in seqsamp.T if not (\"-\" in col or \"N\" in col)]\n",
    "    pis = [i.most_common(2)[1][1] > 1 for i in counts if len(i.most_common(2))>1]\n",
    "    if sum(pis) >= N:\n",
    "        return sum(pis)\n",
    "    else:\n",
    "        return 0      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_loci_to_nexus(loci, hdict, dirs, minPIS=2):\n",
    "    \"\"\" \n",
    "    This parses the .loci file format produced by ipyrad to \n",
    "    keep only loci that have data for all taxa listed in \n",
    "    the dictionary (hdict), and which have at least minPIS\n",
    "    parsimony informative SNPs. \n",
    "    \"\"\"\n",
    "    ## keep track of how many loci pass\n",
    "    nlocus = 0\n",
    "    \n",
    "    ## create subsampled data set\n",
    "    for loc in loci:\n",
    "        dat = loc.split(\"\\n\")[:-1]\n",
    "\n",
    "        ## get names and seq from locus\n",
    "        names = [i.split()[0] for i in dat]\n",
    "        seqs = np.array([list(i.split()[1]) for i in dat])\n",
    "\n",
    "        ## check that locus has required samples for each subtree\n",
    "        if all([i in names for i in hdict.values()]):\n",
    "            seqsamp = seqs[[names.index(tax) for tax in hdict.values()]]\n",
    "            seqsamp = resolveambig(seqsamp)\n",
    "            pis = newPIS(seqsamp, minPIS)\n",
    "            if pis:\n",
    "                nlocus += 1\n",
    "                ## remove invariable columns given this subsampling\n",
    "                seqsamp[seqsamp == \"-\"] = \"N\"\n",
    "                rmcol = np.all(seqsamp == \"N\", axis=0)\n",
    "                seqsamp = seqsamp[:, ~rmcol]\n",
    "\n",
    "                ## write to a nexus file\n",
    "                mdict = dict(zip(hdict.keys(), [i.tostring() for i in seqsamp]))\n",
    "                nexmake(mdict, nlocus, dirs)\n",
    "    print nlocus, 'loci kept'            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the loci for each test\n",
    "You can either find the `.loci` file path and enter it here, or load you Assembly object with ipyrad and access the loci file from the object attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29154_superba              TCTGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTTTCGATCTCAGGCGGTCTTACTCA\n",
      "30556_thamno               TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTTACTCA\n",
      "30686_cyathophylla         TCCAGTCCCGCGGGTGATCAAGGCCCCACCACCGCATCTCACATTCTCGATCTCAGGCGGTCTTACTCA\n",
      "33413_thamno               TCCGGTCCTTCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTTACTCA\n",
      "35236_rex                  TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTMGATCTCAGGCGGTCTTACTCA\n",
      "35855_rex                  TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTTACTCA\n",
      "38362_rex                  TCCGGTCCTTCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTTACTCA\n",
      "40578_rex                  TCCGGTCCYKCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTCGATCTCAGGCGGTCTTACTCA\n",
      "41478_cyathophylloides     TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTATCGATCTCAGGCGGTCTTACTCA\n",
      "41954_cyathophylloides     TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTATCGATCTCAGGCGGTCTTACTCA\n",
      "//                           --    **                         -         * *                     |0\n",
      "\n",
      "29154_superba              AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "30556_thamno               AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "30686_cyathophylla         AATGTTATATGTTGTTCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "32082_przewalskii          AATGTTATATGTTGTCCTTGATCAATTTTAGGGCCACATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "33588_przewalskii          AATGTTATATGTTGTCCTTGATCAATTTTAGGGCCACATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "35236_rex                  AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "35855_rex                  AATGTTATATTATATCCTTGATCAATTTTAGAGTCATATTTGGAGCCCTTGCATTCTTGATGTTGCATC\n",
      "38362_rex                  AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "40578_rex                  AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGTAGCCTTTGCATTCTTGTTGTTGCATC\n",
      "41478_cyathophylloides     AATGTTATATGTTGTCCTTGATCAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "41954_cyathophylloides     AATGTTATATGTTGTCCTTGATNAATTTTAGAGTCATATTTGGAGCCTTTGCATTCTTGATGTTGCATC\n",
      "//                                   -- - -               * *  *     -    -           -         |87792|\n"
     ]
    }
   ],
   "source": [
    "## get loci file from it's path or from ipyrad object\n",
    "locifile = data.outfiles.loci\n",
    "#locifile = \"/home/deren/Documents/ipyrad/tests/pedicularis/pedic_outfiles/pedic.loci\"\n",
    "\n",
    "## parse the file into a list of individual loci\n",
    "loci = open(locifile).read().strip().split(\"|\\n\")\n",
    "\n",
    "## print the first and last locus\n",
    "print \"{}\\n\\n{}\".format(loci[0], loci[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample loci and write NEXUS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 loci kept\n",
      "1833 loci kept\n"
     ]
    }
   ],
   "source": [
    "## write nexus file to the analysis directories\n",
    "sample_loci_to_nexus(loci, subsamples, DIR1)\n",
    "sample_loci_to_nexus(loci, fullsamples, DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run mrbayes on loci in parallel\n",
    "We now want to get a posterior distribution of gene trees from each RAD locus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ipp.require(subprocess)\n",
    "def mrbayes(infile):\n",
    "    proc = subprocess.Popen(['mb', infile])\n",
    "    proc.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a load balanced view to distribute jobs\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "\n",
    "## get all the nexus files \n",
    "nex1 = glob.glob(os.path.join(DIR1, \"*.nex\"))\n",
    "nex2 = glob.glob(os.path.join(DIR2, \"*.nex\"))\n",
    "\n",
    "## send jobs to the engines\n",
    "for nexfile in nex1:#+nex2:\n",
    "    lbview.apply(mrbayes, nexfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of the mrbayes runs\n",
    "These can take quite a while when there are thousands of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/847 tasks finished after  507 s"
     ]
    }
   ],
   "source": [
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the mrbayes posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbsum(dirs):\n",
    "    \"\"\" function to write mbsum cmds \"\"\"\n",
    "    trees1 = glob.glob(os.path.join(dirs, \"*.run1.t\"))\n",
    "    trees2 = glob.glob(os.path.join(dirs, \"*.run2.t\"))\n",
    "    for tidx in xrange(len(trees1)):\n",
    "        cmd = [\"mbsum\", \"-n\", \"0\", \n",
    "               \"-o\", os.path.join(dirs, str(tidx))+\".in\", \n",
    "               trees1[tidx], \n",
    "               trees2[tidx]]\n",
    "        proc = subprocess.check_call(cmd)\n",
    "        proc.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## run mbsum on each directory of tree files\n",
    "mbsum(DIR1)\n",
    "mbsum(DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run BUCKy to infer concordance factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bucky(outname, indir, alpha, nchains, nreps, niter):\n",
    "    cmd = [\"bucky\", \"-a\", alpha,\n",
    "                    \"-c\", nchains,\n",
    "                    \"-k\", nreps\n",
    "                    \"-n\", niter, \n",
    "                    \"-o\", outname, \n",
    "                    os.path.join(indir, \"*.in\")]\n",
    "    proc = subprocess.check_call(cmd)\n",
    "    proc.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## submit jobs to run at several values of alpha\n",
    "for indir in [DIR1, DIR2]:\n",
    "    for alpha in [0.1, 1, 10]:\n",
    "        lbview.apply(bucky, *(alpha, 4, 4, 4000000, os.path.join(DIR1, \"BUCKY_{}\".format(alpha)), DIR1)\n",
    "        lbview.apply(bucky, *(alpha, 4, 4, 4000000, os.path.join(DIR2, \"BUCKY_{}\".format(alpha)), DIR2)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat analysis_bucky/test1/BUCKY_1.concordance.tre"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
