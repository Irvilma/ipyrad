{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook for running BUCKy in parallel in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the *Pedicularis* example data set from the first empirical ipyrad tutorial. Here I show how to run BUCKy on a large set of loci parsed from the output file with the `.loci` ending. All code in this notebook is Python. You can simply follow along and execute this same code in a Jupyter notebook of your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "# Modification to this notebook are in progress...\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software requirements for this notebook\n",
    "All required software can be installed through conda by running the commented out code below in a terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## conda install -c BioBuilds mrbayes\n",
    "## conda install -c ipyrad ipyrad\n",
    "## conda install -c ipyrad bucky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import Python libraries\n",
    "import ipyrad.analysis as ipa\n",
    "import ipyparallel as ipp\n",
    "#import subprocess as sps\n",
    "import ipyrad as ip\n",
    "#import glob\n",
    "#import os\n",
    "#import ipyrad.file_conversion as ifc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster setup\n",
    "To execute code in parallel we will use the `ipyparallel` Python library. A quick guide to starting a parallel cluster locally can be found [here](link), and instructions for setting up a remote cluster on a HPC cluster is available [here](http://ipyrad.readthedocs.io/HPC_Tunnel.html). In either case, this notebook assumes you have started an `ipcluster` instance that this notebook can find, which the cell below will test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 engines found\n"
     ]
    }
   ],
   "source": [
    "## look for running ipcluster instance, and create load-balancer\n",
    "ipyclient = ipp.Client()\n",
    "print \"{} engines found\".format(len(ipyclient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bucky analysis object\n",
    "The two required arguments are the `name` and `data` arguments. The `data` argument should be a .loci file or a .alleles.loci file. The name will be used to name output files, which will be written to `{workdir}/{name}/{number}.nexus`. Bucky doesn't deal well with missing data, so loci will only be included if they contain data for all samples in the analysis. It also doesn't work very well with more than about 10-12 samples. By default, all samples found in the loci file will be used, unless you enter a list of names (the `samples` argument) to subsample taxa. It is best to select one individual per species or subspecies. You can set a number of additional parameters in the `.params` dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make a list of sample names you wish to include in your BUCKy analysis \n",
    "samples = [\n",
    "    \"29154_superba\", \n",
    "    \"30686_cyathophylla\", \n",
    "    \"41478_cyathophylloides\", \n",
    "    \"33413_thamno\", \n",
    "    \"30556_thamno\",\n",
    "    \"35236_rex\",\n",
    "    \"40578_rex\", \n",
    "    \"38362_rex\", \n",
    "    \"33588_przewalskii\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'bucky'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-41f2dd4cd39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## initiate a bucky object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m b = ipa.bucky(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"analysis-ipyrad/pedic_outfiles/pedic.alleles.loci\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworkdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"analysis-bucky\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'bucky'"
     ]
    }
   ],
   "source": [
    "## initiate a bucky object\n",
    "b = ipa.bucky(\n",
    "    name=\"test\",\n",
    "    data=\"analysis-ipyrad/pedic_outfiles/pedic.alleles.loci\",\n",
    "    workdir=\"analysis-bucky\",\n",
    "    samples=samples,\n",
    "    minSNPs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## print the params dictionary\n",
    "b.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infile is: /home/deren/Documents/ipyrad/tests/branch-test/base_outfiles/base.loci\n",
      "outdir is: /home/deren/Documents/ipyrad/tests/analysis-bucky\n"
     ]
    }
   ],
   "source": [
    "## This will write nexus files to {workdir}/{name}/[number].nex\n",
    "b.write_multinexus_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example nexus file\n",
    "Nexus files are written to a new directory called `bucky-{name}`, where name is the name entered into the `loci2multinex()` function. If you entered a `outdir` argument as well then this new directory will be made as a subdirectory inside that outdir. Above we used name=\"example\" and outdir=WORKDIR, which created files in the directory shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NEXUS\n",
      "begin data;\n",
      "dimensions ntax=9 nchar=66;\n",
      "format datatype=dna interleave=yes gap=- missing=N;\n",
      "matrix\n",
      "30686_cyathophylla      CTTGGCAGGTGGCAGTTCGTTGCTGTTATATGCTGTAAGAAAAT-AAAAAAAAATCACCTGTTTAG\n",
      "33413_thamno            CTTGGCAGGTGGCAGTTTGTTGCTGTTTTATGCTGTAAGAAAAT--AAAAAAAACCACCTGTTTAG\n",
      "30556_thamno            CTTNGCAGGTGGCAGTTTGTTGCTGTTTTATGCTGTAAGAAAAT-NAAAAAAAATCACCTGTTTAG\n",
      "33588_przewalskii       CTTGGCAGGTGGCAGTTCGTTGCTGAAATATGCTGTAAGAAAAT-AAAGAAAAATCATTT-TTTGG\n",
      "29154_superba           CTTGGCAGTTGGCATTTCGTTGCTGTTATATGCTGTAAGAAAAT-AAAAAAAAATCACCTGTTTAA\n",
      "40578_rex               CTTGGCAGGTGGCAGTTTGTTGCTGTTTTATGCTGTAAGAAAAT--AAAAAAAATCACCTGTTTAG\n",
      "41478_cyathophylloides  CTTGGCAGGTGGCAGTTCGTTGCTGTTATATGCTGTAAGAAAATAAAAAAAAAATCACCTGTTTAG\n",
      "38362_rex               CTTGGCAGGTGGCAGTTTGTTGCTGTTTTATGCTGTAAGAAAATAAAAAAAAAATCACCTGTTTAG\n",
      "35236_rex               CTTGGCAGGTGGCAGTTTGTTGCTGTTTTATGCTGTAAGAAAAT--AAAAAAAATCACCTGTTTAG\n",
      "\n",
      "    ;\n",
      "\n",
      "begin mrbayes;\n",
      "set autoclose=yes nowarn=yes;\n",
      "lset nst=6 rates=gamma;\n",
      "mcmc ngen=2000000 samplefreq=1000 printfreq=2000000;\n",
      "sump burnin=1000000;\n",
      "sumt burnin=1000000;\n",
      "end;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print an example nexus file\n",
    "! cat analysis-bucky/test/1.nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get all nexus files for this data set\n",
    "nexfiles = glob.glob(os.path.join(RUNDIR, \"*.nex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Python function to call `mrbayes`, `mbsum` and `bucky`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrbayes(infile):\n",
    "    ## double check file path\n",
    "    infile = os.path.realpath(infile)\n",
    "    if not os.path.exists(infile):\n",
    "        raise Exception(\"infile not found; try using a fullpath\")\n",
    "        \n",
    "    ## call mrbayes\n",
    "    cmd = ['mb', infile]\n",
    "    proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE)\n",
    "    stdout = proc.communicate()\n",
    "    \n",
    "    ## check for errors\n",
    "    if proc.returncode:\n",
    "        return stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbsum(dirs):\n",
    "    trees1 = glob.glob(os.path.join(dirs, \"*.run1.t\"))\n",
    "    trees2 = glob.glob(os.path.join(dirs, \"*.run2.t\"))\n",
    "    tidx = 0\n",
    "    for tidx in xrange(len(trees1)):\n",
    "        cmd = [\"mbsum\", \n",
    "               \"-n\", \"0\", \n",
    "               \"-o\", os.path.join(dirs, str(tidx))+\".in\", \n",
    "               trees1[tidx], \n",
    "               trees2[tidx]]\n",
    "        proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE)\n",
    "        proc.communicate()\n",
    "    print \"summed {} trees in: {}\".format(tidx, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucky(outname, indir, alpha, nchains, nreps, niter):\n",
    "    ## check paths\n",
    "    if not os.path.exists(indir):\n",
    "        raise Exception(\"infiles not found; try using a fullpath\")\n",
    "    \n",
    "    ## call bucky \n",
    "    infiles = os.path.join(indir, \"*.in\")\n",
    "    cmd = [\"bucky\", \n",
    "           \"-a\", str(alpha),\n",
    "           \"-c\", str(nchains),\n",
    "           \"-k\", str(nreps),\n",
    "           \"-n\", str(int(niter)), \n",
    "           \"-o\", outname, \n",
    "           infiles]\n",
    "    \n",
    "    cmd = \" \".join(cmd)\n",
    "    proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE, shell=True)\n",
    "    stdout = proc.communicate()\n",
    "    if proc.returncode:\n",
    "        return \" \".join(cmd), stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run mrbayes on all nexus files in parallel\n",
    "It is important that the lists contain the full paths to the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## send jobs to the parallel engines\n",
    "asyncs = []\n",
    "for nexfile in nexfiles:\n",
    "    async = lbview.apply(mrbayes, nexfile)\n",
    "    asyncs.append(async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of the mrbayes runs\n",
    "If you want to check the progress interactively then execute the cell below, which will tell you how many jobs have finished. The cell below that uses a wait() statement to block progress until all of the mrbayes jobs are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrbayes batch runs:\n",
      "722 jobs submitted\n",
      "35 jobs finished\n"
     ]
    }
   ],
   "source": [
    "ready =  [i for i in asyncs if i.ready()]\n",
    "failed = [i for i in ready if not i.successful()]\n",
    "\n",
    "## print progress\n",
    "print \"mrbayes batch runs:\"\n",
    "print \"{} jobs submitted\".format(len(asyncs))\n",
    "print \"{} jobs finished\".format(len(ready))\n",
    "\n",
    "## print errors, if any.\n",
    "if any(failed):\n",
    "    print failed[0].exception()\n",
    "    print failes[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## waits until all mrbayes runs are finished\n",
    "ipyclient.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the mrbayes posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed 9 trees in: /home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13\n",
      "summed 0 trees in: /home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp9\n"
     ]
    }
   ],
   "source": [
    "## run mbsum on each directory of tree files\n",
    "mbsum(RUNDIR1)\n",
    "mbsum(RUNDIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run BUCKy to infer concordance factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchains = 4\n",
    "nreps = 4\n",
    "niter = 1e6\n",
    "alphas = [0.1, 1, 10]\n",
    "\n",
    "## submit jobs to run at several values of alpha\n",
    "bsyncs = []\n",
    "for alpha in alphas:\n",
    "    outname = os.path.join(RUNDIR, \"bucky-{}\".format(alpha))\n",
    "    args = (outname, RUNDIR, alpha, nchains, nreps, niter)\n",
    "    async = lbview.apply(bucky, *args)\n",
    "    bsyncs.append(async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of Bucky runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucky batch runs:\n",
      "3 jobs submitted\n",
      "0 jobs finished\n"
     ]
    }
   ],
   "source": [
    "ready =  [i for i in bsyncs if i.ready()]\n",
    "failed = [i for i in ready if not i.successful()]\n",
    "print \"bucky batch runs:\"\n",
    "print \"{} jobs submitted\".format(len(bsyncs))\n",
    "print \"{} jobs finished\".format(len(ready))\n",
    "if len(ready) == len(bsyncs):\n",
    "    ## print errors, if any.\n",
    "    if any(failed):\n",
    "        print failed[0].exception()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Look at individual results files for final stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = glob.glob(os.path.join(RUNDIR, \"bucky-*.concordance\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-1.txt.concordance',\n",
       " '/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-0.1.concordance',\n",
       " '/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-0.1.txt.concordance',\n",
       " '/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-1.concordance',\n",
       " '/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-10.txt.concordance',\n",
       " '/home/deren/Documents/ipyrad/tests/analysis-bucky/bucky-samp13/bucky-10.concordance']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
