{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipyrad testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ipyrad:H4CKERZ-mode: __loglevel__ = DEBUG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.66\n"
     ]
    }
   ],
   "source": [
    "import ipyrad as ip      ## for RADseq assembly\n",
    "print ip.__version__     ## print version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## clear test directory if it already exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(\"./test_pairgbs\"):\n",
    "    shutil.rmtree(\"./test_pairgbs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started -- Assembly objects\n",
    "The first step is to create an Assembly object. It takes an optional argument that provides it with an internal name. We could imagine that we planned to assemble and later combine data from multiple sequencing runs, but before combining them each group of samples has to be analyzed under a different set of parameters. As an example, we could call this data set \"2014_data_set\" and another \"2015_data_set\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ipyrad.core.assembly:New Assembly object `test_pairgbs` created\n",
      "INFO:ipyrad.core.parallel:Local connection to 4 engines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Assembly object `test_pairgbs` created\n",
      "ipyparallel setup: Local connection to 4 engines.\n"
     ]
    }
   ],
   "source": [
    "## create an Assembly object called data1. \n",
    "## It takes an 'test'\n",
    "data1 = ip.Assembly('test_pairgbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1.set_params(1, \"./test_pairgbs\")\n",
    "data1.set_params(2, \"./data/sim_pairgbs_*.gz\")\n",
    "data1.set_params(3, \"./data/sim_pairgbs_barcodes.txt\")\n",
    "data1.set_params(10, \"pairgbs\")\n",
    "data1.set_params(17, 0)\n",
    "#data1.set_params(19, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   working_directory           ./test_pairgbs                               \n",
      "  2   raw_fastq_path              ./data/sim_pairgbs_*.gz                      \n",
      "  3   barcodes_path               ./data/sim_pairgbs_barcodes.txt              \n",
      "  4   sorted_fastq_path                                                        \n",
      "  5   restriction_overhang        ('TGCAG', '')                                \n",
      "  6   max_low_qual_bases          5                                            \n",
      "  7   engines_per_job             4                                            \n",
      "  8   mindepth_statistical        6                                            \n",
      "  9   mindepth_majrule            6                                            \n",
      "  10  datatype                    pairgbs                                      \n",
      "  11  clust_threshold             0.85                                         \n",
      "  12  minsamp                     4                                            \n",
      "  13  max_shared_heterozygosity   0.25                                         \n",
      "  14  prefix_outname              test_pairgbs                                 \n",
      "  15  phred_Qscore_offset         33                                           \n",
      "  16  max_barcode_mismatch        1                                            \n",
      "  17  filter_adapters             0                                            \n",
      "  18  filter_min_trim_len         35                                           \n",
      "  19  ploidy                      2                                            \n",
      "  20  max_stack_size              1000                                         \n",
      "  21  max_Ns_consens              (5, 5)                                       \n",
      "  22  max_Hs_consens              (8, 8)                                       \n",
      "  23  max_SNPs_locus              (100, 100)                                   \n",
      "  24  max_Indels_locus            (5, 99)                                      \n",
      "  25  trim_overhang               (1, 2, 2, 1)                                 \n",
      "  26  hierarchical_clustering     0                                            \n",
      "  27  assembly_method             denovo                                       \n",
      "  28  reference_sequence                                                       \n"
     ]
    }
   ],
   "source": [
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Demultiplex the raw data files\n",
    "This demultiplexes, and links the new fastq data files as Samples to the Assembly object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state  reads_raw\n",
      "1A0      1       4000\n",
      "1B0      1       4000\n",
      "1C0      1       4000\n",
      "1D0      1       4000\n",
      "2E0      1       4000\n",
      "2F0      1       4000\n",
      "2G0      1       4000\n",
      "2H0      1       4000\n",
      "3I0      1       4000\n",
      "3J0      1       4000\n",
      "3K0      1       4000\n",
      "3L0      1       4000\n"
     ]
    }
   ],
   "source": [
    "## demultiplex the raw_data files\n",
    "## set step1 to only go if no samples are present...\n",
    "data1.step1() #append=True)\n",
    "\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data1.set_params(4, \"./test_pairgbs/fastq/*\")\n",
    "#data1.link_fastqs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter reads \n",
    "If for some reason we wanted to execute on just a subsample of our data, we could do this by selecting only certain samples to call the `step2` function on. Because `step2` is a function of `data`, it will always execute with the parameters that are linked to `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n",
      "INFO:ipyrad.assemble.demultiplex:optim = 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state  reads_raw  reads_filtered\n",
      "1A0      2       4000            4000\n",
      "1B0      2       4000            4000\n",
      "1C0      2       4000            4000\n",
      "1D0      2       4000            4000\n",
      "2E0      2       4000            4000\n",
      "2F0      2       4000            4000\n",
      "2G0      2       4000            4000\n",
      "2H0      2       4000            4000\n",
      "3I0      2       4000            4000\n",
      "3J0      2       4000            4000\n",
      "3K0      2       4000            4000\n",
      "3L0      2       4000            4000\n"
     ]
    }
   ],
   "source": [
    "data1.step2() #[\"1A0\",\"1B0\"])#\n",
    "\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the `name` and `fname` of the `Sample` objects and edit them as desired without affecting the original data files. The `name` identifier is equal to the filename (`fname`) by default, but is the name used in the final output files, and thus it may be desirable to reduce it to something more readable, like below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "data1 = ip.load_assembly(\"test_pairgbs/test_pairgbs.assembly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 1 samples using 4 engines per job.\n"
     ]
    }
   ],
   "source": [
    "data1.step3([\"1A0\"], force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state  reads_raw  reads_filtered  clusters_total  clusters_kept\n",
      "1A0      3       4000            4000             100            100\n",
      "1B0      3       4000            4000             100            100\n",
      "1C0      3       4000            4000             100            100\n",
      "1D0      3       4000            4000             100            100\n",
      "2E0      3       4000            4000             100            100\n",
      "2F0      3       4000            4000             100            100\n",
      "2G0      3       4000            4000             100            100\n",
      "2H0      3       4000            4000             100            100\n",
      "3I0      3       4000            4000             100            100\n",
      "3J0      3       4000            4000             100            100\n",
      "3K0      3       4000            4000             100            100\n",
      "3L0      3       4000            4000             100            100\n"
     ]
    }
   ],
   "source": [
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A0      4       4000            4000             100            100   \n",
      "1B0      4       4000            4000             100            100   \n",
      "1C0      4       4000            4000             100            100   \n",
      "1D0      4       4000            4000             100            100   \n",
      "2E0      4       4000            4000             100            100   \n",
      "2F0      4       4000            4000             100            100   \n",
      "2G0      4       4000            4000             100            100   \n",
      "2H0      4       4000            4000             100            100   \n",
      "3I0      4       4000            4000             100            100   \n",
      "3J0      4       4000            4000             100            100   \n",
      "3K0      4       4000            4000             100            100   \n",
      "3L0      4       4000            4000             100            100   \n",
      "\n",
      "     hetero_est  error_est  \n",
      "1A0    0.009533   0.000482  \n",
      "1B0    0.009633   0.000469  \n",
      "1C0    0.009736   0.000499  \n",
      "1D0    0.009428   0.000428  \n",
      "2E0    0.009071   0.000480  \n",
      "2F0    0.008443   0.000456  \n",
      "2G0    0.009796   0.000437  \n",
      "2H0    0.009537   0.000474  \n",
      "3I0    0.009630   0.000506  \n",
      "3J0    0.008724   0.000537  \n",
      "3K0    0.009428   0.000509  \n",
      "3L0    0.009821   0.000513  \n"
     ]
    }
   ],
   "source": [
    "data1.step4()\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1.step5([\"1A0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data1.step5([\"1A0\"])  ## better filters for -N-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick parameter explanations are always on-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip.get_params_info(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history \n",
    "A common problem after struggling through an analysis is that you find you've completely forgotten what parameters you used at what point, and when you changed them. The log history time stamps all calls to `set_params()`, as well as calls to `step` methods. It also records copies/branching of data objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data.log:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Assembly objects\n",
    "Assembly objects can be saved and loaded so that interactive analyses can be started, stopped, and returned to quite easily. The format of these saved files is a serialized 'pickle' object used by Python. Individual Sample objects are saved within Assembly objects. While it is important to remember that some of the information in Assembly objects is in their links to data files, most of the useful information that we would want to analyze post assembly is stored in the object itself. Thus these objects will be useful for making plots and tables of assembly statistics later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save assembly object\n",
    "#ip.save_assembly(\"data1.p\")\n",
    "\n",
    "## load assembly object\n",
    "#data = ip.load_assembly(\"data1.p\")\n",
    "#print data.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
