{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "from ipyrad.assemble.cluster_across import *\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient = ipp.Client()\n",
    "len(ipyclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loading Assembly: aligntest\n",
      "  from saved path: ~/Documents/ipyrad/tests/analysis-ipyrad/aligntest.json\n"
     ]
    }
   ],
   "source": [
    "data = ip.load_json(\"analysis-ipyrad/aligntest.json\")\n",
    "samples = data.samples.values()\n",
    "noreverse = False\n",
    "force = True\n",
    "randomseed = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyrad.assemble.write_outfiles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare dirs\n",
    "data.dirs.outfiles = os.path.join(data.dirs.project, data.name+\"_outfiles\")\n",
    "if not os.path.exists(data.dirs.outfiles):\n",
    "    os.mkdir(data.dirs.outfiles)\n",
    "\n",
    "## make the snps/filters data base, fills the dups and inds filters\n",
    "## and fills the splits locations\n",
    "data.database = os.path.join(data.dirs.outfiles, data.name+\".hdf5\")\n",
    "init_arrays(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 641 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "## grab super seqs and upper it\n",
    "with h5py.File(data.clust_database) as io5:\n",
    "    superints = io5[\"seqs\"][0:100000, 1, :].view(np.int8)\n",
    "    #print(superints.shape)\n",
    "    #print(superints[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "with h5py.File(data.clust_database) as io5:\n",
    "    #superints = np.char.upper(io5[\"seqs\"][0:100000, 1,]).view(np.int8)\n",
    "    superints = io5[\"seqs\"][0:100000, 1, :]#.view(np.int8)\n",
    "    mask = np.char.islower(superints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'G', 'C', ..., 'N', 'N', 'N'],\n",
       "       ['T', 'G', 'C', ..., 'N', 'N', 'N'],\n",
       "       ['T', 'G', 'C', ..., 'N', 'N', 'N'],\n",
       "       ..., \n",
       "       ['T', 'G', 'C', ..., 'N', 'N', 'N'],\n",
       "       ['N', 'N', 'N', ..., 'N', 'N', 'N'],\n",
       "       ['N', 'N', 'N', ..., 'N', 'N', 'N']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.char.upper(superints)#.view(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [####################] 100%  filtering loci        | 0:00:09 | s7 | \n"
     ]
    }
   ],
   "source": [
    "filter_all_clusters(data, samples, ipyclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(data.clust_database, 'r') as io5:\n",
    "    optim = io5[\"seqs\"].attrs[\"chunksize\"][0]\n",
    "    nloci = io5[\"seqs\"].shape[0]\n",
    "\n",
    "    ## get name and snp padding\n",
    "    anames = io5[\"seqs\"].attrs[\"samples\"]\n",
    "    snames = [i.name for i in samples]\n",
    "    ## get only snames in this data set sorted in the order they are in io5\n",
    "    names = [i for i in anames if i in snames]\n",
    "    pnames, _ = padnames(names)\n",
    "    \n",
    "sidx = np.array([i in snames for i in anames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 21, 42]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0, 50, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  [                    ]   0%  building loci/stats   | 0:00:00 | s7 | "
     ]
    }
   ],
   "source": [
    "## start vcf progress bar\n",
    "start = time.time()\n",
    "elapsed = datetime.timedelta(seconds=int(time.time()-start))\n",
    "progressbar(20, 0, \" building loci/stats   | {} | s7 |\".format(elapsed))\n",
    "\n",
    "## get some db info\n",
    "with h5py.File(data.clust_database, 'r') as io5:\n",
    "    ## will iterate optim loci at a time\n",
    "    optim = io5[\"seqs\"].attrs[\"chunksize\"][0]\n",
    "    nloci = io5[\"seqs\"].shape[0]\n",
    "    anames = io5[\"seqs\"].attrs[\"samples\"]\n",
    "\n",
    "## get name and snp padding\n",
    "pnames, snppad = padnames(anames)\n",
    "snames = [i.name for i in samples]\n",
    "smask = np.array([i not in snames for i in anames])\n",
    "\n",
    "## keep track of how many loci from each sample pass all filters\n",
    "samplecov = np.zeros(len(anames), dtype=np.int32)\n",
    "\n",
    "## set initial value to zero for all values above min_samples_locus\n",
    "#for cov in range(data.paramsdict[\"min_samples_locus\"], len(anames)+1):\n",
    "locuscov = Counter()\n",
    "for cov in range(len(anames)+1):\n",
    "    locuscov[cov] = 0\n",
    "\n",
    "## client for sending jobs to parallel engines\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "\n",
    "## send jobs in chunks\n",
    "loci_asyncs = {}\n",
    "for istart in xrange(0, nloci, optim):\n",
    "    args = [data, optim, pnames, snppad, smask, istart, samplecov, locuscov]\n",
    "    loci_asyncs[istart] = lbview.apply(locichunk, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [####################] 100%  building loci/stats   | 0:00:20 | s7 | \n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    done = [i.ready() for i in loci_asyncs.values()]\n",
    "    elapsed = datetime.timedelta(seconds=int(time.time()-start))\n",
    "    progressbar(len(done), sum(done),\n",
    "        \" building loci/stats   | {} | s7 |\".format(elapsed))\n",
    "    time.sleep(0.1)\n",
    "    if len(done) == sum(done):\n",
    "        print(\"\")\n",
    "        break\n",
    "\n",
    "## check for errors\n",
    "for job in loci_asyncs:\n",
    "    if loci_asyncs[job].ready() and not loci_asyncs[job].successful():\n",
    "        LOGGER.error(\"error in building loci [%s]: %s\",\n",
    "                     job, loci_asyncs[job].exception())\n",
    "        raise IPyradWarningExit(loci_asyncs[job].exception())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## concat and cleanup\n",
    "results = [i.get() for i in loci_asyncs.values()]\n",
    "#results.sort(key=[int(i) for i in loci_asyncs])\n",
    "## update dictionaries\n",
    "for chunk in results:\n",
    "    samplecov += chunk[0]\n",
    "    locuscov.update(chunk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get all chunk files\n",
    "tmploci = glob.glob(data.outfiles.loci+\".[0-9]*\")\n",
    "## sort by start value\n",
    "tmploci.sort(key=lambda x: int(x.split(\".\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmploc = tmploci[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29154_superba          TCTGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTTTCGATCTCAGGCGGTCTT', '30556_thamno           TCCGGTCCCGCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTT', '30686_cyathophylla     TCCAGTCCCGCGGGTGATCAAGGCCCCACCACCGCATCTCACATTCTCGATCTCAGGCGGTCTT', '33413_thamno           TCCGGTCCTTCGGGTGATCAAGGCCCCACCACCGCGTCTCACATTCTAGATCTCAGGCGGTCTT']\n",
      "['29154_superba          AATGATGGTGGTACACATATTAATTACAATTTGGACAAC', '30556_thamno           ACAGATGGTGGTACACATGTCAATTACAATTTGGATAAC', '30686_cyathophylla     AATGATGGTGGTACACATATTAATTACAATTTGGACAAC', '33413_thamno           AGTGATGGTGGTACACATGTCNANTACAATTTGGACAAC']\n",
      "['29154_superba          CATTAATCAGC-AAAAAAACACTCACTTTAAAGAAAAATGAATAACTCCAACAGCATGAGCTAC', '30556_thamno           CATTAATCAGC-AAAAAAATACTCACTTTAAAG-AAAATGAATAACTCCAACAGCATGAGCTAC', '30686_cyathophylla     CATTAATCAGCAAAAAAAACACTCACTTTAAAG-AAAATGAATAACTCCAACAGCATGAGCTAC', '33413_thamno           CATTAATCAGC-AAAAAAATACTCACTTTAAAG-AAAATGAATAACACCAACAGCATGAGCTAC']\n",
      "['29154_superba          ATTGCAANATGAACCTATGAAGCTAAGGTAGCCCNACGCAACAAAATAAAATTTGATTTTGAAC', '30556_thamno           ATTGCAACATGAACCTATGAAGCTAAGGTARCCCAACGCAACAAAATAAAATTTGATTTTGAAC', '30686_cyathophylla     ATTGCAACATGAACCTATGAAGCTAAGGTAGCCCAACGCAAC-AAATAAAATTTGATTTTGAAC', '33413_thamno           ATTGCAACATGAACCTATGAAGCTAAGGTAGCCCAACGCAACAAAATAAAATTTGATTTTGAAC']\n",
      "['29154_superba          TCCGCCGCTGTTCCTTTAATGGCATATCCGCGGCGGCGCCACCAGTACCGCCACCGNCT', '30556_thamno           TCCGCCGCTGTTCCTTTAATGGCATATCCGCGGCGGCGCCACCMGNACCGCCACCGTCT', '30686_cyathophylla     TCCGCCGCTGTTCCTTTAATGGCATATCCGCGGCGGCGCCACCAGTACCGCCACCGTCT', '33413_thamno           TCCGCCGCTGTTCCTTTAATGGCATATCCGCGGCGGCGCCACCAGTACCGCCACCGTCT']\n",
      "['29154_superba          TAATTTAAACAGCTGAGCCTGCAATCGTGGAAGGAAGTTAAACGAAA', '30556_thamno           TAATTTAAACAGCTGAGCCTGCAATTGTGGAAGGAAGTTAAACGAAA', '32082_przewalskii      TAATTTAAACAGCTGAGCCTGCAATCGTGGNAGGNAGTTAAACNAAA', '33413_thamno           TAATTTAAACAGCTGAGCCTGCAATTGTGGAAGGAAGTTAAACGAAA']\n",
      "['29154_superba          ANGATCTTT-GACTGTAACCCAAAACCCAAACAACCAAACCAGGCCCCATAGCGT---GGTTCA', '30556_thamno           AGGATCTTTCGTCTGTAACCCAAAACCCAAACAACCAAACCAGGCCCCATAACGT---GCTTCA', '30686_cyathophylla     AGGATCTTTCGGCTGTAACCCAAAACCCAAACAATCAAACCAGGCCCCATAACGT---GGTTCA', '33413_thamno           AGGATCTTTCGTCTGTAACCCAAAACCCAAACAACCAAACCAGGCCCCATAACGTGCAGGTTCA']\n",
      "['29154_superba          ATCAAAACAGTACTTTTCAGCTACTACACACACACAC-----ACATCACTCAAAACTTTTGCAAACC', '30556_thamno           ATCAAACCAGTACTTTTCAGCTACTACACWCACAC-------ACATCACTCAAAACTTTTGCAAACC', '30686_cyathophylla     ATCAAAACAGTACTTTTCAGCTACTACACACACACACACACAACATCACTCAAAACTTTTGCAAACC', '32082_przewalskii      ATCAAAACAGTACTTTTCAGCTACTACACACACACAC-----ACATCACTCAAAACTTTTGCAAACC', '33413_thamno           ATCAAACCAGTACTTTTCAGCTAMTACACACAyACACTC---ACATCACTCAAAACTTTTGCAAACC']\n",
      "['29154_superba          AAGGCGGTTATGTACGTACCGCGGGCCCAGACTTTGTGGTTGATGGGTGCCAAGGAGAAGT', '30556_thamno           AAGGCGGTTATGTACGTACCGCGGGCCCAGACTTTGTGGTTGATGGGTGCCAAGGAGAAGT', '30686_cyathophylla     AAGGCGGTTATGTACGTACCGCGGGCCCAGACTTTGTGGTTGATGGGTGCCAAGGAGAAGT', '32082_przewalskii      AAGGCGGTTTTGTACGTACCGCGGGCCCRGRCTyTGTGGCTGATGGGTGCCAAGGAGAAGT', '33413_thamno           AAGGCGGTTATGTACGTACCGCGGGCCCAGACTTTGTGGTTGATGGGTGCCAAGGAGAAGT']\n",
      "['29154_superba          TTCGCCGAAGTCAGATAAGCTTCTGCGAGCTCGCTATCTTCTCCATTCTAACTNATTTATCTCA', '30556_thamno           TTCGCCGAAGTCAGTTAAGCTTCTGCGAGCTCGCTATCTTCTCCATTCTAACTGATTTATCTCA', '30686_cyathophylla     TTCGCCGAAGTCAGTTAAGCTTCTGCGAGCTCGCTATCTTCTCCATTCTAACTGATTTATCCCA', '32082_przewalskii      TTCGCCGAAGTCAGTTAAGCTTCTGCGAGCTCGCTATCTTCTCCATTCTAACTGATTTATCTCA', '33413_thamno           TTCGCCGAAGTCAGTTAAGCTTCTGCGAGCTCGCTATCTTCTCCATTCTAACTGATTTATCTCA']\n"
     ]
    }
   ],
   "source": [
    "alleles = []\n",
    "\n",
    "with open(tmploc) as inloc:\n",
    "    data = inloc.read().split(\"|\\n\")\n",
    "    for loc in data[:10]:\n",
    "        lines = loc.split(\"\\n\")\n",
    "        ldata = lines[:-1]\n",
    "        snps = lines[-1]\n",
    "        \n",
    "        print ldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## write tmpchunks to locus file\n",
    "with open(data.outfiles.loci, 'w') as locifile:\n",
    "    for tmploc in tmploci:\n",
    "        with open(tmploc, 'r') as inloc:\n",
    "            locifile.write(inloc.read())\n",
    "        os.remove(tmploc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
