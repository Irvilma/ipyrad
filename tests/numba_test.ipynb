{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing ipyrad functions for speed improvements with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [list(\"AAA-TTTT\"),\n",
    "        list(\"AAATTTTT\"),\n",
    "        list(\"AAA-TTTT\"),\n",
    "        list(\"AAA-TTTN\"),\n",
    "        list(\"AAA-TTTT\"),\n",
    "        list(\"AAT-TTCT\"),\n",
    "        list(\"AAT-TTCT\"),\n",
    "        list(\"A-T-TTNT\"),\n",
    "        list(\"AAA-TTCT\"),\n",
    "        list(\"AAT-TTCT\") \n",
    "       ]\n",
    "consens = \"AAWNTTYT\"\n",
    "stack = [Counter(i) for i in np.array(data).T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0 0 0 0 0 0 1 1]\n",
      "[0 1 0 9 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(data)[:,:]\n",
    "coldepths = arr.shape[0]\n",
    "print coldepths\n",
    "\n",
    "ndepths = np.sum(arr=='N', axis=0)\n",
    "print ndepths\n",
    "\n",
    "idepths = np.sum(arr=='-', axis=0)\n",
    "print idepths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 10,  0,  0],\n",
       "       [ 0,  9,  0,  0],\n",
       "       [ 0,  6,  4,  0],\n",
       "       [ 0,  0,  1,  0],\n",
       "       [ 0,  0, 10,  0],\n",
       "       [ 0,  0, 10,  0],\n",
       "       [ 4,  0,  5,  0],\n",
       "       [ 0,  0,  9,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.sum(arr==x, axis=0) for x in list(\"CATG\")]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loading Assembly: data1 [test_rad/data1.assembly]\n",
      "  New Assembly: data1\n"
     ]
    }
   ],
   "source": [
    "import ipyrad as ip\n",
    "import numpy as np\n",
    "import gzip\n",
    "import itertools\n",
    "\n",
    "data1 = ip.load.load_assembly(\"test_rad/data1.assembly\")\n",
    "sample = data1.samples[\"1A_0\"]\n",
    "subsample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data1\n",
    "\n",
    "clusters = gzip.open(sample.files.clusters)\n",
    "pairdealer = itertools.izip(*[iter(clusters)]*2)\n",
    "## array will be (nclusters, readlen, 4)\n",
    "if \"pair\" in data.paramsdict[\"datatype\"]:\n",
    "    readlen = 2*data._hackersonly[\"max_fragment_length\"]\n",
    "else:\n",
    "    readlen = data._hackersonly[\"max_fragment_length\"]\n",
    "dims = (int(sample.stats.clusters_hidepth), readlen, 4)\n",
    "stacked = np.zeros(dims, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clustdealer(pairdealer, optim):\n",
    "    \"\"\" return optim clusters given iterators, and whether it got all or not\"\"\"\n",
    "    ccnt = 0\n",
    "    chunk = []\n",
    "    while ccnt < optim:\n",
    "        ## try refreshing taker, else quit\n",
    "        try:\n",
    "            taker = itertools.takewhile(lambda x: x[0] != \"//\\n\", pairdealer)\n",
    "            oneclust = [\"\".join(taker.next())]\n",
    "        except StopIteration:\n",
    "            #LOGGER.debug('last chunk %s', chunk)\n",
    "            return 1, chunk\n",
    "\n",
    "        ## load one cluster\n",
    "        while 1:\n",
    "            try: \n",
    "                oneclust.append(\"\".join(taker.next()))\n",
    "            except StopIteration:\n",
    "                break\n",
    "        chunk.append(\"\".join(oneclust))\n",
    "        ccnt += 1\n",
    "    return 0, chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stackarray(data, sample):\n",
    "    \"\"\" makes a list of lists of reads at each site \"\"\"\n",
    "    ## get clusters file\n",
    "    clusters = gzip.open(sample.files.clusters)\n",
    "    pairdealer = itertools.izip(*[iter(clusters)]*2)\n",
    "\n",
    "    ## array will be (nclusters, readlen, 4)\n",
    "    if \"pair\" in data.paramsdict[\"datatype\"]:\n",
    "        readlen = 2*data._hackersonly[\"max_fragment_length\"]\n",
    "    else:\n",
    "        readlen = data._hackersonly[\"max_fragment_length\"]\n",
    "    dims = (int(sample.stats.clusters_hidepth), readlen, 4)\n",
    "    stacked = np.zeros(dims, dtype=np.int16)\n",
    "\n",
    "    ## don't use sequence edges / restriction overhangs\n",
    "    cutlens = [None, None]\n",
    "    for cidx, cut in enumerate(data.paramsdict[\"restriction_overhang\"]):\n",
    "        if cut:\n",
    "            cutlens[cidx] = len(cut)\n",
    "    try:\n",
    "        cutlens[1] = -1*cutlens[1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    #LOGGER.info(cutlens)\n",
    "\n",
    "    ## fill stacked\n",
    "    done = 0\n",
    "    nclust = 0\n",
    "    while not done:\n",
    "        try:\n",
    "            done, chunk = clustdealer(pairdealer, 1)\n",
    "        except IndexError:\n",
    "            raise IPyradError(\"clustfile formatting error in %s\", chunk)\n",
    "        if chunk:\n",
    "            piece = chunk[0].strip().split(\"\\n\")\n",
    "            names = piece[0::2]\n",
    "            seqs = piece[1::2]\n",
    "            ## pull replicate read info from seqs\n",
    "            reps = [int(sname.split(\";\")[-2][5:]) for sname in names]\n",
    "            sseqs = [list(seq) for seq in seqs]\n",
    "            arrayed = np.concatenate(\n",
    "                      [[seq]*rep for seq, rep in zip(sseqs, reps)])\n",
    "            ## enforce minimum depth for estimates\n",
    "            if arrayed.shape[0] >= data.paramsdict[\"mindepth_statistical\"]:\n",
    "                ## remove edge columns\n",
    "                arrayed = arrayed[:, cutlens[0]:cutlens[1]]\n",
    "                ## remove cols that are pair separator\n",
    "                arrayed = arrayed[~np.any(arrayed == \"n\", axis=1)]\n",
    "                ## convert - to N\n",
    "                arrayed[arrayed == \"-\"] = \"N\"\n",
    "                ## remove cols that are all Ns\n",
    "                arrayed = arrayed[~np.any(arrayed == \"n\", axis=1)]                \n",
    "                ## store in stacked dict\n",
    "                catg = np.array(\\\n",
    "                    [np.sum(arrayed == i, axis=0) for i in list(\"CATG\")], \n",
    "                    dtype='int16').T\n",
    "                stacked[nclust, :catg.shape[0], :] = catg\n",
    "                nclust += 1\n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def tablestack(rstack):\n",
    "    \"\"\" makes a count dict of each unique array element \"\"\"\n",
    "    ## goes by 10% at a time to minimize memory overhead. Is possible it skips\n",
    "    ## the last chunk, but this shouldn't matter.\n",
    "    table = Counter()\n",
    "    for i in xrange(0, rstack.shape[0], rstack.shape[0]//10):\n",
    "        tmp = Counter([j.tostring() for j in rstack[i:i+rstack.shape[0]//10]])\n",
    "        table.update(tmp)\n",
    "    return table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def frequencies(stacked):\n",
    "    \"\"\" return frequency counts \"\"\"\n",
    "    totals = stacked.sum(axis=1)\n",
    "    totals = totals.sum(axis=0)\n",
    "    freqs = totals/np.float32(totals.sum())\n",
    "    return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked = stackarray(data, sample)\n",
    "bfreqs = frequencies(stacked)\n",
    "rstack = stacked.reshape(stacked.shape[0]*stacked.shape[1],\n",
    "                             stacked.shape[2])\n",
    "tstack = tablestack(rstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacks = np.array([np.fromstring(i, dtype=np.int16) \\\n",
    "                       for i in tstack.iterkeys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropme = np.zeros(4, dtype=np.int16).tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ustacks = np.array([np.fromstring(i, dtype=np.int16) \\\n",
    "                        for i in tstack.iterkeys()])\n",
    "counts = np.array(tstack.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startp = np.array([0.01, 0.001], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24844044,  0.24991964,  0.2499051 ,  0.25173481])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13186534682448681"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.binom.pmf(10, 100., 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?numba.jit('f2', nopython=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  1,  0,  0],\n",
       "       [ 0, 16,  1,  0],\n",
       "       [ 0,  0,  9, 11],\n",
       "       ..., \n",
       "       [24,  0,  1,  0],\n",
       "       [ 0,  0, 16,  1],\n",
       "       [ 0,  0, 28,  0]], dtype=int16)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ustacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jit(['float32[:,:](float32, float32, int16[:,:])'])\n",
    "def jlikelihood1(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability homozygous\"\"\"\n",
    "    ## make sure base_frequencies are in the right order\n",
    "    #print uniqstackl.sum()-uniqstack, uniqstackl.sum(), 0.001\n",
    "    totals = np.array([ustacks.sum(axis=1)]*4).T\n",
    "    prob = scipy.stats.binom.pmf(totals-ustacks, totals, errors)\n",
    "    return np.sum(bfreqs*prob, axis=1)\n",
    "\n",
    "\n",
    "def likelihood1(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability homozygous\"\"\"\n",
    "    ## make sure base_frequencies are in the right order\n",
    "    #print uniqstackl.sum()-uniqstack, uniqstackl.sum(), 0.001\n",
    "    totals = np.array([ustacks.sum(axis=1)]*4).T\n",
    "    prob = scipy.stats.binom.pmf(totals-ustacks, totals, errors)\n",
    "    return np.sum(bfreqs*prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@numba.jit(['float32[:](float32, float32[:], int16[:,:])'])\n",
    "def jlikelihood2(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability of heterozygous\"\"\"\n",
    "    returns = np.zeros(len(ustacks), dtype=np.float32)\n",
    "    for idx, ustack in enumerate(ustacks):\n",
    "        spair = np.array(list(itertools.combinations(ustack, 2)))\n",
    "        bpair = np.array(list(itertools.combinations(bfreqs, 2)))\n",
    "        one = 2.*bpair.prod(axis=1)\n",
    "        tot = ustack.sum()\n",
    "        atwo = tot - spair[:,0] - spair[:,1]\n",
    "        two = scipy.stats.binom.pmf(atwo, tot, (2.*errors)/3.)\n",
    "        three = scipy.stats.binom.pmf(\\\n",
    "                    spair[:,0], spair.sum(axis=1), 0.5)\n",
    "        four = 1.-np.sum(bfreqs**2)\n",
    "        returns[idx] = np.sum(one*two*(three/four))\n",
    "    return np.array(returns)\n",
    "\n",
    "\n",
    "def likelihood2(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability of heterozygous\"\"\"\n",
    "    returns = np.zeros([len(ustacks)])\n",
    "    for idx, ustack in enumerate(ustacks):\n",
    "        spair = np.array(list(itertools.combinations(ustack, 2)))\n",
    "        bpair = np.array(list(itertools.combinations(bfreqs, 2)))\n",
    "        one = 2.*bpair.prod(axis=1)\n",
    "        tot = ustack.sum()\n",
    "        atwo = tot - spair[:,0] - spair[:,1]\n",
    "        two = scipy.stats.binom.pmf(atwo, tot, (2.*errors)/3.)\n",
    "        three = scipy.stats.binom.pmf(\\\n",
    "                    spair[:,0], spair.sum(axis=1), 0.5)\n",
    "        four = 1.-np.sum(bfreqs**2)\n",
    "        returns[idx] = np.sum(one*two*(three/four))\n",
    "    return np.array(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  1]\n",
      " [23  0]\n",
      " [23  0]\n",
      " [ 1  0]\n",
      " [ 1  0]\n",
      " [ 0  0]]\n",
      "[ 0  1  1 23 23 24]\n"
     ]
    }
   ],
   "source": [
    "spair = np.array(list(itertools.combinations(ustacks[0], 2)))\n",
    "print spair\n",
    "atwo = tot - spair[:,0] - spair[:,1]\n",
    "print atwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "print ustacks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.43051344e-06,   1.19209453e-07,   1.19209453e-07,\n",
       "         5.00000000e-01,   5.00000000e-01,   1.00000000e+00])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.binom.pmf(atwo, tot, (2.*0.001)/3.)\n",
    "scipy.stats.binom.pmf(spair[:,0], spair.sum(axis=1), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = ustacks[0].sum()\n",
    "tot\n",
    "atwo = tot - np.array([i[0] for i in sp])\n",
    "atwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  1],\n",
       "       [23,  0],\n",
       "       [23,  0],\n",
       "       [ 1,  0],\n",
       "       [ 1,  0],\n",
       "       [ 0,  0]], dtype=int16)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot - np.array(list(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 118 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "likelihood2(0.001, bfreqs, ustacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 115 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "jlikelihood2(0.001, bfreqs, ustacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 124 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "likelihood2(0.001, bfreqs, ustacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.88 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 665 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "jlikelihood1(0.001, bfreqs, ustacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 596 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "likelihood1(0.001, bfreqs, ustacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOly Cow\n",
    "using jit is so much faster! Just need to rewrite code to fill empty arrays instead of appending to lists and we should be able to use jit just fine for steps 1,2,4,5,7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.70 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 2.99 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fillarr(arr, list(\"abcdefgh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 778.38 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 209 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jfillarr(arr, list(\"abcdefgh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e1483d9e89a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## pure python\n",
    "def findbcode(cut, longbar, read1):\n",
    "    search = read1[1][:longbar+len(cut)]\n",
    "    countcuts = search.count(cut)\n",
    "    if countcuts == 1:\n",
    "        barcode = search.split(cut, 1)[0]\n",
    "    elif countcuts == 2:\n",
    "        barcode = search.rsplit(cut, 2)[0]\n",
    "    else:\n",
    "        barcode = \"\"\n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## jit version\n",
    "@jit\n",
    "def jfindbarcode(cut, longbar, read1):\n",
    "    search = read1[1][:longbar+len(cut)]\n",
    "    countcuts = search.count(cut)\n",
    "    if countcuts == 1:\n",
    "        barcode = search.split(cut, 1)[0]\n",
    "    elif countcuts == 2:\n",
    "        barcode = search.rsplit(cut, 2)[0]\n",
    "    else:\n",
    "        barcode = \"\"\n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut = \"TGCAG\"\n",
    "longbar = 6\n",
    "read1 = ['fakeread','AAACCCTGCAGAAAAAAAAAAAAAAAAA']\n",
    "nread1 = np.array(['fakeread','AAACCCTGCAGAAAAAAAAAAAAAAAAA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.48 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 914 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "findbcode(cut, longbar, read1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 11.24 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 1.08 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "findbcode(cut, longbar, nread1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 53.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "jfindbarcode(cut, longbar, nread1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read1[1][:longbar+6].count(\"TGCAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequencies(stacked):\n",
    "    \"\"\" return frequency counts \"\"\"\n",
    "    totals = stacked.sum(axis=1)\n",
    "    totals = totals.sum(axis=0)\n",
    "    freqs = totals/np.float32(totals.sum())\n",
    "    return freqs\n",
    "\n",
    "\n",
    "@jit(['float32[:,:](float32, float32, int16[:,:])'])\n",
    "def jlikelihood1(errors, bfreqs, ustacks):\n",
    "    \"\"\"Probability homozygous. All numpy and no loop so there was \n",
    "    no numba improvement to speed when tested. \"\"\"\n",
    "    ## make sure base_frequencies are in the right order\n",
    "    #print uniqstackl.sum()-uniqstack, uniqstackl.sum(), 0.001\n",
    "    totals = np.array([ustacks.sum(axis=1)]*4).T\n",
    "    prob = scipy.stats.binom.pmf(totals-ustacks, totals, errors)\n",
    "    return np.sum(bfreqs*prob, axis=1)\n",
    "\n",
    "def likelihood1(errors, bfreqs, ustacks):\n",
    "    \"\"\"Probability homozygous. All numpy and no loop so there was \n",
    "    no numba improvement to speed when tested. \"\"\"\n",
    "    ## make sure base_frequencies are in the right order\n",
    "    #print uniqstackl.sum()-uniqstack, uniqstackl.sum(), 0.001\n",
    "    totals = np.array([ustacks.sum(axis=1)]*4).T\n",
    "    prob = scipy.stats.binom.pmf(totals-ustacks, totals, errors)\n",
    "    return np.sum(bfreqs*prob, axis=1)\n",
    "\n",
    "\n",
    "@jit(['float32[:](float32, float32[:], int16[:,:])'])\n",
    "def jlikelihood2(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability of heterozygous. Very minimal speedup w/ numba.\"\"\"\n",
    "    returns = np.zeros(len(ustacks), dtype=np.float32)\n",
    "    for idx, ustack in enumerate(ustacks):\n",
    "        spair = np.array(list(itertools.combinations(ustack, 2)))\n",
    "        bpair = np.array(list(itertools.combinations(bfreqs, 2)))\n",
    "        one = 2.*bpair.prod(axis=1)\n",
    "        tot = ustack.sum()\n",
    "        atwo = tot - spair[:, 0] - spair[:, 1]\n",
    "        two = scipy.stats.binom.pmf(atwo, tot, (2.*errors)/3.)\n",
    "        three = scipy.stats.binom.pmf(\\\n",
    "                    spair[:, 0], spair.sum(axis=1), 0.5)\n",
    "        four = 1.-np.sum(bfreqs**2)\n",
    "        returns[idx] = np.sum(one*two*(three/four))\n",
    "    return np.array(returns)\n",
    "\n",
    "\n",
    "def likelihood2(errors, bfreqs, ustacks):\n",
    "    \"\"\"probability of heterozygous\"\"\"\n",
    "    returns = np.zeros([len(ustacks)])\n",
    "    for idx, ustack in enumerate(ustacks):\n",
    "        spair = np.array(list(itertools.combinations(ustack, 2)))\n",
    "        bpair = np.array(list(itertools.combinations(bfreqs, 2)))\n",
    "        one = 2.*bpair.prod(axis=1)\n",
    "        tot = ustack.sum()\n",
    "        atwo = tot - spair[:, 0] - spair[:, 1]\n",
    "        two = scipy.stats.binom.pmf(atwo, tot, (2.*errors)/3.)\n",
    "        three = scipy.stats.binom.pmf(\\\n",
    "                    spair[:, 0], spair.sum(axis=1), 0.5)\n",
    "        four = 1.-np.sum(bfreqs**2)\n",
    "        returns[idx] = np.sum(one*two*(three/four))\n",
    "    return np.array(returns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_diploid_lik(pstart, bfreqs, ustacks, counts):\n",
    "    \"\"\" Log likelihood score given values [H,E] \"\"\"\n",
    "    hetero, errors = pstart\n",
    "    if (hetero <= 0.) or (errors <= 0.):\n",
    "        score = np.exp(100)\n",
    "    else:\n",
    "        ## get likelihood for all sites\n",
    "        lik1 = (1.-hetero)*likelihood1(errors, bfreqs, ustacks)\n",
    "        lik2 = (hetero)*likelihood2(errors, bfreqs, ustacks)\n",
    "        liks = lik1+lik2\n",
    "        logliks = np.log(liks[liks > 0])*counts[liks > 0]\n",
    "        score = -logliks.sum()\n",
    "    return score\n",
    "\n",
    "\n",
    "@jit\n",
    "def j_diploid_lik(pstart, bfreqs, ustacks, counts):\n",
    "    \"\"\" Log likelihood score given values [H,E]. \"\"\"\n",
    "    hetero, errors = pstart\n",
    "    ## tell it to score terribly if scores are negative\n",
    "    if (hetero <= 0.) or (errors <= 0.):\n",
    "        score = np.exp(100)\n",
    "    else:\n",
    "        ## get likelihood for all sites\n",
    "        lik1 = (1.-hetero)*jlikelihood1(errors, bfreqs, ustacks)\n",
    "        lik2 = (hetero)*jlikelihood2(errors, bfreqs, ustacks)\n",
    "        liks = lik1+lik2\n",
    "        logliks = np.log(liks[liks > 0])*counts[liks > 0]\n",
    "        score = -logliks.sum()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pstart = np.array([0.01, 0.001], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 7.62 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func = get_diploid_lik\n",
    "hetero, errors = scipy.optimize.fmin(func, pstart,\n",
    "                                    (bfreqs, ustacks, counts), \n",
    "                                    disp=False,\n",
    "                                    full_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 7.72 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func = j_diploid_lik\n",
    "hetero, errors = scipy.optimize.fmin(func, pstart,\n",
    "                                    (bfreqs, ustacks, counts), \n",
    "                                    disp=False,\n",
    "                                    full_output=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
