{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _ipyrad_ testing tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Import _ipyrad_ and remove previous test files if they are already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.62\n"
     ]
    }
   ],
   "source": [
    "## import modules\n",
    "import ipyrad as ip      ## for RADseq assembly\n",
    "print ip.__version__     ## print version\n",
    "\n",
    "## clear data from test directory if it already exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(\"./test_rad/\"):\n",
    "    shutil.rmtree(\"./test_rad/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly and Sample objects\n",
    "\n",
    "Assembly and Sample objects are used by _ipyrad_ to access data stored on disk and to manipulate it. Each biological sample in a data set is represented in a Sample object, and a set of Samples is stored inside an Assembly object. The Assembly object has functions to assemble the data, and stores a log of all steps performed and the resulting statistics of those steps. Assembly objects can be copied or merged to allow branching events where different parameters can subsequently be applied to different Assemblies going forward. Examples of this are shown below.\n",
    "\n",
    "To create an Assembly object call `ip.Assembly` and pass a name for the data set. An Assembly object does not initially contain Samples, they will be created either by linking fastq files to the Assembly object if data are already demultiplexed, or by running `step1()` to demultiplex raw data files, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly object named data1\n"
     ]
    }
   ],
   "source": [
    "## create an Assembly object called data1. \n",
    "data1 = ip.Assembly(\"data1\")\n",
    "\n",
    "## The object will be saved to disk using its assigned name\n",
    "print \"Assembly object named\", data1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying assembly parameters\n",
    "All of the parameter settings are linked to an Assembly object, which has a set of default parameters when it is created. These can be viewed using the `get_params()` function. To get more detailed information about all paramteres use `ip.get_params_info()` or to select a single parameter use `ip.get_params_info(3)`. Assembly objects have a function `set_params()` that can be used to modify parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   working_directory             ./test_rad                                   \n",
      "  2   raw_fastq_path                ./data/sim_rad_test_R1_.fastq.gz             \n",
      "  3   barcodes_path                 ./data/sim_rad_test_barcodes.txt             \n",
      "  4   sorted_fastq_path                                                          \n",
      "  5   restriction_overhang          ('TGCAG', '')                                \n",
      "  6   max_low_qual_bases            5                                            \n",
      "  7   N_processors                  3                                            \n",
      "  8   mindepth_statistical          6                                            \n",
      "  9   mindepth_majrule              6                                            \n",
      "  10  datatype                      rad                                          \n",
      "  11  clust_threshold               0.85                                         \n",
      "  12  minsamp                       4                                            \n",
      "  13  max_shared_heterozygosity     0.25                                         \n",
      "  14  prefix_outname                data1                                        \n",
      "  15  phred_Qscore_offset           33                                           \n",
      "  16  max_barcode_mismatch          1                                            \n",
      "  17  filter_adapters               0                                            \n",
      "  18  filter_min_trim_len           35                                           \n",
      "  19  ploidy                        2                                            \n",
      "  20  max_stack_size                1000                                         \n",
      "  21  max_Ns_consens                5                                            \n",
      "  22  max_Hs_consens                8                                            \n",
      "  23  max_SNPs_locus                (100, 100)                                   \n",
      "  24  max_Indels_locus              (5, 99)                                      \n",
      "  25  trim_overhang                 (1, 2, 2, 1)                                 \n",
      "  26  hierarchical_clustering       0                                            \n"
     ]
    }
   ],
   "source": [
    "## modify parameters for this Assembly object\n",
    "data1.set_params(1, \"./test_rad\")\n",
    "data1.set_params(2, \"./data/sim_rad_test_R1_.fastq.gz\")\n",
    "data1.set_params(3, \"./data/sim_rad_test_barcodes.txt\")\n",
    "data1.set_params(7, 3)\n",
    "data1.set_params(10, 'rad')\n",
    "\n",
    "## print the new parameters to screen\n",
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting data\n",
    "If the data are already demultiplexed then fastq files can be linked directly to the Data object, which in turn will create Sample objects for each fastq file (or pair of fastq files for paired data). The files may be gzip compressed. If the data are not demultiplexed then you will have to run the step1 function below to demultiplex the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This would link fastq files from the 'sorted_fastq_path' if present\n",
    "## Here it does nothing b/c there are no files in the sorted_fastq_path\n",
    "data1.link_fastqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Demultiplex the raw data files\n",
    "This uses the barcodes information to demultiplex reads in data files found in the 'raw_fastq_path'. It will create a Sample object for each sample that will be stored in the Assembly object. The state of each sample will be set to 1, meaning that the sample has completed step 1 of the _ipyrad_ assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      1      20099             NaN             NaN            NaN   \n",
      "1B_0      1      19977             NaN             NaN            NaN   \n",
      "1C_0      1      20114             NaN             NaN            NaN   \n",
      "1D_0      1      19895             NaN             NaN            NaN   \n",
      "2E_0      1      19928             NaN             NaN            NaN   \n",
      "2F_0      1      19934             NaN             NaN            NaN   \n",
      "2G_0      1      20026             NaN             NaN            NaN   \n",
      "2H_0      1      19936             NaN             NaN            NaN   \n",
      "3I_0      1      20084             NaN             NaN            NaN   \n",
      "3J_0      1      20011             NaN             NaN            NaN   \n",
      "3K_0      1      20117             NaN             NaN            NaN   \n",
      "3L_0      1      19901             NaN             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n",
      "CPU times: user 2.31 s, sys: 98.9 ms, total: 2.41 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## run step 1 to demultiplex the data\n",
    "data1.step1()\n",
    "\n",
    "## print the results for each Sample in data1\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter reads \n",
    "If for some reason we wanted to execute on just a subsample of our data, we could do this by selecting only certain samples to call the `step2` function on. Because `step2` is a function of `data`, it will always execute with the parameters that are linked to `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      2      20099           20099             NaN            NaN   \n",
      "1B_0      2      19977           19977             NaN            NaN   \n",
      "1C_0      2      20114           20114             NaN            NaN   \n",
      "1D_0      2      19895           19895             NaN            NaN   \n",
      "2E_0      2      19928           19928             NaN            NaN   \n",
      "2F_0      2      19934           19934             NaN            NaN   \n",
      "2G_0      2      20026           20026             NaN            NaN   \n",
      "2H_0      2      19936           19936             NaN            NaN   \n",
      "3I_0      2      20084           20084             NaN            NaN   \n",
      "3J_0      2      20011           20011             NaN            NaN   \n",
      "3K_0      2      20117           20117             NaN            NaN   \n",
      "3L_0      2      19901           19901             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n",
      "CPU times: user 10 s, sys: 430 ms, total: 10.5 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## example of ways to run step 2 to filter and trim reads\n",
    "#data1.step2(\"1B_0\")             ## run on a single sample\n",
    "#data1.step2([\"1B_0\", \"1C_0\"])   ## run on one or more samples\n",
    "data1.step2()                    ## run on all samples, skipping finished ones\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: clustering within-samples\n",
    "\n",
    "Let's imagine at this point that we are interested in clustering our data at two different clustering thresholds. We will try 0.90 and 0.85. First we need to make a copy the Assembly object. This will inherit the locations of the data linked in the first object, but diverge in any future applications to the object. Thus, they can share the same working directory, and will inherit shared files, but create divergently linked files within this directory. You can view the directories linked to an Assembly object with the `.dirs` argument, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a copy of our Assemlbly object\n",
    "data2 = data1.copy(newname=\"test2\")\n",
    "\n",
    "## set clustering threshold to 0.90\n",
    "data2.set_params(11, 0.90)\n",
    "\n",
    "## look at inherited parameters\n",
    "data2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## run step 3 to cluster reads within samples using vsearch\n",
    "data1.step3(['2H_0'])  # [\"2H_0\", \"2G_0\"])\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run step 3 to cluster reads within samples using vsearch\n",
    "data2.step3()  # [\"2H_0\", \"2G_0\"])\n",
    "\n",
    "## print the results\n",
    "print data2.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branching Assembly objects\n",
    "And you can see below that the two Assembly objects are now working with several shared directories (working, fastq, edits) but with different clust directories (clust_0.85 and clust_0.9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"data1 directories:\"\n",
    "for (i,j) in data1.dirs.items():\n",
    "    print \"{}\\t{}\".format(i, j)\n",
    "    \n",
    "print \"\\ndata2 directories:\"\n",
    "for (i,j) in data2.dirs.items():\n",
    "    print \"{}\\t{}\".format(i, j)\n",
    "    \n",
    "## TODO: raw and fastq dirs... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1.statsfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of plotting with _ipyrad_\n",
    "There are a a few simple plotting functions in _ipyrad_ useful for visualizing results. These are in the module `ipyrad.plotting`. Below is an interactive plot for visualizing the distributions of coverages across the 12 samples in the test data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyrad.plotting as iplot\n",
    "\n",
    "## plot for one or more selected samples\n",
    "iplot.depthplot(data1, [\"1A_0\", \"1B_0\"])\n",
    "\n",
    "## plot for all samples in data1\n",
    "#iplot.depthplot(data1)\n",
    "\n",
    "## save plot as pdf and html\n",
    "iplot.depthplot(data1, outprefix=\"testfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Joint estimation of heterozygosity and error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## run step 4\n",
    "data1.step4()\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Consensus base calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import ipyrad as ip\n",
    "\n",
    "## reload autosaved data. In case you quit and came back \n",
    "#data1 = ip.load_dataobj(\"test_rad/data1.assembly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run step 5\n",
    "#data1.step5()\n",
    "\n",
    "## print the results\n",
    "#print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick parameter explanations are always on-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip.get_params_info(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history \n",
    "A common problem after struggling through an analysis is that you find you've completely forgotten what parameters you used at what point, and when you changed them. The log history time stamps all calls to `set_params()`, as well as calls to `step` methods. It also records copies/branching of data objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data1.log:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Assembly objects\n",
    "Assembly objects can be saved and loaded so that interactive analyses can be started, stopped, and returned to quite easily. The format of these saved files is a serialized 'dill' object used by Python. Individual Sample objects are saved within Assembly objects. These objects to not contain the actual sequence data, but only link to it, and so are not very large. The information contained includes parameters and the log of Assembly objects, and the statistics and state of Sample objects. Assembly objects are autosaved each time an assembly `step` function is called, but you can also create your own checkpoints with the `save` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save assembly object\n",
    "#ip.save_assembly(\"data1.p\")\n",
    "\n",
    "## load assembly object\n",
    "#data = ip.load_assembly(\"data1.p\")\n",
    "#print data.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
