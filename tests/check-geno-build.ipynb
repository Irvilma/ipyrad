{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the geno output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import ipyrad as ip\n",
    "import ipyparallel as ipp\n",
    "from ipyrad.assemble.write_outfiles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loading Assembly: cli\n",
      "  from saved path: ~/Documents/ipyrad/tests/cli/cli.json\n"
     ]
    }
   ],
   "source": [
    "data = ip.load_json(\"cli/cli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = data.samples.values()\n",
    "sidx = [1 for i in samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient = ipp.Client()\n",
    "ipyclient.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## prepare dirs\n",
    "data.dirs.outfiles = os.path.join(data.dirs.project, data.name+\"_outfiles\")\n",
    "if not os.path.exists(data.dirs.outfiles):\n",
    "    os.mkdir(data.dirs.outfiles)\n",
    "\n",
    "## make the snps/filters data base, fills the dups and inds filters\n",
    "## and fills the splits locations\n",
    "data.database = os.path.join(data.dirs.outfiles, data.name+\".hdf5\")\n",
    "init_arrays(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [####################] 100%  filtering loci        | 0:00:06 | s7 | \n",
      "  [####################] 100%  building loci/stats   | 0:00:00 | s7 | \n"
     ]
    }
   ],
   "source": [
    "filter_all_clusters(data, samples, ipyclient)\n",
    "\n",
    "## Everything needed is in the now filled h5 database. Filters were applied\n",
    "## with 'samples' taken into account. Now we create the loci file (default)\n",
    "## output and build a stats file. \n",
    "data.outfiles.loci = os.path.join(data.dirs.outfiles, data.name+\".loci\")\n",
    "make_loci_and_stats(data, samples, ipyclient)\n",
    "\n",
    "## OPTIONAL OUTPUTS:\n",
    "output_formats = data.paramsdict[\"output_formats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [####################] 100%  building vcf file     | 0:00:02 | s7 | \n",
      "  [####################] 100%  writing vcf file      | 0:00:00 | s7 | \n"
     ]
    }
   ],
   "source": [
    "## held separate from *output_formats cuz it's big and parallelized \n",
    "if any([x in output_formats for x in [\"v\", \"V\"]]):\n",
    "    full = \"V\" in output_formats\n",
    "    try:\n",
    "        make_vcf(data, samples, ipyclient, full=full)\n",
    "    except IPyradWarningExit as inst:\n",
    "        ## Something fsck vcf build. Sometimes this is simply a memory\n",
    "        ## issue, so trap the exception and allow it to try building\n",
    "        ## the other output formats.\n",
    "        print(\"  Error building vcf. See ipyrad_log.txt for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "optim = 100\n",
    "\n",
    "maxlen = data._hackersonly[\"max_fragment_length\"] + 20\n",
    "\n",
    "## get data sliced (optim chunks at a time)\n",
    "hslice = [start, start+optim]\n",
    "\n",
    "## read all taxa from disk (faster), then subsample taxa with sidx and\n",
    "## keepmask to greatly reduce the memory load\n",
    "with h5py.File(data.database, 'r') as co5:\n",
    "    afilt = co5[\"filters\"][hslice[0]:hslice[1], :]\n",
    "    keepmask = afilt.sum(axis=1) == 0\n",
    "    ## apply mask to edges\n",
    "    aedge = co5[\"edges\"][hslice[0]:hslice[1], :]\n",
    "    aedge = aedge[keepmask, :]\n",
    "del afilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(data.clust_database, 'r') as io5:\n",
    "    ## apply mask to edges to aseqs and acatg\n",
    "    aseqs = io5[\"seqs\"][hslice[0]:hslice[1], :, :].view(np.uint8)\n",
    "    aseqs = aseqs[keepmask, :]\n",
    "    aseqs = aseqs[:, sidx, :]\n",
    "    acatg = io5[\"catgs\"][hslice[0]:hslice[1], :, :, :]\n",
    "    acatg = acatg[keepmask, :]\n",
    "    acatg = acatg[:, sidx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12, 116, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acatg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "io5 = h5py.File(data.clust_database, 'r')\n",
    "co5 = h5py.File(data.database, 'r')\n",
    "\n",
    "## will iterate optim loci at a time\n",
    "optim = io5[\"seqs\"].attrs[\"chunksize\"][0]\n",
    "nloci = io5[\"seqs\"].shape[0]\n",
    "\n",
    "## get name and snp padding\n",
    "anames = io5[\"seqs\"].attrs[\"samples\"]\n",
    "snames = [i.name for i in samples]\n",
    "## get only snames in this data set sorted in the order they are in io5\n",
    "names = [i for i in anames if i in snames]\n",
    "pnames, _ = padnames(names)\n",
    "#pnames.sort()\n",
    "\n",
    "## get names boolean\n",
    "sidx = np.array([i in snames for i in anames])\n",
    "assert len(pnames) == sum(sidx)\n",
    "\n",
    "## get names index in order of pnames\n",
    "#sindx = [list(anames).index(i) for i in snames]\n",
    "\n",
    "## build arrays and outputs from arrays.\n",
    "## TODO, don't block during make-arrays\n",
    "arrs = make_arrays(data, sidx, optim, nloci, io5, co5)\n",
    "seqarr, snparr, bisarr, maparr = arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'T', 'T', ..., 'C', 'G', 'A'],\n",
       "       ['T', 'T', 'T', ..., 'C', 'G', 'A'],\n",
       "       ['T', 'T', 'T', ..., 'C', 'G', 'A'],\n",
       "       ..., \n",
       "       ['T', 'C', 'T', ..., 'C', 'G', 'A'],\n",
       "       ['T', 'T', 'T', ..., 'C', 'G', 'G'],\n",
       "       ['A', 'T', 'T', ..., 'C', 'G', 'A']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snparr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'C', 'A', ''],\n",
       "       ['T', 'C', '', ''],\n",
       "       ['T', 'A', '', ''],\n",
       "       ..., \n",
       "       ['C', 'A', '', ''],\n",
       "       ['G', 'T', '', ''],\n",
       "       ['A', 'G', '', '']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snpref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpref = reftrick(snparr.view(np.int8), GETCONS).view(\"S1\")\n",
    "bisref = reftrick(bisarr.view(np.int8), GETCONS).view(\"S1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## I order them by same order as in .loci, which is alphanumeric\n",
    "snpgeno = np.zeros(snparr.shape, dtype=np.uint8)\n",
    "snpgeno.fill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4018,)\n",
      "(4018,)\n"
     ]
    }
   ],
   "source": [
    "print snparr[0, :].shape\n",
    "print snpref[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       ..., \n",
       "       [2, 9, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 9],\n",
       "       [9, 2, 2, ..., 2, 2, 2]], dtype=uint8)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fill in complete hits\n",
    "mask2 = np.array(snparr == snpref[:, 0])#, dtype=np.int)\n",
    "snpgeno[mask2] = 2\n",
    "snpgeno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       ..., \n",
       "       [2, 9, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 9],\n",
       "       [9, 2, 2, ..., 2, 2, 2]], dtype=uint8)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fill in single hits (heteros)\n",
    "ambref = np.apply_along_axis(lambda x: TRANS[tuple(x)], 1, snpref[:, :2])\n",
    "mask1 = np.array(snparr == ambref)\n",
    "snpgeno[mask1] = 1\n",
    "snpgeno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 2],\n",
       "       ..., \n",
       "       [2, 0, 2, ..., 2, 2, 2],\n",
       "       [2, 2, 2, ..., 2, 2, 0],\n",
       "       [9, 2, 2, ..., 2, 2, 2]], dtype=uint8)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fill in zero hits (match to second base)\n",
    "mask0 = np.array(snparr == snpref[:, 1])#, dtype=np.int)\n",
    "snpgeno[mask0] = 0\n",
    "snpgeno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove those with a third base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222200202229\n",
      "222222222022\n",
      "222220222222\n",
      "222022222222\n",
      "222022222222\n",
      "222222222122\n",
      "222222202222\n",
      "222222222202\n",
      "222222122222\n",
      "022222222222\n",
      "222022222222\n",
      "000022222222\n",
      "222220222222\n",
      "222222212222\n",
      "222222212222\n",
      "221222222222\n",
      "222222220000\n",
      "222222222002\n",
      "222222222002\n",
      "222222222220\n",
      "\n",
      "TTTTCCTCTTTA\n",
      "TTTTTTTTTCTT\n",
      "TTTTTATTTTTT\n",
      "GGGTGGGGGGGG\n",
      "AAAGAAAAAAAA\n",
      "GGGGGGGGGSGG\n",
      "CCCCCCCTCCCC\n",
      "CCCCCCCCCCAC\n",
      "GGGGGGKGGGGG\n",
      "CAAAAAAAAAAA\n",
      "CCCTCCCCCCCC\n",
      "TTTTCCCCCCCC\n",
      "GGGGGCGGGGGG\n",
      "CCCCCCCMCCCC\n",
      "TTTTTTTWTTTT\n",
      "AAWAAAAAAAAA\n",
      "AAAAAAAAGGGG\n",
      "AAAAAAAAATTA\n",
      "TTTTTTTTTAAT\n",
      "GGGGGGGGGGGT\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(sys.stdout, snpgeno[:, :20].T, delimiter=\"\", fmt=\"%d\")\n",
    "print ''\n",
    "np.savetxt(sys.stdout, snparr[:, :20].T, delimiter=\"\", fmt=\"%s\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
