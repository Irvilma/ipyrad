{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D-statistics testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load /home/deren/Documents/ipyrad/ipyrad/analysis/dstat.py\n",
    "#!/usr/bin/env ipython2\n",
    "\n",
    "\"\"\" D-statistic calculations \"\"\"\n",
    "# pylint: disable=E1101\n",
    "# pylint: disable=F0401\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import numba\n",
    "except ImportError:\n",
    "    sys.exit('Python package `numba` not found')\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "\n",
    "def pandawrap(PDF, func):\n",
    "    pass\n",
    "\n",
    "\n",
    "### NUMBA FUNCS\n",
    "@numba.jit('i4(i4[:])')\n",
    "def sum1d(array):\n",
    "    \"\"\" a sum function that is typed for speed in numba\"\"\"\n",
    "    sumn = 0.0\n",
    "    for i in range(array.shape[0]):\n",
    "        sumn += array[i]\n",
    "    return sumn\n",
    "\n",
    "@numba.jit('f4(i4[:], i4[:])')\n",
    "def jcalc_d12(abbba, babba):\n",
    "    \"\"\" D12 calc for fixed differences from pdf (pandas data frame)\"\"\"\n",
    "    return sum1d(abbba-babba)/sum1d(abbba+babba)\n",
    "\n",
    "@numba.jit('f4(i4[:], i4[:])')\n",
    "def jcalc_d1(abbaa, babaa):\n",
    "    \"\"\" D1 calc for fixed differences from pdf (pandas data frame)\"\"\"    \n",
    "    return sum1d(abbaa-babaa)/sum1d(abbaa+babaa)\n",
    "\n",
    "@numba.jit('f4(i4[:], i4[:])')\n",
    "def jcalc_d2(ababa, baaba):\n",
    "    \"\"\" D2 calc for fixed differences from pdf (pandas data frame)\"\"\"        \n",
    "    return sum1d(ababa-baaba)/sum1d(ababa+baaba)\n",
    "\n",
    "\n",
    "\n",
    "@numba.jit('f4[:,:](i4[:,:], i4)')#, nopython=True)\n",
    "def jtestloop(vals, nboots):\n",
    "    \"\"\" fast numba testloop\"\"\"\n",
    "    ## create empty results array\n",
    "    barr = np.zeros((nboots, 3), dtype=np.float32)\n",
    "    ## fill array\n",
    "    for iboot in xrange(nboots):\n",
    "        samples = np.random.randint(0, vals.shape[0], vals.shape[0])\n",
    "        ## create empty boot array\n",
    "        bootarr = np.zeros((vals.shape[0], 19), dtype=np.int32)\n",
    "        ## fill the boots array\n",
    "        for irand in xrange(vals.shape[0]):\n",
    "            bootarr[irand] = vals[samples[irand]]\n",
    "        ## calculate Dstats from bootarr and insert to barr\n",
    "        barr[iboot][0] += jcalc_d12(bootarr[:, 8], bootarr[:, 12])\n",
    "        barr[iboot][1] += jcalc_d12(bootarr[:, 7], bootarr[:, 11])\n",
    "        barr[iboot][2] += jcalc_d12(bootarr[:, 6], bootarr[:, 10])                \n",
    "    return barr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@numba.jit('f4[:,:](i4[:,:], i4[:])', nopython=True)\n",
    "def jtestloop2(vals, rands):\n",
    "    \"\"\" fast numba testloop\"\"\"\n",
    "    ## create empty results array\n",
    "    barr = np.zeros((rands.shape[0], 3), dtype=np.float32)\n",
    "    ## fill array\n",
    "    for iboot in xrange(rands.shape[0]):\n",
    "        #samples = np.random.randint(0, vals.shape[0], vals.shape[0])\n",
    "        ## create empty boot array\n",
    "        bootarr = np.zeros((vals.shape[0], 19), dtype=np.int32)\n",
    "        ## fill the boots array\n",
    "        for irand in xrange(vals.shape[0]):\n",
    "            bootarr[irand] = vals[rands[irand]]\n",
    "        ## calculate Dstats from bootarr and insert to barr\n",
    "        barr[iboot][0] += jcalc_d12(bootarr[:, 8], bootarr[:, 12])\n",
    "        barr[iboot][1] += jcalc_d12(bootarr[:, 7], bootarr[:, 11])\n",
    "        barr[iboot][2] += jcalc_d12(bootarr[:, 6], bootarr[:, 10])                \n",
    "    return barr\n",
    "\n",
    "\n",
    "\n",
    "## call function to get test statistics\n",
    "def jdstat_part(pdf, nboots):\n",
    "    \"\"\" Function to perform bootstrap resampling to measure\n",
    "    significance of partitioned D-statistics. \"\"\"\n",
    "    ## dict to store boot results with column order D12, D1, D2\n",
    "    barr = np.zeros((nboots, 3), dtype=np.float32)\n",
    "    \n",
    "    ## do bootstrap resampling with replacement\n",
    "    for iboot in xrange(nboots):\n",
    "        samples = np.random.randint(0, pdf.shape[0], pdf.shape[0])\n",
    "        bootdf = pd.DataFrame([pdf.loc[i] for i in samples])\n",
    "        barr[iboot] = [calc_d12(bootdf), calc_d1(bootdf), calc_d2(bootdf)]\n",
    "\n",
    "    ## array for full data results\n",
    "    rarr = np.zeros((9,), dtype=np.float16)\n",
    "    rarr[0:3] = [calc_d12(pdf), calc_d1(pdf), calc_d2(pdf)]\n",
    "    rarr[3:6] = [barr]\n",
    "\n",
    "\n",
    "    results[\"D_12\"] = calc_d12(pdf)\n",
    "    results[\"D_1\"] = calc_d1(pdf)\n",
    "    results[\"D_2\"] = calc_d2(pdf)\n",
    "    \n",
    "    ## get standard deviation & Z from boots\n",
    "    results[\"D12sd\"] = np.std(boots[\"D12\"])\n",
    "    results[\"Z12\"] = abs(results[\"D_12\"])/float(results[\"D12sd\"])\n",
    "    results[\"D1sd\"] = np.std(boots[\"D1\"])\n",
    "    results[\"Z1\"] = abs(results[\"D_1\"])/float(results[\"D1sd\"])\n",
    "    results[\"D2sd\"] = np.std(boots[\"D2\"])\n",
    "    results[\"Z2\"] = abs(results[\"D_2\"])/float(results[\"D2sd\"])\n",
    "    return pd.Series(results)\n",
    "\n",
    "\n",
    "\n",
    "## Functions to calculate partitioned D-statistics\n",
    "def calc_d12(pdf):\n",
    "    \"\"\" D12 calc for fixed differences from pdf (pandas data frame)\"\"\"\n",
    "    return sum(pdf.ABBBA-pdf.BABBA)/float(sum(pdf.ABBBA+pdf.BABBA))\n",
    "\n",
    "def calc_d1(pdf):\n",
    "    \"\"\" D1 calc for fixed differences from pdf (pandas data frame)\"\"\"    \n",
    "    return sum(pdf.ABBAA-pdf.BABAA)/float(sum(pdf.ABBAA+pdf.BABAA))\n",
    "\n",
    "def calc_d2(pdf):\n",
    "    \"\"\" D2 calc for fixed differences from pdf (pandas data frame)\"\"\"        \n",
    "    return sum(pdf.ABABA-pdf.BAABA)/float(sum(pdf.ABABA+pdf.BAABA))\n",
    "\n",
    "\n",
    "\n",
    "## Functions to calculate D-foil\n",
    "def calc_dfo(pdf): \n",
    "    \"\"\" DFO calc for fixed differences from pdf \"\"\"\n",
    "    nleft = pdf.BABAA+pdf.BBBAA+pdf.ABABA+pdf.AAABA\n",
    "    nright = pdf.BAABA+pdf.BBABA+pdf.ABBAA+pdf.AABAA\n",
    "    return sum(nleft-nright)/float(sum(nleft+nright))\n",
    "\n",
    "def calc_dil(pdf):\n",
    "    \"\"\" DIL calc for fixed differences from pdf \"\"\"\n",
    "    nleft = pdf.ABBAA+pdf.BBBAA+pdf.BAABA+pdf.AAABA\n",
    "    nright = pdf.ABABA+pdf.BBABA+pdf.BABAA+pdf.AABAA\n",
    "    return sum(nleft-nright)/float(sum(nleft+nright))\n",
    "    \n",
    "def calc_dfi(pdf):\n",
    "    \"\"\" DFI calc for fixed differences from pdf \"\"\"    \n",
    "    nleft = pdf.BABAA+pdf.BABBA+pdf.ABABA+pdf.ABAAA\n",
    "    nright = pdf.ABBAA+pdf.ABBBA+pdf.BAABA+pdf.BAAAA\n",
    "    return sum(nleft-nright)/float(sum(nleft+nright))\n",
    "\n",
    "def calc_dol(pdf):\n",
    "    \"\"\" DOL calc for fixed differences from pdf \"\"\"        \n",
    "    nleft = pdf.BAABA+pdf.BABBA+pdf.ABBAA+pdf.ABAAA\n",
    "    nright = pdf.ABABA+pdf.ABBBA+pdf.BABAA+pdf.BAAAA\n",
    "    return sum(nleft-nright)/float(sum(nleft+nright))\n",
    "\n",
    "\n",
    "\n",
    "## call function to get test statistics\n",
    "def dstat_part(pdf, nboots):\n",
    "    \"\"\" Function to perform bootstrap resampling to measure\n",
    "    significance of partitioned D-statistics. \"\"\"\n",
    "    ## dict to store boot results with column order D12, D1, D2\n",
    "    barr = np.zeros((nboots, 3), dtype=np.float16)\n",
    "    \n",
    "    ## do bootstrap resampling with replacement\n",
    "    for iboot in xrange(nboots):\n",
    "        samples = np.random.randint(0, pdf.shape[0], pdf.shape[0])\n",
    "        bootdf = pd.DataFrame([pdf.loc[i] for i in samples])\n",
    "        barr[iboot] = [calc_d12(bootdf), calc_d1(bootdf), calc_d2(bootdf)]\n",
    "\n",
    "    ## array for full data results\n",
    "    rarr = np.zeros((9,), dtype=np.float16)\n",
    "    rarr[0:3] = [calc_d12(pdf), calc_d1(pdf), calc_d2(pdf)]\n",
    "    rarr[3:6] = [barr]\n",
    "\n",
    "\n",
    "    results[\"D_12\"] = calc_d12(pdf)\n",
    "    results[\"D_1\"] = calc_d1(pdf)\n",
    "    results[\"D_2\"] = calc_d2(pdf)\n",
    "    \n",
    "    ## get standard deviation & Z from boots\n",
    "    results[\"D12sd\"] = np.std(boots[\"D12\"])\n",
    "    results[\"Z12\"] = abs(results[\"D_12\"])/float(results[\"D12sd\"])\n",
    "    results[\"D1sd\"] = np.std(boots[\"D1\"])\n",
    "    results[\"Z1\"] = abs(results[\"D_1\"])/float(results[\"D1sd\"])\n",
    "    results[\"D2sd\"] = np.std(boots[\"D2\"])\n",
    "    results[\"Z2\"] = abs(results[\"D_2\"])/float(results[\"D2sd\"])\n",
    "    return pd.Series(results)\n",
    "\n",
    "\n",
    "\n",
    "def dstat_foil(pdf, nboots):\n",
    "    \"\"\" Function to perform boostrap resampling on Dfoil stats \"\"\"    \n",
    "    ## dict to store results\n",
    "    results = {}\n",
    "    \n",
    "    ## dict to store bootstrap reps\n",
    "    boots = {\"DFO\": [], \n",
    "             \"DIL\": [],\n",
    "             \"DFI\": [],\n",
    "             \"DOL\": []}\n",
    "    \n",
    "    ## do bootstrap resampling with replacement\n",
    "    for _ in xrange(nboots):\n",
    "        samples = np.random.randint(0, len(pdf), len(pdf))\n",
    "        bootdf = pd.DataFrame([pdf.loc[i] for i in samples])\n",
    "        boots[\"DFO\"].append(calc_dfo(bootdf))\n",
    "        boots[\"DIL\"].append(calc_dil(bootdf))\n",
    "        boots[\"DFI\"].append(calc_dfi(bootdf))\n",
    "        boots[\"DOL\"].append(calc_dol(bootdf))\n",
    "        \n",
    "    ## calculate on full data\n",
    "    results[\"DFO\"] = calc_dfo(pdf)\n",
    "    results[\"DIL\"] = calc_dil(pdf)\n",
    "    results[\"DFI\"] = calc_dfi(pdf)\n",
    "    results[\"DOL\"] = calc_dol(pdf)\n",
    "    \n",
    "    ## get standard deviation & Z from boots\n",
    "    results[\"DFOsd\"] = np.std(boots[\"DFO\"])\n",
    "    results[\"Z_DFO\"] = abs(results[\"DFO\"])/float(results[\"DFOsd\"])\n",
    "    results[\"DILsd\"] = np.std(boots[\"DIL\"])\n",
    "    results[\"Z_DIL\"] = abs(results[\"DIL\"])/float(results[\"DILsd\"])            \n",
    "    results[\"DFIsd\"] = np.std(boots[\"DFI\"])\n",
    "    results[\"Z_DFI\"] = abs(results[\"DFI\"])/float(results[\"DFIsd\"])\n",
    "    results[\"DOLsd\"] = np.std(boots[\"DOL\"])\n",
    "    results[\"Z_DOL\"] = abs(results[\"DOL\"])/float(results[\"DOLsd\"])    \n",
    "    return pd.Series(results)\n",
    "\n",
    "\n",
    "## Functions to calculate Dfoil with chi-square test \"\"\"\n",
    "def x_dfo(pdf):\n",
    "    \"\"\" calculate DFO significance by chi-square test \"\"\"\n",
    "    nleft = [pdf.BABAA[i]+pdf.BBBAA[i]+pdf.ABABA[i]+pdf.AAABA[i] \\\n",
    "              for i in range(len(pdf))]\n",
    "    nright = [pdf.BAABA[i]+pdf.BBABA[i]+pdf.ABBAA[i]+pdf.AABAA[i] \\\n",
    "              for i in range(len(pdf))] \n",
    "    getd = [(i-j)/float(i+j) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    xstat = [((i-j)**2/float(i+j)) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    sig = [1.-scipy.stats.chi2.cdf(x, 1) for x in xstat]\n",
    "    return [np.mean(getd), np.std(getd), np.mean(sig)]\n",
    "    \n",
    "\n",
    "def x_dil(pdf):\n",
    "    \"\"\" calculate DIL significance by chi-square test \"\"\"\n",
    "    nleft = [pdf.ABBAA[i]+pdf.BBBAA[i]+pdf.BAABA[i]+pdf.AAABA[i] \\\n",
    "              for i in xrange(len(pdf))]\n",
    "    nright = [pdf.ABABA[i]+pdf.BBABA[i]+pdf.BABAA[i]+pdf.AABAA[i] \\\n",
    "              for i in xrange(len(pdf))]\n",
    "    getd = [(i-j)/float(i+j) if (i+j) > 0 else 0 for \\\n",
    "            i, j in zip(nleft, nright)]\n",
    "    xstat = [((i-j)**2/float(i+j)) if (i+j) > 0 else 0 for \\\n",
    "            i, j in zip(nleft, nright)]\n",
    "    sig = [1.-scipy.stats.chi2.cdf(x, 1) for x in xstat]\n",
    "    return [np.mean(getd), np.std(getd), np.mean(sig)]\n",
    "\n",
    "\n",
    "def x_dfi(pdf):\n",
    "    \"\"\" calculate DFI significane by chi-square test \"\"\"\n",
    "    nleft = [pdf.BABAA[i]+pdf.BABBA[i]+pdf.ABABA[i]+pdf.ABAAA[i] \\\n",
    "              for i in xrange(len(pdf))]\n",
    "    nright = [pdf.ABBAA[i]+pdf.ABBBA[i]+pdf.BAABA[i]+pdf.BAAAA[i] \\\n",
    "              for i in xrange(len(pdf))]\n",
    "    getd = [(i-j)/float(i+j) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    xstat = [((i-j)**2/float(i+j)) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    sig = [1.-scipy.stats.chi2.cdf(x, 1) for x in xstat]\n",
    "    return [np.mean(getd), np.std(getd), np.mean(sig)]\n",
    "\n",
    "    \n",
    "def x_dol(pdf):\n",
    "    \"\"\" calculate DOL significance by chi-square test \"\"\"\n",
    "    nleft = [pdf.BAABA[i]+pdf.BABBA[i]+pdf.ABBAA[i]+pdf.ABAAA[i] \\\n",
    "              for i in xrange(len(pdf))]\n",
    "    nright = [pdf.ABABA[i]+pdf.ABBBA[i]+pdf.BABAA[i]+pdf.BAAAA[i] \\\n",
    "               for i in xrange(len(pdf))]\n",
    "    getd = [(i-j)/float(i+j) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    xstat = [((i-j)**2/float(i+j)) if (i+j) > 0 else 0 for \\\n",
    "             i, j in zip(nleft, nright)]\n",
    "    sig = [1.-scipy.stats.chi2.cdf(x, 1) for x in xstat]\n",
    "    return [np.mean(getd), np.std(getd), np.mean(sig)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loci2pdf(loci, where=None, ntotal=None):\n",
    "    \"\"\" takes ms output file created using dfoil_sim.py and \n",
    "    creates a table of site counts similar to what the dfoil_sim.py\n",
    "    script attempts to do, but correctly. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loci : list\n",
    "        list of loci \n",
    "    ntotal : int\n",
    "        total number of sites simulated, since ms does not output \n",
    "        invariant sites this is needed to calc AAAAA\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas.Dataframe\n",
    "        A DataFrame with results\n",
    "\n",
    "    \"\"\"\n",
    "    ## site patterns\n",
    "    sitep = [\"total\",\n",
    "             \"AAAAA\", \"AAABA\", \"AABAA\", \"AABBA\",\n",
    "             \"ABAAA\", \"ABABA\", \"ABBAA\", \"ABBBA\",\n",
    "             \"BAAAA\", \"BAABA\", \"BABAA\", \"BABBA\",\n",
    "             \"BBAAA\", \"BBABA\", \"BBBAA\", \"BBBBA\", \"locID\", \"pos\"]\n",
    "\n",
    "    ## Create DataFrame\n",
    "    lcounts = pd.DataFrame(0, columns=sitep, \n",
    "                              index=xrange(loci.shape[0]), \n",
    "                              dtype=np.int32)\n",
    "    ## counter for position\n",
    "    pos = 0\n",
    "    lcounts[\"locID\"] = where\n",
    "    ## iterate over loci\n",
    "    for iloc in xrange(loci.shape[0]):\n",
    "        ## get real length \n",
    "        ntotal = loci[iloc][0].astype(\"S1\").tostring().find('9')\n",
    "        ## get site patterns in this locus\n",
    "        counts = loci[iloc][:][:, :ntotal].astype(\"S1\")\n",
    "        ## for each site in this locus\n",
    "        counts[counts == '0'] = 'B'        \n",
    "        counts[counts == '1'] = 'A'\n",
    "        for site in counts.T:\n",
    "            #print(site)\n",
    "            if site[-1] not in ['9', 'B']:\n",
    "                lcounts[site.tostring()][iloc] += 1\n",
    "        ## fill in meta info\n",
    "        #lcounts[\"AAAAx\"][iloc] = ntotal-lcounts.iloc[iloc].values.sum()\n",
    "        lcounts[\"total\"][iloc] = ntotal\n",
    "        lcounts[\"pos\"][iloc] = int(pos)\n",
    "        #lcounts[\"loc\"][iloc] = int(iloc)\n",
    "        pos += ntotal\n",
    "    i = 0\n",
    "    while os.path.exists(\n",
    "            os.path.join(\n",
    "              os.path.curdir, \"dstat_%s.csv\") % i):\n",
    "        i += 1        \n",
    "    handle = os.path.join(os.path.curdir, \"dstat_%s.csv\") % i\n",
    "    lcounts.to_csv(handle, sep=\"\\t\")\n",
    "    return lcounts\n",
    "\n",
    "\n",
    "def ms2loci(handle, maxlen=200):\n",
    "    \"\"\" converts ms output file to loci list \"\"\"\n",
    "    ## read in the input file\n",
    "    with open(handle, 'r') as infile:\n",
    "        indata = infile.read()\n",
    "\n",
    "    ## split by locus, skip first chunk which contains ms code and random seeds\n",
    "    loci = indata.strip().split(\"//\")[1:]\n",
    "    farr = np.ones((len(loci), 5, maxlen), dtype=\"int8\")\n",
    "\n",
    "    ## iterate\n",
    "    for iloc in xrange(farr.shape[0]):\n",
    "        arr = np.int8([list(j) for j in loci[iloc].strip().split(\"\\n\")[2:]])\n",
    "        farr[iloc][:, :arr.shape[1]] = arr\n",
    "    return farr\n",
    "\n",
    "\n",
    "\n",
    "## convert loci file to binary loci list\n",
    "def loci2loci(handle, taxonlist, maxlen=200):\n",
    "    \"\"\" converts loci file to a binary loci list \"\"\"\n",
    "    ## read in the input file\n",
    "    with open(handle, 'r') as infile:\n",
    "        indata = infile.read()\n",
    "\n",
    "    ## split on \"//\" for legacy compatibility\n",
    "    loci = indata.strip().split(\"//\")[:-1]\n",
    "    loci[0] = \" \\n\" + loci[0]\n",
    "\n",
    "    ## create emtpy array to fill\n",
    "    nloci = len(loci)\n",
    "    farr = np.ones((nloci, 5, maxlen), dtype=\"int8\")\n",
    "    taxc = np.zeros((nloci,))\n",
    "\n",
    "    ## iterate over loci to find those which have taxon sampling\n",
    "    for iloc in xrange(nloci):\n",
    "        lines = loci[iloc].split(\"\\n\", 1)[1].split()\n",
    "        names = [i[1:] for i in lines[::2]]\n",
    "        seqs = np.array([list(i) for i in lines[1::2]])\n",
    "        seqlen = seqs.shape[1]\n",
    "\n",
    "        taxi = sum([i in names for i in taxonlist])\n",
    "        taxc[iloc] += taxi\n",
    "        if taxi == len(taxonlist):\n",
    "            arr = np.zeros((5, maxlen), dtype=\"int8\")\n",
    "            ## fill outgroup with 1s\n",
    "            arr[-1].fill(1)\n",
    "            ## fill fake data columns with 9s\n",
    "            arr[:, seqlen-maxlen:].fill(9)\n",
    "\n",
    "            ## get outgroup values\n",
    "            outvals = seqs[names.index(taxonlist[4])]\n",
    "            for itax in xrange(4):\n",
    "                tmparr = np.int8(seqs[names.index(taxonlist[itax])] == outvals)\n",
    "                arr[itax][:tmparr.shape[0]] = tmparr\n",
    "            farr[iloc] = arr\n",
    "\n",
    "    ## warn if no SNPs are found\n",
    "    ## warn if no loci have sampling of all taxa\n",
    "\n",
    "    print(np.histogram(taxc, range(7)))\n",
    "    ## return array that includes np.ones for loci w/o taxa\n",
    "    return farr[taxc == len(taxonlist)], taxc\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## test input files\n",
    "    # MSFILE = \"/home/deren/Dropbox/dfoiled_copy/\" \\\n",
    "    #         +\"mysim_3_1_L10000_W100_test.sites.ms.tmp\"\n",
    "    LOCIFILE = \"/home/deren/Dropbox/RADexplore/EmpVib/\" \\\n",
    "              +\"vib_half_64tip_c85d6m4p99.loci\"\n",
    "\n",
    "    # ## taxon list to parse from LOCIFILE\n",
    "    TAXONLIST = ['acutifolium_DRY3_MEX_006', \n",
    "                 'sulcatum_D9_MEX_003', \n",
    "                 'jamesonii_D12_PWS_1636', \n",
    "                 'triphyllum_D13_PWS_1783',\n",
    "                 'dentatum_ELS4']\n",
    "    \n",
    "    # ## get binary loci list from file\n",
    "    # LOCI = ms2loci(MSFILE)\n",
    "    # #print(LOCI)\n",
    "    # PDF = loci2pdf(LOCI, 100)\n",
    "    # print(PDF)\n",
    "    # NBOOTS = 100\n",
    "    # RANDS = np.random.randint(0, NBOOTS, NBOOTS).astype(np.int32)\n",
    "    # #print(dstat_part(PDF, nboots=100))\n",
    "    # #print(dstat_foil(PDF, nboots=100))    \n",
    "\n",
    "\n",
    "    # sys.exit()\n",
    "    LOCI = loci2loci(LOCIFILE, TAXONLIST)\n",
    "    print(LOCI.shape)\n",
    "    print(LOCI[:2])\n",
    "\n",
    "    # ## get data frame of site counts by loci\n",
    "    NTOTAL = 100\n",
    "    PDF = loci2pdf(LOCI, NTOTAL)\n",
    "    # print(PDF)\n",
    "\n",
    "    ## calculate dstats\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSFILE = \"/home/deren/Dropbox/dfoiled_copy/\" \\\n",
    "            +\"mysim_3_1_L10000_W100_test.sites.ms.tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test loci file  \n",
    "LOCIFILE = \"/home/deren/Dropbox/RADexplore/EmpVib/\" \\\n",
    "          +\"vib_half_64tip_c85d6m4p99.loci\"\n",
    "\n",
    "## taxon list to parse from LOCIFILE\n",
    "TAXONLIST = ['acutifolium_DRY3_MEX_006', \n",
    "             'sulcatum_D9_MEX_003', \n",
    "             'jamesonii_D12_PWS_1636', \n",
    "             'triphyllum_D13_PWS_1783',\n",
    "             'dentatum_ELS4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse ms file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms 5 10000 -t 2.8 -I 5 1 1 1 1 1 -ej 0.5 2 1 -ej 0.5 4 3 -ej 1.0 3 1 -ej 1.5 5 1 -em 0.25 1 3 5e-05 -eM 0.2 0 \r\n",
      "31869 36848 37157\r\n",
      "\r\n",
      "//\r\n",
      "segsites: 20\r\n",
      "positions: 0.0031 0.0244 0.1230 0.1290 0.1293 0.1793 0.2310 0.2690 0.2692 0.3604 0.3688 0.4768 0.5175 0.6129 0.6662 0.7199 0.7221 0.8945 0.9315 0.9703 \r\n",
      "00000010100100100000\r\n",
      "00000000100110010000\r\n",
      "10101101010000000111\r\n",
      "00101000000000001110\r\n",
      "01010000001001000000\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 11 $MSFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total  AAAAA  AAABA  AABAA  AABBA  ABAAA  ABABA  ABBAA  ABBBA  BAAAA  \\\n",
      "0    100     84      1      5      4      2      0      0      0      2   \n",
      "1    100     90      2      1      0      3      0      0      0      4   \n",
      "2    100     85      6      2      1      2      0      0      0      1   \n",
      "3    100     83      3      2      1      4      0      0      0      6   \n",
      "4    100     84      5      3      0      1      0      0      0      1   \n",
      "\n",
      "   BAABA  BABAA  BABBA  BBAAA  BBABA  BBBAA  BBBBA  pos  \n",
      "0      0      0      0      2      0      0      0    0  \n",
      "1      0      0      0      0      0      0      0  100  \n",
      "2      0      0      0      2      0      0      1  200  \n",
      "3      0      0      0      0      0      0      1  300  \n",
      "4      0      0      0      1      0      0      5  400  \n"
     ]
    }
   ],
   "source": [
    "#LOCI = ms2loci(MSFILE)\n",
    "#print(LOCI)\n",
    "\n",
    "#PDF = loci2pdf(LOCI, 100)\n",
    "print(PDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse loci file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([66512, 29493, 22204, 11580,  3739,   643]), array([0, 1, 2, 3, 4, 5, 6]))\n"
     ]
    }
   ],
   "source": [
    "#mloci = ms2loci(MSFILE, 100)\n",
    "lloci, taxc = loci2loci(LOCIFILE, TAXONLIST)\n",
    "#PDF = loci2pdf(LOCI, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int8)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCI[0][:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = LOCI.astype(\"S1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 5, 200)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9'],\n",
       "       ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9'],\n",
       "       ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9'],\n",
       "       ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9'],\n",
       "       ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "        '1', '1', '1', '1', '1', '1', '1', '1', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "        '9', '9', '9', '9', '9']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 5)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(chars ==\"9\", axis=2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is marking \"N-RKSWY\" columns as '9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqs = np.array([\n",
    "        list(\"CAAGATTCTGC----ATTAATCAAG------TTGAC\"),\n",
    "        list(\"CAAGATTCTGC----ATTAATCAAG------TTGAC\"),\n",
    "        list(\"CTAGATTCTGC----ATTAAGCAAG------TTTAC\"),\n",
    "        list(\"CAAGATTCTGC----ATTAATCAAG------TTTAC\"),\n",
    "        list(\"CAACATTCTGC----ATTAATCAAG------TTTAC\")        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'A' 'A' 'G' 'A' 'T' 'T' 'C' 'T' 'G' 'C' '-' '-' '-' '-' 'A' 'T' 'T'\n",
      "  'A' 'A' 'T' 'C' 'A' 'A' 'G' '-' '-' '-' '-' '-' '-' 'T' 'T' 'G' 'A' 'C']\n",
      " ['C' 'A' 'A' 'G' 'A' 'T' 'T' 'C' 'T' 'G' 'C' '-' '-' '-' '-' 'A' 'T' 'T'\n",
      "  'A' 'A' 'T' 'C' 'A' 'A' 'G' '-' '-' '-' '-' '-' '-' 'T' 'T' 'G' 'A' 'C']\n",
      " ['C' 'T' 'A' 'G' 'A' 'T' 'T' 'C' 'T' 'G' 'C' '-' '-' '-' '-' 'A' 'T' 'T'\n",
      "  'A' 'A' 'G' 'C' 'A' 'A' 'G' '-' '-' '-' '-' '-' '-' 'T' 'T' 'T' 'A' 'C']\n",
      " ['C' 'A' 'A' 'G' 'A' 'T' 'T' 'C' 'T' 'G' 'C' '-' '-' '-' '-' 'A' 'T' 'T'\n",
      "  'A' 'A' 'T' 'C' 'A' 'A' 'G' '-' '-' '-' '-' '-' '-' 'T' 'T' 'T' 'A' 'C']\n",
      " ['C' 'A' 'A' 'C' 'A' 'T' 'T' 'C' 'T' 'G' 'C' '-' '-' '-' '-' 'A' 'T' 'T'\n",
      "  'A' 'A' 'T' 'C' 'A' 'A' 'G' '-' '-' '-' '-' '-' '-' 'T' 'T' 'T' 'A' 'C']]\n",
      "[[1 1 1 0 1 1 1 1 1 1 1 9 9 9 9 1 1 1 1 1 1 1 1 1 1 9 9 9 9 9 9 1 1 0 1 1 9\n",
      "  9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [1 1 1 0 1 1 1 1 1 1 1 9 9 9 9 1 1 1 1 1 1 1 1 1 1 9 9 9 9 9 9 1 1 0 1 1 9\n",
      "  9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [1 0 1 0 1 1 1 1 1 1 1 9 9 9 9 1 1 1 1 1 0 1 1 1 1 9 9 9 9 9 9 1 1 1 1 1 9\n",
      "  9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [1 1 1 0 1 1 1 1 1 1 1 9 9 9 9 1 1 1 1 1 1 1 1 1 1 9 9 9 9 9 9 1 1 1 1 1 9\n",
      "  9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 9\n",
      "  9 9 9 9 9 9 9 9 9 9 9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros((5, 50), dtype=\"int8\")\n",
    "arr[-1].fill(1)\n",
    "arr[:, len(seqs[0])-50:].fill(9)\n",
    "print(seqs)\n",
    "outvals = seqs[-1]\n",
    "\n",
    "\n",
    "for itax in xrange(4):\n",
    "    tmparr = np.int8(seqs[itax] == outvals)\n",
    "    for val in list(\"N-RKSWY\"):\n",
    "        tmparr[np.where(seqs[-1]==val)] = 9\n",
    "    arr[itax][:tmparr.shape[0]] = tmparr\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is getting rid of '9' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 50)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr = np.array([arr, arr, arr, arr, arr])\n",
    "farr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]]], dtype=int8)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr[..., :, np.any(farr[0] != 9, axis=0).astype(np.int8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']],\n",
       "\n",
       "       [['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']],\n",
       "\n",
       "       [['1', '1', '1', ..., '1', '1', '0'],\n",
       "        ['1', '1', '1', ..., '1', '1', '0'],\n",
       "        ['1', '1', '1', ..., '1', '1', '0'],\n",
       "        ['1', '1', '1', ..., '1', '1', '0'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']],\n",
       "\n",
       "       ..., \n",
       "       [['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']],\n",
       "\n",
       "       [['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']],\n",
       "\n",
       "       [['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1'],\n",
       "        ['1', '1', '1', ..., '1', '1', '1']]], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[..., :, np.any(chars[0] !=\"9\", axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   119,    269,    449,    482,    525,   1078,   1745,   2012,\n",
       "         2470,   2903,   3154,   3760,   3791,   3830,   4059,   4255,\n",
       "         4640,   4931,   5424,   5873,   5983,   6107,   6476,   6545,\n",
       "         6653,   7100,   7161,   7479,   7713,   7933,   7970,   8106,\n",
       "         8862,   8893,   8905,   9256,   9458,  10106,  10110,  10414,\n",
       "        10576,  10618,  10659,  10668,  10765,  10780,  10933,  11283,\n",
       "        11652,  11722,  11801,  11803,  12011,  12365,  12502,  12747,\n",
       "        12865,  12965,  12983,  13403,  13609,  13750,  14001,  14518,\n",
       "        14529,  15127,  15135,  15227,  15483,  15572,  16852,  16934,\n",
       "        17114,  17240,  17339,  17427,  17456,  17605,  17972,  18099,\n",
       "        18311,  18727,  18759,  18837,  18983,  19471,  19657,  19875,\n",
       "        20123,  20318,  20353,  20406,  21095,  21110,  21363,  21458,\n",
       "        21912,  21998,  22240,  23042,  23422,  23702,  23857,  23928,\n",
       "        24104,  24286,  24296,  24455,  24553,  24749,  24757,  24908,\n",
       "        25064,  25272,  25780,  26285,  26324,  26479,  26797,  27321,\n",
       "        27550,  27822,  28059,  28177,  28221,  28525,  28688,  29256,\n",
       "        29395,  29474,  30287,  30446,  30653,  31279,  31363,  31386,\n",
       "        31391,  31716,  31723,  31739,  32024,  32069,  32845,  32941,\n",
       "        33074,  33098,  33136,  33202,  33258,  33708,  33735,  33992,\n",
       "        34047,  34177,  34427,  34485,  34632,  34695,  34756,  35153,\n",
       "        35159,  35374,  35464,  35736,  35787,  35846,  35948,  35981,\n",
       "        36162,  36325,  36774,  36792,  36815,  36945,  37244,  37461,\n",
       "        37992,  38290,  38390,  38951,  39120,  39132,  39273,  39280,\n",
       "        39732,  39743,  40062,  40372,  40625,  40631,  40643,  40971,\n",
       "        41130,  41184,  41257,  41441,  41596,  41891,  41920,  41957,\n",
       "        42078,  42086,  42468,  42575,  42822,  42979,  43155,  43365,\n",
       "        43418,  43501,  43516,  44179,  44286,  44314,  44316,  44899,\n",
       "        45043,  45359,  45450,  45459,  45633,  45829,  45895,  46037,\n",
       "        46070,  46090,  46096,  46151,  46278,  46616,  46619,  47100,\n",
       "        47122,  47213,  47233,  47485,  47588,  47752,  48108,  48155,\n",
       "        48718,  49557,  50033,  50118,  50239,  50407,  50957,  51133,\n",
       "        51371,  51450,  51554,  51660,  51730,  51860,  51967,  52126,\n",
       "        52239,  52430,  52431,  52731,  53040,  53390,  53749,  54062,\n",
       "        54284,  54420,  54426,  54981,  55610,  55978,  56840,  57011,\n",
       "        57031,  57067,  57093,  57394,  57536,  57594,  57651,  58132,\n",
       "        58281,  58362,  58486,  58786,  59293,  59488,  59517,  59559,\n",
       "        59684,  59692,  60012,  60170,  60442,  60496,  61107,  61115,\n",
       "        61211,  61482,  61656,  61953,  62051,  62171,  62494,  62683,\n",
       "        62813,  62871,  62942,  63124,  63421,  63665,  63821,  64382,\n",
       "        65029,  65180,  65183,  65352,  65439,  66084,  66143,  66177,\n",
       "        66262,  66571,  66601,  66783,  67584,  67817,  67946,  67951,\n",
       "        67989,  68465,  69167,  69207,  69772,  69785,  69799,  69857,\n",
       "        69924,  70133,  70238,  70351,  70658,  70916,  71417,  71428,\n",
       "        71481,  71548,  71614,  71952,  72141,  72190,  72305,  72400,\n",
       "        72598,  73007,  73395,  73497,  73557,  73630,  73636,  73777,\n",
       "        73840,  74336,  74338,  74657,  74681,  74698,  74745,  74789,\n",
       "        74826,  74898,  74982,  75606,  75901,  75905,  76147,  76349,\n",
       "        76640,  76669,  77268,  77339,  77538,  78150,  78887,  78941,\n",
       "        78962,  79280,  79492,  79658,  79664,  79748,  79925,  80007,\n",
       "        80065,  80820,  80851,  81174,  81237,  81376,  81388,  81520,\n",
       "        82102,  82300,  82856,  83042,  83446,  83535,  83639,  83656,\n",
       "        83787,  83913,  84009,  84248,  84273,  84328,  84697,  84737,\n",
       "        85525,  85827,  85897,  86019,  86046,  86177,  86565,  86596,\n",
       "        86618,  87041,  87210,  87586,  87759,  87808,  88260,  88304,\n",
       "        88578,  89099,  89335,  89681,  90107,  90116,  90756,  91003,\n",
       "        91081,  91117,  91649,  91656,  91844,  92169,  92202,  92309,\n",
       "        92843,  93280,  94071,  94189,  94493,  94576,  94582,  95079,\n",
       "        95238,  95612,  95681,  95751,  95759,  95895,  96122,  96142,\n",
       "        96206,  96308,  96372,  96464,  96746,  96862,  96914,  97108,\n",
       "        97373,  97646,  97735,  97931,  98618,  98769,  98932,  99185,\n",
       "        99189,  99858, 100197, 100456, 100483, 100829, 100864, 101565,\n",
       "       101600, 101695, 101781, 101793, 101876, 102565, 102663, 102674,\n",
       "       102745, 102795, 102821, 102867, 103462, 104313, 104380, 104886,\n",
       "       104916, 105041, 105067, 105111, 105779, 105808, 106527, 106831,\n",
       "       107702, 107759, 107834, 107940, 108117, 108353, 108532, 108906,\n",
       "       108947, 109317, 109326, 109429, 109624, 109835, 110052, 110084,\n",
       "       110156, 110336, 110384, 110483, 110965, 111034, 111405, 111535,\n",
       "       111665, 111677, 112278, 112356, 112388, 112409, 112448, 112507,\n",
       "       112780, 112981, 113219, 113589, 113733, 113776, 114023, 114042,\n",
       "       114519, 114776, 114883, 114975, 115448, 115639, 116349, 116394,\n",
       "       116608, 117171, 118051, 118195, 118281, 118628, 118971, 118995,\n",
       "       119044, 119063, 119147, 119424, 119516, 119611, 119971, 120086,\n",
       "       120166, 120319, 121029, 121055, 121357, 121502, 121669, 121718,\n",
       "       121775, 122378, 122573, 122891, 123589, 123620, 124200, 124226,\n",
       "       124245, 124404, 124450, 124790, 124946, 125152, 125984, 126335,\n",
       "       126366, 126789, 127020, 127066, 127328, 127507, 127653, 127704,\n",
       "       128200, 128249, 129169, 129768, 129882, 129969, 130040, 130150,\n",
       "       130244, 130295, 130476, 130697, 130733, 131009, 131047, 131073,\n",
       "       131231, 131297, 131928, 131936, 132072, 132269, 132303, 132348,\n",
       "       132637, 132647, 132664, 132702, 132718, 132872, 133053, 133180,\n",
       "       133505, 133818, 134101])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(taxc==5)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for loc in xrange(1):#mloci.shape[0]):\n",
    "    mloci[loc] = np.array([mloci[loc] == 0]).astype(np.int8)\n",
    "    mloci\n",
    "    print(mloci[loc])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 100)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mloci.shape\n",
    "#np.all(mloci > 0, axis=2)\n",
    "#mloci[mloci[:,:,:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 1, 1, 1, 9],\n",
    "              [1, 1, 1, 1, 9],\n",
    "              [1, 1, 1, 1, 9],\n",
    "              [1, 1, 1, 1, 2],\n",
    "              [9, 9, 9, 9, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loci2loci(handle, taxonlist, maxlen=200):\n",
    "    \"\"\" converts loci file to a binary loci list \"\"\"\n",
    "    ## read in the input file\n",
    "    with open(handle, 'r') as infile:\n",
    "        indata = infile.read()\n",
    "\n",
    "    ## split on \"//\" for legacy compatibility\n",
    "    loci = indata.strip().split(\"//\")[:-1]\n",
    "    loci[0] = \" \\n\" + loci[0]\n",
    "\n",
    "    ## create emtpy array to fill\n",
    "    nloci = len(loci)\n",
    "    farr = np.ones((nloci, 5, maxlen), dtype=\"int8\")\n",
    "    taxc = np.zeros((nloci,))\n",
    "\n",
    "    ## iterate over loci to find those which have taxon sampling\n",
    "    for iloc in xrange(nloci):\n",
    "        lines = loci[iloc].split(\"\\n\", 1)[1].split()\n",
    "        names = [i[1:] for i in lines[::2]]\n",
    "        seqs = np.array([list(i) for i in lines[1::2]])\n",
    "        seqlen = seqs.shape[1]\n",
    "\n",
    "        taxi = sum([i in names for i in taxonlist])\n",
    "        taxc[iloc] += taxi\n",
    "        if taxi == len(taxonlist):\n",
    "            arr = np.zeros((5, maxlen), dtype=\"int8\")\n",
    "            ## fill outgroup with 1s\n",
    "            arr[-1].fill(1)\n",
    "            ## fill fake data columns with 9s\n",
    "            arr[:, seqlen-maxlen:].fill(9)\n",
    "\n",
    "            ## get outgroup values\n",
    "            outvals = seqs[names.index(taxonlist[4])]\n",
    "            for itax in xrange(4):\n",
    "                tmparr = np.int8(seqs[names.index(taxonlist[itax])] == outvals)\n",
    "                arr[itax][:tmparr.shape[0]] = tmparr\n",
    "            farr[iloc] = arr\n",
    "\n",
    "    ## warn if no SNPs are found\n",
    "    ## warn if no loci have sampling of all taxa\n",
    "\n",
    "    print(np.histogram(taxc, range(7)))\n",
    "    ## return array that includes np.ones for loci w/o taxa\n",
    "    return farr[taxc == len(taxonlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([66512, 29493, 22204, 11580,  3739,   643]), array([0, 1, 2, 3, 4, 5, 6]))\n"
     ]
    }
   ],
   "source": [
    "ll = loci2loci(LOCIFILE, TAXONLIST, maxlen=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'B9999'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-c231f7d63fbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mLOCI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mPDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloci2pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOCI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-55aeafbbf244>\u001b[0m in \u001b[0;36mloci2pdf\u001b[1;34m(loci, ntotal)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[0mlcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[1;31m## fill in meta info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mlcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AAAAA\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mntotal\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/deren/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/deren/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/deren/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/deren/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2851\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2852\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2853\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/deren/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method)\u001b[0m\n\u001b[0;32m   1570\u001b[0m         \"\"\"\n\u001b[0;32m   1571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1572\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3824)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3704)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12231)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B9999'"
     ]
    }
   ],
   "source": [
    "LOCI.shape\n",
    "PDF = loci2pdf(LOCI, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
