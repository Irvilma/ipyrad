{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cookbook: abba-baba introgression stats\n",
    "\n",
    "The *ipyrad.analysis* Python module includes functions to calculate abba-baba admixture statistics, as well as several variants of these measures, and to perform signifance tests. The code in this notebook is all Python, which you can copy/paste into an IPython terminal to execute, or, preferably, run in a Jupyter notebook like this one. See the other analysis cookbooks for [instructions](http://ipyrad.readthedocs.io/analysis.html) on using Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing muscle (please be faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "from ipyrad.assemble.cluster_within import *\n",
    "from ipyrad.assemble.write_outfiles import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems to be much faster\n",
    "Test on a real clust.gz file before you spend time incorporating this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def muscle_call(data, names, seqs):\n",
    "    \"\"\"\n",
    "    Makes subprocess call to muscle. A little faster than before.\n",
    "    TODO: Need to make sure this works on super large strings and does not\n",
    "    overload the PIPE buffer.\n",
    "    \"\"\"\n",
    "\n",
    "    ## make input string\n",
    "    inputstr = \"\\n\".join([\"{}\\n{}\".format(i, j) for i, j in zip(names, seqs)])\n",
    "    cmd = [ipyrad.bins.muscle, \"-quiet\"]\n",
    "\n",
    "    ## increase gap penalty if reference region is included\n",
    "    ## This could use more testing/refining!\n",
    "    if \"_REF;+0\" in names:\n",
    "        cmd += [\"-gapopen\", \"-1200\"]\n",
    "\n",
    "    ## make a call arg\n",
    "    proc1 = sps.Popen(cmd, stdin=sps.PIPE, stdout=sps.PIPE, close_fds=True)\n",
    "    ## return result\n",
    "    return proc1.communicate(inputstr)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>A\\nAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGGG\\n>B\\nAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGG\\n>C\\nAAAATTTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGG\\n>D\\nAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGGG'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\">A\", \">B\", \">C\", \">D\"]\n",
    "\n",
    "seqs = [\"AAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGGG\",\n",
    "        \"AAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGG\",\n",
    "        \"AAAATTTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGG\",\n",
    "        \"AAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGGG\"]\n",
    "\n",
    "inputstr = \"\\n\".join([\"{}\\n{}\".format(i, j) for i, j in zip(names, seqs)])\n",
    "\n",
    "m = ipyrad.bins.muscle\n",
    "sss = inputstr\n",
    "sss\n",
    "#! echo -c $inputstr # | m -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.43 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "x = muscle_call(\"\", names, seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import uuid\n",
    "import random\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def newtrick():\n",
    "    MARKER = str(uuid.uuid4())\n",
    "\n",
    "    #shell_command = [ip.bins.muscle, '-quiet'\n",
    "    p = Popen(\"sh\", stdin=PIPE, stdout=PIPE, stderr=STDOUT,\n",
    "              universal_newlines=True) # decode output as utf-8, newline is '\\n'\n",
    "\n",
    "    i = 0\n",
    "    outs = []\n",
    "    while True:\n",
    "        # write next command\n",
    "        shell_command = \"echo '{}'\".format(inputstr)# | {} - \".format(inputstr, ip.bins.muscle)\n",
    "        #print(shell_command)\n",
    "        print(shell_command, file=p.stdin)\n",
    "\n",
    "        # insert MARKER into stdout to separate output from different shell_command\n",
    "        print(\"echo '%s'\" % MARKER, file=p.stdin)\n",
    "\n",
    "        # read command output\n",
    "        for line in iter(p.stdout.readline, MARKER+'\\n'):\n",
    "            if line.endswith(MARKER+'\\n'):\n",
    "                outs.append(line[:-len(MARKER)-1])\n",
    "                break # command output ended without a newline\n",
    "            outs.append(line)\n",
    "        outs.append(\"\\n\")\n",
    "            #print(line, end='')\n",
    "        #print('\\n')\n",
    "\n",
    "        # exit on condition\n",
    "        if i == 100:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "        \n",
    "    # cleanup\n",
    "    p.stdout.close()\n",
    "    if p.stderr:\n",
    "        p.stderr.close()\n",
    "    p.stdin.close()\n",
    "    p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0197730064392\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "newtrick()\n",
    "print(time.time() - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000000000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.007 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Back to baba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## start by loading several Python librarires\n",
    "import ipyrad as ip\n",
    "import ipyrad.analysis as ipa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loading Assembly: cli\n",
      "  from saved path: ~/Documents/ipyrad/tests/cli/cli.json\n"
     ]
    }
   ],
   "source": [
    "data = ip.load_json(\"cli/cli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geno : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.geno\n",
       "loci : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.loci\n",
       "nexus : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.nex\n",
       "phy : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.phy\n",
       "snpsmap : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.snps.map\n",
       "snpsphy : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.snps.phy\n",
       "str : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.str\n",
       "ugeno : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.u.geno\n",
       "usnpsphy : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.u.snps.phy\n",
       "ustr : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.ustr\n",
       "vcf : /home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.vcf\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.read_table(data.outfiles.vcf, comment=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make loci parsing script\n",
    "This takes a .loci file and converts it to an array of the format:\n",
    "\n",
    "(4 or 5, n-variable-loci, maxsnps)\n",
    "e.g., (4, 1000, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = {\n",
    "    'p1': [\"1A_0\", \"1B_0\", \"1C_0\"],\n",
    "    'p2': [\"1D_0\"],\n",
    "    'p3': [\"2E_0\", \"2F_0\"],\n",
    "    'out': [\"3L_0\", \"3J_0\", \"3K_0\"], \n",
    "}\n",
    "\n",
    "mindict = {\n",
    "    'p1': 1,\n",
    "    'p2': 1,\n",
    "    'p3': 1, \n",
    "    'out': 1,\n",
    "}\n",
    "\n",
    "handle = data.outfiles.loci\n",
    "ntips = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def loci_to_arr(locifile, test, mindict=None):\n",
    "\n",
    "    ## read in the input file\n",
    "    with open(locifile, 'r') as infile:\n",
    "        loci = infile.read().strip().split(\"|\\n\")\n",
    "        nloci = len(loci)\n",
    "\n",
    "    ## get max loc length\n",
    "    maxlen = 0\n",
    "    for iloc in xrange(nloci):\n",
    "        lines = loci[iloc].split(\"\\n\")[:-1]\n",
    "        _maxl = len(lines[0]) \n",
    "        maxlen = max(maxlen, _maxl)\n",
    "\n",
    "    ## make the array (4 or 5)\n",
    "    arr = np.zeros((nloci, len(test), maxlen), dtype=np.float64)\n",
    "    \n",
    "    ## if not mindict, make one that requires 1 in each taxon\n",
    "    if not mindict:\n",
    "        mindict = {i:1 for i in test}\n",
    "\n",
    "    ## grab seqs just for the good guys\n",
    "    for loc in xrange(nloci):    \n",
    "\n",
    "        ## parse the locus\n",
    "        lines = loci[loc].split(\"\\n\")[:-1]\n",
    "        names = [i.split()[0] for i in lines]\n",
    "        seqs = np.array([list(i.split()[1]) for i in lines])\n",
    "\n",
    "        ## check that names cover the test\n",
    "        covs = [sum([j in names for j in test[tax]]) >= mindict[tax] for tax in test]\n",
    "        if all(covs):\n",
    "        \n",
    "            ## get that refseq \n",
    "            ref = np.where([i in test['out'] for i in names])[0]\n",
    "            refseq = seqs[ref].view(np.uint8)\n",
    "            ancestral = np.array([reftrick(refseq, GETCONS)[:, 0]])\n",
    "\n",
    "            ## and fill it in\n",
    "            iseq = reffreq(ancestral, refseq, GETCONS)\n",
    "            arr[loc, -1, :iseq.shape[1]] = iseq \n",
    "\n",
    "            ## fill each other tax freq in test\n",
    "            keys = sorted([i for i in test.keys() if i[0] == 'p'])\n",
    "            for tidx, key in enumerate(keys):\n",
    "\n",
    "                ## get idx of names in test tax\n",
    "                nidx = np.where([i in test[key] for i in names])[0]\n",
    "                sidx = seqs[nidx].view(np.uint8)\n",
    "                ## get freq of sidx\n",
    "                iseq = reffreq(ancestral, sidx, GETCONS)\n",
    "                ## fill it in \n",
    "                arr[loc, tidx, :iseq.shape[1]] = iseq\n",
    "\n",
    "    ## size-down array to the number of loci that have taxa for the test\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0.5,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = loci_to_arr(handle, test)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##np.sum(arr[:, 0] * (1.-arr[:, 1]) * arr[:, 2] * (1-arr[:, 3])\n",
    "       \n",
    "    \n",
    "np.seterr(divide=\"ignore\")\n",
    "    \n",
    "aa = arr[:10]\n",
    "\n",
    "top = (aa[:, 0] * (1.-aa[:, 1]) * aa[:, 2] * (1.-aa[:, 3])) - \\\n",
    "((1.-aa[:, 0]) * (aa[:, 1]) * (aa[:, 2]) * (1.-aa[:, 3]))\n",
    "\n",
    "\n",
    "bot = (aa[:, 0] * (1.-aa[:, 1]) * aa[:, 2] * (1.-aa[:, 3])) + \\\n",
    "((1.-aa[:, 0]) * (aa[:, 1]) * (aa[:, 2]) * (1.-aa[:, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top = (arr[:, 0]) * (1.-arr[:, 1]) * (arr[:, 2]) * (1.-arr[:, 3]) - \\\n",
    "(1.-arr[:, 0]) * (arr[:, 1]) * (arr[:, 2]) * (1.-arr[:, 3])\n",
    "\n",
    "bot = (arr[:, 0]) * (1.-arr[:, 1]) * (arr[:, 2]) * (1.-arr[:, 3]) + \\\n",
    "(1.-arr[:, 0]) * (arr[:, 1]) * (arr[:, 2]) * (1.-arr[:, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bot != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.13888888888888903, 3.6388888888888893)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.sum(), bot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.038167938931297746"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(top) / np.sum(bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  0.5, ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]],\n",
       "\n",
       "       [[ 1. ,  0. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  0. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "        [ 1. ,  1. ,  1. , ...,  0. ,  0. ,  0. ]]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[0, 2, 78, 3], :]\n",
    "\n",
    "boot = np.random.randint(0, high=arr.shape[0], size=arr.shape[0])\n",
    "arr[boot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "me = seqs[ref].view(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67, 84, 65, 71, 67, 71, 84, 84, 84, 84, 84, 84, 67, 71, 71, 67, 71,\n",
       "       67, 65, 84, 65, 71, 67, 67, 84, 67, 67, 67, 65, 84, 65, 84, 67, 65,\n",
       "       67, 67, 71, 65, 71, 84, 71, 67, 71, 67, 71, 65, 84, 71, 67, 71, 84,\n",
       "       65, 65, 71, 84, 71, 71, 71, 65, 67, 65, 67, 67, 84, 67, 67, 67, 67,\n",
       "       67, 67, 84, 65, 67, 71, 67, 71, 71, 67, 84, 67, 65], dtype=uint8)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reftrick()\n",
    "ancestral = reftrick(me, GETCONS)[:, 0]\n",
    "ancestral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['C', 'T', 'A', 'G', 'C', 'G', 'T', 'T', 'T', 'T', 'T', 'T', 'C',\n",
       "        'G', 'G', 'C', 'G', 'C', 'A', 'T', 'A', 'G', 'C', 'C', 'T', 'C',\n",
       "        'C', 'C', 'A', 'T', 'A', 'T', 'C', 'A', 'C', 'C', 'G', 'A', 'G',\n",
       "        'T', 'G', 'C', 'G', 'C', 'G', 'A', 'T', 'G', 'C', 'G', 'T', 'A',\n",
       "        'A', 'G', 'T', 'G', 'G', 'G', 'A', 'C', 'A', 'C', 'C', 'T', 'C',\n",
       "        'C', 'C', 'C', 'C', 'C', 'T', 'A', 'C', 'G', 'C', 'G', 'G', 'C',\n",
       "        'T', 'C', 'A'],\n",
       "       ['C', 'T', 'A', 'G', 'C', 'G', 'T', 'T', 'T', 'T', 'T', 'T', 'C',\n",
       "        'G', 'G', 'C', 'G', 'C', 'A', 'T', 'A', 'G', 'C', 'C', 'T', 'C',\n",
       "        'C', 'C', 'A', 'T', 'A', 'T', 'C', 'A', 'C', 'C', 'G', 'A', 'G',\n",
       "        'T', 'G', 'C', 'G', 'C', 'G', 'A', 'T', 'G', 'C', 'G', 'T', 'A',\n",
       "        'A', 'G', 'T', 'G', 'G', 'G', 'A', 'C', 'A', 'C', 'C', 'T', 'C',\n",
       "        'C', 'C', 'C', 'C', 'C', 'T', 'A', 'C', 'G', 'C', 'G', 'G', 'C',\n",
       "        'T', 'C', 'A']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['G', 'G', 'T', 'C', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'M'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'G', 'G', 'T', 'C'],\n",
       "       ['T', 'A', 'G', 'T', 'C'],\n",
       "       ['-', '-', '-', '-', '-']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larr = np.array([list(i.split(\"|\")[0]) for i in lines])\n",
    "getem = np.where(np.all(larr == \" \", axis=0))[0].max()\n",
    "larr[:, getem:]\n",
    "\n",
    "#np.where(larr[-1] == '-' +\\\n",
    "#larr[-1] == \" \"\n",
    "         \n",
    "    \n",
    "## could subselect SNPs but then we still need to do it again after\n",
    "## we subset the taxa, so instead let's just grab all sites.\n",
    "## only drawback is speed and mem, a bit.\n",
    "who = np.where(np.logical_or(larr[-1] == \"-\", larr[-1] == \"*\"))[0]\n",
    "larr[:, who]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'A', '_', ..., 'T', 'C', 'A'],\n",
       "       ['1', 'B', '_', ..., 'T', 'C', 'A'],\n",
       "       ['1', 'C', '_', ..., 'T', 'C', 'A'],\n",
       "       ..., \n",
       "       ['3', 'K', '_', ..., 'T', 'C', 'A'],\n",
       "       ['3', 'L', '_', ..., 'T', 'C', 'A'],\n",
       "       ['/', '/', ' ', ..., ' ', ' ', ' ']], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//                                                       *                                |0\n",
      "[ '1A_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '1B_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '1C_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '1D_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '2E_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '2F_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '2G_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '2H_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '3I_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '3J_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '3K_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '3L_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTAAACGTGGCAGGACCTGTTGGAAAAACACGCAGA'\n",
      " '//                                                       *                                |0']\n",
      "//                       -                            -                                   |1\n",
      "[ '1A_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '1B_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '1C_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '1D_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '2E_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '2F_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACATGCCCCGGCCCGACC-ACTCTAACTCGATGTAGGA'\n",
      " '2G_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '2H_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '3I_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '3J_0     TTGTCCATTTTCAAGTCAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '3K_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '3L_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGA'\n",
      " '//                       -                            -                                   |1']\n",
      "//                                                       -                    -           |2\n",
      "[ '1A_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '1B_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '1C_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '1D_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGTTATCTCATCTCATGCTTTCCGGGTTATTTAAA'\n",
      " '2E_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '2F_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '2G_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '2H_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '3I_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '3J_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '3K_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '3L_0     AGCACAGGTCGAACCCATGCGGTCCTAGGTACCCTGCGTTCATGGGAGGTATCTCATCTCATGCTTTCCAGGTTATTTAAA'\n",
      " '//                                                       -                    -           |2']\n",
      "//                    -    -                                          -                - -|3\n",
      "[ '1A_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTC'\n",
      " '1B_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '1C_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '1D_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '2E_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '2F_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '2G_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCKTA'\n",
      " '2H_0     GACTGCGAATGACGGTGGTTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '3I_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '3J_0     GACTGCGAATGACSGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '3K_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACACTCTGGAGCGCGTACCGTA'\n",
      " '3L_0     GACTGCGAATGACGGTGGCTAGTACTCGAGGAAGGGTCGCACCGCAGTAAGCTAATCTGACCCTCTGGAGCGCGTACCGTA'\n",
      " '//                    -    -                                          -                - -|3']\n",
      "//          -   *         --     -  - *                     *                * -          |4\n",
      "[ '1A_0     AGTCTCCTAAACCCCAGGCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '1B_0     AGTCTCCTAAACCCCAGGCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '1C_0     AGTCTCCTAAACCCCAGGCTTTGGTTAWGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '1D_0     AGTTTCCTAAACCCCAGGCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '2E_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '2F_0     AGTCTCCCAAACCCCAGCCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '2G_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '2H_0     AGTCTCCCAAACCCCAGGMTTTGGWTAAGATGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '3I_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGGTGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTAGCGGATCCGAG'\n",
      " '3J_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGGTGCGGTCCGCGATCGCCGAGATGTTGCCAAAGCGTAGCAAGCGGATCCGAG'\n",
      " '3K_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGGTGCGGTCCGCGATCGCCGAGATGTTGCCAAAGCGTAGCAAGCGGATCCGAG'\n",
      " '3L_0     AGTCTCCCAAACCCCAGGCTTTGGTTAAGGTGCGGTCCGCGATCGCCGAGAAGTTGCCAAAGCGTAGCTATCGGATCCGAG'\n",
      " '//          -   *         --     -  - *                     *                * -          |4']\n",
      "//                           -   -     *                                             -    |5\n",
      "[ '1A_0     GATAGGCTTACGCTTGACACGAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '1B_0     GATA-GCTTACGCTTGACACGAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTYGCAT'\n",
      " '1C_0     GATA-GCTTACGCTTGACACGAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '1D_0     GATAGGCTTACGCTTGACACGAAATGATGTGGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '2E_0     GATAGGCTTACGCTTGACACGAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '2F_0     GATAGGCTTACGCTTGACACGAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '2G_0     GATAGGCTTACGCTTGACACSAAATGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '2H_0     GATAGGCTTACGCTTGACACGAAAAGATGTAGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '3I_0     GATAGGCTTACGCTTGACACGAAATGATGTGGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '3J_0     GATAGGCTTACGCTTGACACGAAATGATGTGGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '3K_0     GATAGGCTTACGCTTGACACGAAATGATGTGGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '3L_0     GATAGGCTTACGCTTGACACGAAATGATGTGGTTATCTCGGAGTCCAGACCGCCTGATAACCTAGGCAATGCATCTCGCAT'\n",
      " '//                           -   -     *                                             -    |5']\n",
      "//        -                                          -                     -   -          |6\n",
      "[ '1A_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGSGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '1B_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '1C_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '1D_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '2E_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '2F_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '2G_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '2H_0     GGAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTCTGACATAATT'\n",
      " '3I_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '3J_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '3K_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACACCCTTTGACATAATT'\n",
      " '3L_0     GAAACGTAATTATCGCTCGCCAGTCTTTATTCCTATATGGCAGGGGCGCAGCTATATGGTAGTACATCCTTTGACATAATT'\n",
      " '//        -                                          -                     -   -          |6']\n",
      "//           -        -         -    --           -        -     *                 -   *  |7\n",
      "[ '1A_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTGGC'\n",
      " '1B_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTGGC'\n",
      " '1C_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTGGC'\n",
      " '1D_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCTCCAGTATACCTTCGAACGATTGGC'\n",
      " '2E_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTAGC'\n",
      " '2F_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTAGC'\n",
      " '2G_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTAGC'\n",
      " '2H_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCACCAGTATACCTTCGAACTATTAGC'\n",
      " '3I_0     GAGGCGTATAAGCCGCGTATGTAGGCTTGATGGGCGGCTAAACAACTTTTGGAGTCTCCAGTATACCTTCGAACTATTGGC'\n",
      " '3J_0     GAGGCGTATAAGCCGCGTATGTAGGCTTRATGGGCGGCTAAWCAACTTTTRGAGTCTCCAGTATACCTTCGAACTATTGGC'\n",
      " '3K_0     GAGGCGTATAAGCCGCGTATGTASGCTTGATGGGCGGCTAAACAACTTTTGGAGTCTCCAGTATACCTTCGAACTATTGGC'\n",
      " '3L_0     GAGGTGTATAAGCTGCGTATGTAGGCTTGMTGGGCGGCTAAACAACTTTTGGAGTCTCCAGTATACCTTCGAACTATTGGC'\n",
      " '//           -        -         -    --           -        -     *                 -   *  |7']\n",
      "//              *         *           ** -                              *        *        |8\n",
      "[ '1A_0     AATGTCGTCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '1B_0     AATGTCGTCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '1C_0     AATGTCGTCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '1D_0     AATGTCGTCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '2E_0     AATGTCGGCCGACGAGGTGTCACACGGGTATACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '2F_0     AATGTCGGCCGACGAGGTGTCACACGGGTATACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '2G_0     AATGTCGGCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '2H_0     AATGTCGGCCGACGAGGTGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '3I_0     AATGTCGGCCGACGAGGCGTCACACGGGTGYASGCGCCCGCCTCTGTTCACAGCGCGTGGTTGRACAGGGAATCCTTTCCC'\n",
      " '3J_0     AATGTCGGCCGACGAGGCGTCACACGGGTGYACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGRACAGGGAATCCTTTCCC'\n",
      " '3K_0     AATGTCGGCCGACGAGGCGTCACACGGGTGWACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGAACAGGGAATCCTTTCCC'\n",
      " '3L_0     AATGTCGGCCGACGAGGCGTCACACGGGTGTACGCGCCCGCCTCTGTTCACAGCGCGTGGTTGGACAGGGAAGCCTTTCCC'\n",
      " '//              *         *           ** -                              *        *        |8']\n",
      "//                -   -                            -       -                     -        |9\n",
      "[ '1A_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '1B_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '1C_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '1D_0     CTAGCGTTTGTTCGGCGCATAGCCTCCCATATCACCGAGTGCTCGATGCGCAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '2E_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTAMGCGGCTCA'\n",
      " '2F_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '2G_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '2H_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '3I_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '3J_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '3K_0     CTAGCGTTTTTTCGGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '3L_0     CTAGCGTTTTTTCAGCGCATAGCCTCCCATATCACCGAGTGCGCGATGCGTAAGTGGGACACCTCCCCCCTACGCGGCTCA'\n",
      " '//                -   -                            -       -                     -        |9']\n"
     ]
    }
   ],
   "source": [
    "for loc in xrange(10): #nloci):\n",
    "    ## parse the locus\n",
    "    lines = loci[loc].split(\"\\n\")#[:-1]\n",
    "    names = [i.split()[0] for i in lines]\n",
    "    seqs = np.array([list(i.split()[1]) for i in lines])\n",
    "    snpidx = lines[-1]\n",
    "    \n",
    "    print(snpidx)\n",
    "    print(np.array(list(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _loci2loci(handle, taxonlist, maxlen=200):\n",
    "    \"\"\"\n",
    "    Converts loci format data to a numpy array as floats of SNP props.\n",
    "    \"\"\"\n",
    "\n",
    "    ## read in the input file\n",
    "    with open(handle, 'r') as infile:\n",
    "        loci = infile.read().strip().split(\"|\\n\")\n",
    "        nloci = len(loci)\n",
    "\n",
    "    ## count max snps \n",
    "    maxsnps = 0\n",
    "    for iloc in xrange(nloci):\n",
    "        lines = loci[iloc].split(\"//\")[1].strip()\n",
    "        _maxl = len([i for i in lines.split(\"|\")[0].strip() if i != \" \"])\n",
    "        maxsnps = max(maxsnps, _maxl)\n",
    "\n",
    "    ## build array ({4or5}, nloci, maxsnps)\n",
    "    arr = np.zeros((nloci, 4, maxsnps), dtype=np.float)\n",
    "       \n",
    "    ## get the outgroup allele (most common in outgroup)\n",
    "    for loc in xrange(10): #nloci):\n",
    "        ## parse the locus\n",
    "        lines = loci[loc].split(\"\\n\")[:-1]\n",
    "        names = [i.split()[0] for i in lines]\n",
    "        seqs = np.array([list(i.split()[1]) for i in lines])\n",
    "        snpidx = lines[-1]\n",
    "        \n",
    "        ## find most frequent allele among outgroups and call that the\n",
    "        ## outgroup allele (A). How do we break ties? For simplicity, we'll\n",
    "        ## consistently choose lowest base to break ties (e.g., A over C)\n",
    "        arr[:, -1].fill(1)\n",
    "        \n",
    "        ## \n",
    "        #for otax in taxonlist[-1]:\n",
    "        #    print seqs[names.index(otax)]\n",
    "        \n",
    "        #print(seqs)\n",
    "        #print(names)\n",
    "        #seqlen = seqs.shape[1]\n",
    "\n",
    "        #taxi = sum([i in names for i in taxonlist])\n",
    "        #taxc[iloc] += taxi        \n",
    "        #print(loci[loc])\n",
    "\n",
    "    return arr\n",
    "    \n",
    "    \n",
    "#print maxlen\n",
    "arr = _loci2loci(handle, test)\n",
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            arr = np.zeros((5, maxlen), dtype=np.float64)\n",
    "            ## find most frequent allele among outgroups and call that the\n",
    "            ## outgroup allele (A). How do we break ties? For simplicity, we'll\n",
    "            ## consistently choose lowest base to break ties (e.g., A over C)\n",
    "            arr[-1].fill(1)\n",
    "\n",
    "            ## fill fake data columns with 9s\n",
    "            arr[:, seqlen-maxlen:].fill(9)\n",
    "\n",
    "            ## get outgroup values\n",
    "            outvals = seqs[names.index(taxonlist[4])]\n",
    "            for itax in xrange(4):\n",
    "                ## make 1s all sites that match to outg\n",
    "                tmparr = np.int8(seqs[names.index(taxonlist[itax])] == outvals)\n",
    "                ## make 9s all sites that have (N-RKSMW)\n",
    "                #tmparr[\n",
    "                arr[itax][:tmparr.shape[0]] = tmparr\n",
    "            farr[iloc] = arr\n",
    "\n",
    "    ## warn if no SNPs are found\n",
    "    ## warn if no loci have sampling of all taxa\n",
    "\n",
    "    #print(np.histogram(taxc, range(7)))\n",
    "    ## return array that includes np.ones for loci w/o taxa\n",
    "    return farr[taxc == len(taxonlist)], taxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxonlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-298de83708f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtaxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtaxonlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtaxc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtaxi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtaxi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxonlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxonlist' is not defined"
     ]
    }
   ],
   "source": [
    "with open(handle, 'r') as infile:\n",
    "    ## split on \"//\" for legacy compatibility\n",
    "    loci = infile.read().strip().split(\"|\\n\")\n",
    "\n",
    "## create emtpy array to fill\n",
    "nloci = len(loci)\n",
    "farr = np.ones((nloci, ntips, maxlen), dtype=np.float64)\n",
    "taxc = np.zeros((nloci,))\n",
    "\n",
    "## iterate over loci to find those which have taxon sampling\n",
    "for iloc in xrange(nloci):\n",
    "    lines = loci[iloc].split(\"//\")[0].split()\n",
    "    names = [i[1:] for i in lines[::2]]\n",
    "    seqs = np.array([list(i) for i in lines[1::2]])\n",
    "\n",
    "    taxi = sum([i in names for i in taxonlist])\n",
    "    taxc[iloc] += taxi\n",
    "    if taxi == len(taxonlist):\n",
    "        arr = np.zeros((5, maxlen), dtype=np.float64)\n",
    "print names\n",
    "print seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'C' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'C' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'C' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'T' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']\n",
      " ['T' 'T' 'A' 'G' 'T' 'T' 'C' 'T' 'T' 'A' 'G' 'A' 'C' 'T' 'A' 'T' 'T' 'C'\n",
      "  'G' 'T' 'T' 'A' 'A' 'C' 'T' 'C' 'G' 'A' 'G' 'G' 'C' 'G' 'A' 'G' 'T' 'G'\n",
      "  'C' 'C' 'C' 'T' 'A' 'A' 'G' 'C' 'G' 'C' 'T' 'A' 'A' 'A' 'C' 'G' 'T' 'G'\n",
      "  'G' 'C' 'A' 'G' 'G' 'A' 'C' 'C' 'T' 'G' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A'\n",
      "  'A' 'C' 'A' 'C' 'G' 'C' 'A' 'G' 'A']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'taxonlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-87cb626db8bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtaxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtaxonlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtaxc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtaxi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtaxi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxonlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxonlist' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    print seqs\n",
    "    seqlen = seqs.shape[1]\n",
    "\n",
    "    taxi = sum([i in names for i in taxonlist])\n",
    "    taxc[iloc] += taxi\n",
    "    if taxi == len(taxonlist):\n",
    "        arr = np.zeros((5, maxlen), dtype=np.float64)\n",
    "        ## find most frequent allele among outgroups and call that the\n",
    "        ## outgroup allele (A). How do we break ties? For simplicity, we'll\n",
    "        ## consistently choose lowest base to break ties (e.g., A over C)\n",
    "        arr[-1].fill(1)\n",
    "\n",
    "        ## fill fake data columns with 9s\n",
    "        arr[:, seqlen-maxlen:].fill(9)\n",
    "\n",
    "        ## get outgroup values\n",
    "        outvals = seqs[names.index(taxonlist[4])]\n",
    "        for itax in xrange(4):\n",
    "            ## make 1s all sites that match to outg\n",
    "            tmparr = np.int8(seqs[names.index(taxonlist[itax])] == outvals)\n",
    "            ## make 9s all sites that have (N-RKSMW)\n",
    "            #tmparr[\n",
    "            arr[itax][:tmparr.shape[0]] = tmparr\n",
    "        farr[iloc] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b4a312e106bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## parse the loci file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "iloc = 0\n",
    "\n",
    "## parse the loci file\n",
    "names = lines[::2]\n",
    "seqs = np.array([list(i) for i in lines[1::2]])\n",
    "seqlen = seqs.shape[1]\n",
    "print seqlen\n",
    "\n",
    "## check for taxon coverage\n",
    "taxi = [any([i in names for i in ptax]) for ptax in test]\n",
    "print taxi\n",
    "\n",
    "## group sequences into arr[arrs] \n",
    "sidx = [[names.index(i) for i in ptax] for ptax in test]\n",
    "seqs = np.array([np.array([seqs[i] for i in isid]).view(np.int8) for isid in sidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f909a1a69aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## choose test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mntips\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtaxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mntips\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtaxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi' is not defined"
     ]
    }
   ],
   "source": [
    "## choose test\n",
    "if ntips == 4:\n",
    "    p3 = [taxi[2]]\n",
    "elif ntips == 5:\n",
    "    p3 = [taxi[2], taxi[3]]\n",
    "else:\n",
    "    raise IPyradWarningExit(\"ntips can only be 4 or 5\")   \n",
    "print ntips\n",
    "\n",
    "\n",
    "## filter for loci w/ sufficient coverage\n",
    "suff = all([taxi[0], taxi[1], taxi[-1]]) & any(p3)\n",
    "if suff:\n",
    "    ## an array to fill\n",
    "    arr = np.zeros((ntips, maxlen), dtype=np.float64)\n",
    "    print arr.shape\n",
    "    \n",
    "    ## fill outgroup with most common base in outgroup\n",
    "    ancestral = reftrick(seqs[-1], GETCONS)[:, 0]\n",
    "    for i in xrange(ntips):\n",
    "        arr[i][:seqlen] = np.sum(seqs[i] == ancestral, axis=0) / \\\n",
    "                                float(seqs[i].shape[0])\n",
    "    print ancestral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "#@numba.jit()\n",
    "def reffreq(refseq, iseq, consdict):\n",
    "    ## empty arrays\n",
    "    freq = np.zeros((1, iseq.shape[1]), dtype=np.float64)\n",
    "    amseq = np.zeros((iseq.shape[0]*2, iseq.shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    ## fill in both copies\n",
    "    for seq in xrange(iseq.shape[0]):\n",
    "        for col in xrange(iseq.shape[1]):\n",
    "            ## expand colums with ambigs and remove N-\n",
    "            base = iseq[seq][col]\n",
    "            who = np.where(consdict[:, 0] == base)[0]\n",
    "            ## resolve heteros or enter into both copies\n",
    "            if np.any(who):\n",
    "                who = who[0]\n",
    "                amseq[(seq*2)][col] = consdict[who][0]\n",
    "                amseq[(seq*2)+1][col] = consdict[who][1]\n",
    "            else:\n",
    "                amseq[(seq*2)][col] = base\n",
    "                amseq[(seq*2)+1][col] = base\n",
    "    \n",
    "    ## get as frequencies\n",
    "    amseq = (refseq == amseq).astype(np.float64)\n",
    "    for i in xrange(amseq.shape[0]):\n",
    "        freq += amseq[i]\n",
    "    return freq / np.float64(amseq.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-694179bbb294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreffreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancestral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'consdict' is not defined"
     ]
    }
   ],
   "source": [
    "reffreq(ancestral, refseq, consdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  1. ,  1. ,  1. ,  1. ,  0.5,  0. ,  1. ]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refseq = np.array([list(\"AACCGGTT\")]).view(np.uint8)\n",
    "iseq = np.array([list(\"AACCGGGT\"), list(\"AACCGCGT\")]).view(np.uint8)\n",
    "consdict = GETCONS\n",
    "\n",
    "reffreq(refseq, iseq, consdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  1. ,  1. ,  1. ,  1. ,  0.5,  0. ,  1. ]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reffreq(refseq, iseq, consdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "## iterate over loci to find those which have taxon sampling\n",
    "for iloc in xrange(nloci):\n",
    "    \n",
    "    ## parse the loci file\n",
    "    lines = loci[iloc].split(\"//\")[0].split()\n",
    "    names = lines[::2]\n",
    "    seqs = np.array([list(i) for i in lines[1::2]])\n",
    "    seqlen = seqs.shape[1]\n",
    "\n",
    "    ## check for taxon coverage\n",
    "    taxi = [any([i in names for i in ptax]) for ptax in test]\n",
    "    \n",
    "    ## group sequences into arr[arrs] \n",
    "    sidx = [[names.index(i) for i in ptax] for ptax in test]\n",
    "    seqs = np.array([np.array([seqs[i] for i in isid]).view(np.int8) for isid in sidx])\n",
    "    \n",
    "    ## choose test\n",
    "    if ntips == 4:\n",
    "        p3 = [taxi[2]]\n",
    "    elif ntips == 5:\n",
    "        p3 = [taxi[2], taxi[3]]\n",
    "    else:\n",
    "        raise IPyradWarningExit(\"ntips can only be 4 or 5\")\n",
    "        \n",
    "    ## filter for loci w/ sufficient coverage\n",
    "    if all([taxi[0], taxi[1], taxi[-1]]) & any(p3):\n",
    "        \n",
    "        ## an array to fill\n",
    "        arr = np.zeros((seqs.shape[0], maxlen), dtype=np.float64)\n",
    "        \n",
    "        ## fill outgroup with most common base in outgroup\n",
    "        ancestral = reftrick(seqs[-1], GETCONS)[:, 0]\n",
    "        for i in xrange(seqs.shape[0]):\n",
    "            arr[i][:seqlen] = np.sum(seqs[i] == ancestral, axis=0) / \\\n",
    "                                 float(seqs[i].shape[0])\n",
    "\n",
    "print arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,81) into shape (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-2e11ef46ae87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtmparr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxonlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m## make 9s all sites that have (N-RKSMW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtmparr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmparr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mfarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,81) into shape (2)"
     ]
    }
   ],
   "source": [
    "        \n",
    "        arr[-1].fill(1)\n",
    "        ## fill fake data columns with 9s\n",
    "        arr[:, seqlen-maxlen:].fill(9)\n",
    "\n",
    "        ## get outgroup values\n",
    "        outvals = seqs[names.index(taxonlist[3])]\n",
    "        for itax in xrange(4):\n",
    "            ## make 1s all sites that match to outg\n",
    "            tmparr = np.int8(seqs[names.index(taxonlist[itax])] == outvals)\n",
    "            ## make 9s all sites that have (N-RKSMW)\n",
    "            arr[itax][:tmparr.shape[0]] = tmparr\n",
    "        farr[iloc] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]],\n",
       "\n",
       "       [[1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]],\n",
       "\n",
       "       [[1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]],\n",
       "\n",
       "       ..., \n",
       "       [[1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]],\n",
       "\n",
       "       [[0, 1, 1, ..., 9, 9, 9],\n",
       "        [0, 1, 1, ..., 9, 9, 9],\n",
       "        [0, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]],\n",
       "\n",
       "       [[1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9],\n",
       "        [1, 1, 1, ..., 9, 9, 9]]], dtype=int8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr[taxc == len(taxonlist)]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
