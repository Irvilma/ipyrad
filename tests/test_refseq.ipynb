{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _ipyrad_ testing tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Import _ipyrad_ and remove previous test files if they are already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.65\n"
     ]
    }
   ],
   "source": [
    "## import modules\n",
    "import ipyrad as ip      ## for RADseq assembly\n",
    "print ip.__version__     ## print version\n",
    "\n",
    "## clear data from test directory if it already exists\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "#if os.path.exists(\"./test_refseq/\"):\n",
    "#    shutil.rmtree(\"./test_refseq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This is useful during development since IPython\n",
    "## seems to want to re-use old .pyc files, \n",
    "## though even this doesn't always work...\n",
    "import IPython.lib.deepreload\n",
    "import __builtin__\n",
    "from IPython.lib import deepreload\n",
    "__builtin__.reload = deepreload.reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize smalt (index reference sequence)\n",
    "This is preparation for indexing. It only ever needs to be done once so shoud be tested during initialization.\n",
    "\n",
    "`smalt index zf-ref ../zf/zf.sm.fa`\n",
    "\n",
    "There is an optional -s flag that could improve mapping accuracy. Consider the best default, probably not worth letting people pass it in, if they want to mess with it they can index their own reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1A_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eee2dfa41c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# TODO: create and link index files to Sample objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1A_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_smi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1A_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_sma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1A_0'"
     ]
    }
   ],
   "source": [
    "# hack the binary paths cuz the current egg doesn't have them in it\n",
    "#data1.muscle=\n",
    "#data1.vsearch\n",
    "#data1.smalt\n",
    "\n",
    "# Reference sequence directory (gzipped fasta files)\n",
    "# TODO: set this as a parameter\n",
    "# e.g., data1.set_params('refseq', \"./data/zf.fa.gz\")\n",
    "\n",
    "# TODO: push this example file to the data/ dir \n",
    "REFSEQ = \"./data/zf.fa.gz\"\n",
    "\n",
    "# Set the step size to 4 (default is 13)\n",
    "# This will slow down read mapping, but increase accuracy\n",
    "SMALT_INDEX_FLAGS = \" -s 4 \"\n",
    "\n",
    "# TODO: create and link a dir/ to the Assembly object for the reference data files\n",
    "data1.dirs.reference = '...'\n",
    "\n",
    "# TODO: create and link index files to Sample objects\n",
    "data1.samples['1A_0'].files.index_smi = '...'\n",
    "data1.samples['1A_0'].files.index_sma = '...'\n",
    "\n",
    "# Test if reference sequence is already indexed\n",
    "# Only index if the .smi and .sma files don't exist, saves lots of time\n",
    "if not os.path.isfile( REFSEQ+\".smi\" ):\n",
    "    # smalt indexing will create two files called REFSEQ.smi and .sma\n",
    "    # in the same directory as the reference sequence. \n",
    "    cmd = data1.smalt + \" index \" + SMALT_INDEX_FLAGS + REFSEQ + \" \" + REFSEQ\n",
    "    print cmd\n",
    "    subprocess.check_call(cmd, shell=True,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            stdout=subprocess.PIPE)\n",
    "    #output = subprocess.check_output( \" \".join(cmd), shell=True)\n",
    "else:\n",
    "    print \"Reference sequence index exists\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly and Sample objects\n",
    "\n",
    "Assembly and Sample objects are used by _ipyrad_ to access data stored on disk and to manipulate it. Each biological sample in a data set is represented in a Sample object, and these Samples are stored inside Assembly objects. The Assembly object contains functions to assemble the data, and stores a log of all steps performed and the resulting statistics of those steps. Assembly objects can be copied or merged to allow branching events where different parameters are applied to assemblies. \n",
    "\n",
    "To create an Assembly object call ip.Assembly and pass it a name for the data set. We could imagine that we planned to assemble and later combine data from multiple sequencing runs, but before combining them each group of samples has to be analyzed under a different set of parameters. As an example, we could call two data sets \"2014_data\" and \"2015_data\". These initially do not contain any Samples. Sample objects are created either by linking fastq files to the Assembly object or by running step 1 to demultiplex raw data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0 new Samples created in 2014_data.\n",
      "0 fastq files linked to Samples.\n",
      "[]\n",
      "0 new Samples created in 2015_data.\n",
      "0 fastq files linked to Samples.\n",
      "Assembly object named 2014_data\n",
      "Assembly object named 2015_data\n"
     ]
    }
   ],
   "source": [
    "## create an Assembly object called data1. \n",
    "## It takes an 'test'\n",
    "data1 = ip.Assembly(\"2014_data\")\n",
    "data2 = ip.Assembly(\"2015_data\")\n",
    "\n",
    "print \"Assembly object named\", data1.name\n",
    "print \"Assembly object named\", data2.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying assembly parameters\n",
    "All of the parameter settings are linked to an Assembly object, which has a set of default parameters when it is created. These can be viewed using the `get_params()` function. To get more detailed information about all paramteres use `ip.get_params_info()` or to select a single parameter use `ip.get_params_info(3)`. Assembly objects have a function `set_params()` that can be used to modify parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   working_directory             ./test_refseq                                \n",
      "  2   raw_fastq_path                ./data/sim_rad_test_R1_.fastq.gz             \n",
      "  3   barcodes_path                 ./data/sim_rad_test_barcodes.txt             \n",
      "  4   sorted_fastq_path                                                          \n",
      "  5   restriction_overhang          ('TGCAG', '')                                \n",
      "  6   max_low_qual_bases            5                                            \n",
      "  7   N_processors                  3                                            \n",
      "  8   mindepth_statistical          6                                            \n",
      "  9   mindepth_majrule              6                                            \n",
      "  10  datatype                      rad                                          \n",
      "  11  clust_threshold               0.85                                         \n",
      "  12  minsamp                       4                                            \n",
      "  13  max_shared_heterozygosity     0.25                                         \n",
      "  14  prefix_outname                2014_data                                    \n",
      "  15  phred_Qscore_offset           33                                           \n",
      "  16  max_barcode_mismatch          1                                            \n",
      "  17  filter_adapters               0                                            \n",
      "  18  filter_min_trim_len           35                                           \n",
      "  19  ploidy                        2                                            \n",
      "  20  max_stack_size                1000                                         \n",
      "  21  max_Ns_consens                5                                            \n",
      "  22  max_Hs_consens                8                                            \n",
      "  23  max_SNPs_locus                (100, 100)                                   \n",
      "  24  max_Indels_locus              (5, 99)                                      \n",
      "  25  trim_overhang                 (1, 2, 2, 1)                                 \n",
      "  26  hierarchical_clustering       0                                            \n",
      "  27  reference_sequence                                                         \n"
     ]
    }
   ],
   "source": [
    "## modify parameters for this Assembly object\n",
    "data1.set_params(1, \"./test_refseq\")\n",
    "data1.set_params(2, \"./data/sim_rad_test_R1_.fastq.gz\")\n",
    "data1.set_params(3, \"./data/sim_rad_test_barcodes.txt\")\n",
    "data1.set_params(7, 3)\n",
    "data1.set_params(10, 'rad')\n",
    "#data1.set_params(27, '/Volumes/WorkDrive/ipyrad/refhacking/MusChr1.fa')\n",
    "\n",
    "## print the new parameters to screen\n",
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting data assembly and Sample objects\n",
    "If the data are already demultiplexed then fastq files can be linked directly to the Data object, which in turn will create Sample objects for each fastq file (or pair of fastq files for paired data). The files may be gzip compressed. If the data are not demultiplexed then you will have to run the step1 function below to demultiplex the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0 new Samples created in 2014_data.\n",
      "0 fastq files linked to Samples.\n"
     ]
    }
   ],
   "source": [
    "## This would link fastq files from the 'sorted_fastq_path' if present\n",
    "## Here it does nothing b/c there are no files in the sorted_fastq_path\n",
    "data1.link_fastqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Demultiplex the raw data files\n",
    "This uses the barcodes information to demultiplex reads in data files found in the 'raw_fastq_path'. It will create a Sample object for each sample that will be stored in the Assembly object. The state of each sample will be set to 1, meaning that the sample has completed step 1 of the _ipyrad_ assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview: 2G_0 GATATA\n",
      "preview: 3K_0 TGAGGG\n",
      "preview: 3J_0 TAATTA\n",
      "preview: 2E_0 AGGGAA\n",
      "preview: 1A_0 CATCAT\n",
      "preview: 1B_0 AGTGAT\n",
      "preview: 3I_0 GGGATT\n",
      "preview: 3L_0 ATATTA\n",
      "preview: 2F_0 AAAGTG\n",
      "preview: 1C_0 ATGGTA\n",
      "preview: 1D_0 GTGGGA\n",
      "preview: 2H_0 GAGGAG\n",
      "preview: ('/Volumes/WorkDrive/ipyrad/ipyrad/tests/data/sim_rad_test_R1_.fastq.gz', 0)\n",
      "splitting large files\n",
      "[0, 1, 2, 3]\n",
      "[[<ipyrad.core.assembly.Assembly object at 0x1133c9310>, '/Volumes/WorkDrive/ipyrad/ipyrad/tests/data/sim_rad_test_R1_.fastq.gz', ('/Volumes/WorkDrive/ipyrad/ipyrad/tests/test_refseq/2014_data_fastqs/chunk_0_aa', 0), 'TGCAG', (6, 'same'), 0, 0], [<ipyrad.core.assembly.Assembly object at 0x1133c9310>, '/Volumes/WorkDrive/ipyrad/ipyrad/tests/data/sim_rad_test_R1_.fastq.gz', ('/Volumes/WorkDrive/ipyrad/ipyrad/tests/test_refseq/2014_data_fastqs/chunk_0_ab', 0), 'TGCAG', (6, 'same'), 1, 0], [<ipyrad.core.assembly.Assembly object at 0x1133c9310>, '/Volumes/WorkDrive/ipyrad/ipyrad/tests/data/sim_rad_test_R1_.fastq.gz', ('/Volumes/WorkDrive/ipyrad/ipyrad/tests/test_refseq/2014_data_fastqs/chunk_0_ac', 0), 'TGCAG', (6, 'same'), 2, 0]]\n",
      "<AsyncMapResult: barmatch>\n",
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      1      20099             NaN             NaN            NaN   \n",
      "1B_0      1      19977             NaN             NaN            NaN   \n",
      "1C_0      1      20114             NaN             NaN            NaN   \n",
      "1D_0      1      19895             NaN             NaN            NaN   \n",
      "2E_0      1      19928             NaN             NaN            NaN   \n",
      "2F_0      1      19934             NaN             NaN            NaN   \n",
      "2G_0      1      20026             NaN             NaN            NaN   \n",
      "2H_0      1      19936             NaN             NaN            NaN   \n",
      "3I_0      1      20084             NaN             NaN            NaN   \n",
      "3J_0      1      20011             NaN             NaN            NaN   \n",
      "3K_0      1      20117             NaN             NaN            NaN   \n",
      "3L_0      1      19901             NaN             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n"
     ]
    }
   ],
   "source": [
    "## run step 1 to demultiplex the data\n",
    "data1.step1(preview=1)\n",
    "\n",
    "## print the results for each Sample in data1\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter reads \n",
    "If for some reason we wanted to execute on just a subsample of our data, we could do this by selecting only certain samples to call the `step2` function on. Because `step2` is a function of `data`, it will always execute with the parameters that are linked to `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      1      20099             NaN             NaN            NaN   \n",
      "1B_0      1      19977             NaN             NaN            NaN   \n",
      "1C_0      1      20114             NaN             NaN            NaN   \n",
      "1D_0      1      19895             NaN             NaN            NaN   \n",
      "2E_0      1      19928             NaN             NaN            NaN   \n",
      "2F_0      1      19934             NaN             NaN            NaN   \n",
      "2G_0      1      20026             NaN             NaN            NaN   \n",
      "2H_0      1      19936             NaN             NaN            NaN   \n",
      "3I_0      1      20084             NaN             NaN            NaN   \n",
      "3J_0      1      20011             NaN             NaN            NaN   \n",
      "3K_0      1      20117             NaN             NaN            NaN   \n",
      "3L_0      1      19901             NaN             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n"
     ]
    }
   ],
   "source": [
    "## run step 1 to demultiplex the data\n",
    "data1.step1()\n",
    "\n",
    "## print the results for each Sample in data1\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter reads \n",
    "If for some reason we wanted to execute on just a subsample of our data, we could do this by selecting only certain samples to call the `step2` function on. Because `step2` is a function of `data`, it will always execute with the parameters that are linked to `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## example of ways to run step 2 to filter and trim reads\n",
    "#data1.step2(\"1A_0\")            ## run on a single sample\n",
    "data1.step2([\"1B_0\", \"1C_0\"])  ## run on one or more samples\n",
    "#data1.step2()                  ## run on all samples, skipping finished ones\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the read mapping (SE)\n",
    "Here's an example cmdline run with args explained below:\n",
    "\n",
    "smalt map -f sam -n 8 -l pp -o Arremon.sam zf-ref ../MarTum-fasta/ArremonR1.fa ../MarTum-fasta/ArremonR2.fa\n",
    "\n",
    "* -f sams - you can also output as 'bam' but it requires installing bambamc which is explained in the smalt docs, but which seems annoying, esp cuz samtools will do it for us.\n",
    "* -n sets the number of threads to 8, dramatically increases speed\n",
    "* -l pp tells smalt about the orientation of the paired reads, in this case pp means both reads are on the same strand in the 5' to 3' direction, I think the second read was originally from the second strand and pyrad reverse complemented it.\n",
    "* -o is the outfile\n",
    "* Next is the indexed reference sequence and the files containing reads\n",
    "\n",
    "Other options to look into:\n",
    "* -y minid Filters output alignments by a threshold in the number of exactly\n",
    "matching nucleotides.\n",
    "* -r seed Determines how reads or mate pairs with multiple best mappings are\n",
    "reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data1.paramsdict[\"working_directory\"]\n",
    "data1.dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "# This is all test junk, ignore\n",
    "###############################\n",
    "output = \"/tmp/wat\"\n",
    "\n",
    "# Check the input files\n",
    "SMALT_CMD = \"check \"\n",
    "## the read1 demultiplexed reads file\n",
    "fr1 = data1.get_params(1)+\"/fastq/1A_0_R1_.gz\"\n",
    "#data1.smalt = \"/usr/local/bin/smalt\"\n",
    "cmd = data1.smalt + \" \" + SMALT_CMD + \" \" + fr1\n",
    "print cmd\n",
    "subprocess.call(cmd, shell=True,\n",
    "                     stderr=subprocess.STDOUT,\n",
    "                     stdout=subprocess.PIPE)\n",
    "\n",
    "SMALT_CMD = \"map -f sam -n 8 -o \" + output\n",
    "## the read1 demultiplexed reads file\n",
    "\n",
    "## TODO: I recommend using parameter descriptions rather than numbers\n",
    "## in the code so it is more robust to potential reordering of parameters\n",
    "fr1 = data1.get_params('working_directory')+\"/fastq/1A_0_R1_.gz\"\n",
    "\n",
    "cmd = data1.smalt + \" \" + SMALT_CMD + \" \" + REFSEQ + \" \" + fr1\n",
    "print cmd\n",
    "subprocess.call(cmd, shell=True,\n",
    "                     stderr=subprocess.STDOUT,\n",
    "                     stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mapped and unmapped reads\n",
    "\n",
    "First get some info about our mapping.\n",
    "\n",
    "    samtools flagstat <yoursam>\n",
    "\n",
    "Get only the mapped reads. 0x4 is a bitmask for 'unmapped' reads, -F means get all not this mask. In both cases -b outputs as bam\n",
    "\n",
    "    samtools view -b -F 0x4 <your.sam> > mapped.bam\n",
    "\n",
    "Same as above, but in this case -f means just give me the ones with this flag set.\n",
    "\n",
    "    samtools view -b -f 0x4 <your.sam> > unmapped.bam\n",
    "\n",
    "## \n",
    "\n",
    "samtools sort -T /tmp/wat -O bam test.mapped.bam > test.mapped.sorted.bam\n",
    "samtools bam2fq test.mapped.sorted.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deren/Dropbox/ipyrad/bin/muscle3.8.31_i86linux64\n",
      "/home/deren/Dropbox/ipyrad/bin/vsearch-1.1.3-linux-x86_64\n",
      "/home/deren/Dropbox/ipyrad/bin/smalt-0.7.6-linux-x86_64\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "\n",
    "#This is junk\n",
    "\n",
    "print data1.muscle\n",
    "print data1.vsearch\n",
    "print data1.smalt\n",
    "print data1.samples[\"1B_0\"].files.edits\n",
    "#bam2py(\"\")\n",
    "#pysam.view(\"-b\", \"-S\", \"-o\") #, INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".sam\", catch_stdout=False)\n",
    "#pysam.sort( \"-O\", \"bam\", \"-o\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", \"-T\", \"tempfile\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", catch_stdout=False)\n",
    "#pysam.index( INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", catch_stdout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: clustering within-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for reference sequence index. If it doesn't exist then create it.\n",
      "This could take several minutes, but it's a one time penalty, so be patient.\n",
      "None\n",
      "Clustering 2 samples on 3 processors.\n",
      "1B_0 aleady clustered. Sample.stats.state == 3\n",
      "1C_0 aleady clustered. Sample.stats.state == 3\n",
      "\n",
      "No samples found in state 2. To rewrite existing data use\n",
      "force=True, or change Sample states to 2.\n",
      "\n",
      ".\n",
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      1      20099             NaN             NaN            NaN   \n",
      "1B_0      3      19977           19977               1              0   \n",
      "1C_0      3      20114           20114               1              0   \n",
      "1D_0      1      19895             NaN             NaN            NaN   \n",
      "2E_0      1      19928             NaN             NaN            NaN   \n",
      "2F_0      1      19934             NaN             NaN            NaN   \n",
      "2G_0      1      20026             NaN             NaN            NaN   \n",
      "2H_0      1      19936             NaN             NaN            NaN   \n",
      "3I_0      1      20084             NaN             NaN            NaN   \n",
      "3J_0      1      20011             NaN             NaN            NaN   \n",
      "3K_0      1      20117             NaN             NaN            NaN   \n",
      "3L_0      1      19901             NaN             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n",
      "/Volumes/WorkDrive/ipyrad/ipyrad/tests/test_refseq/2014_data_fastqs/1B_0_R1_.gz\n"
     ]
    }
   ],
   "source": [
    "## run step 3 to cluster reads within samples using vsearch\n",
    "#data1.step3(preview=1) #[\"2H_0\", \"2G_0\"], preview=1)\n",
    "data1.step3([\"1B_0\", \"1C_0\"], preview=1)\n",
    "## print the results\n",
    "print data1.stats\n",
    "print data1.samples[\"1B_0\"].files.fastq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of plotting with _ipyrad_\n",
    "There are a a few simple plotting functions in _ipyrad_ useful for visualizing results. These are in the module `ipyrad.plotting`. Below is an interactive plot for visualizing the distributions of coverages across the 12 samples in the test data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "import ipyrad.plotting as iplot\n",
    "\n",
    "## reload autosaved data. In case you quit and came back \n",
    "#data1 = ip.load_dataobj(\"test_rad/2014_data.dataobj\")\n",
    "\n",
    "## plot for one or more selected samples\n",
    "iplot.depthplot(data1, [\"1A_0\", \"1B_0\"])\n",
    "\n",
    "## plot for all samples in data1\n",
    "#iplot.depthplot(data1)\n",
    "\n",
    "## save plot as pdf and html\n",
    "iplot.depthplot(data1, outprefix=\"testfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Joint estimation of heterozygosity and error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## run step 4\n",
    "data1.step4() #\"2H_0\", \"2G_0\")\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Consensus base calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run step 5\n",
    "data1.step5([\"2H_0\"])\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick parameter explanations are always on-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip.get_params_info(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history \n",
    "A common problem after struggling through an analysis is that you find you've completely forgotten what parameters you used at what point, and when you changed them. The log history time stamps all calls to `set_params()`, as well as calls to `step` methods. It also records copies/branching of data objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data1.log:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Assembly objects\n",
    "Assembly objects can be saved and loaded so that interactive analyses can be started, stopped, and returned to quite easily. The format of these saved files is a serialized 'dill' object used by Python. Individual Sample objects are saved within Assembly objects. These objects to not contain the actual sequence data, but only link to it, and so are not very large. The information contained includes parameters and the log of Assembly objects, and the statistics and state of Sample objects. Assembly objects are autosaved each time an assembly `step` function is called, but you can also create your own checkpoints with the `save` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      2      20099           20099               1              0   \n",
      "1B_0      2      19977           19977               1              0   \n",
      "1C_0      2      20114           20114               1              0   \n",
      "1D_0      2      19895           19895               1              0   \n",
      "2E_0      2      19928           19928               1              0   \n",
      "2F_0      2      19934           19934               1              0   \n",
      "2G_0      2      20026           20026               1              0   \n",
      "2H_0      2      19936           19936               1              0   \n",
      "3I_0      2      20084           20084               1              0   \n",
      "3J_0      2      20011           20011               1              0   \n",
      "3K_0      2      20117           20117               1              0   \n",
      "3L_0      2      19901           19901               1              0   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n",
      "/private/tmp/ipyrad-test/test_clust_0.85/1A_0.clustS.gz\n"
     ]
    }
   ],
   "source": [
    "## save assembly object\n",
    "#ip.save_assembly(\"data1.p\")\n",
    "\n",
    "## load assembly object\n",
    "data2 = ip.load_assembly(\"/tmp/ipyrad-test/test.assembly\")\n",
    "print data2.name\n",
    "#print data.stats\n",
    "for sample in data2.samples:\n",
    "    data2.samples[sample].stats.state = 2#.state\n",
    "print data2.stats\n",
    "#data2.set_params(4, \"/tmp/ipyrad-test/test_edits/\")\n",
    "#print data2\n",
    "print data2.samples[\"1A_0\"].files.clusters\n",
    "#data2.step2(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for reference sequence index. If it doesn't exist then create it.\n",
      "This could take several minutes, but it's a one time penalty, so be patient.\n",
      "None\n",
      "Clustering 1 samples on 4 processors.\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>reads_raw</th>\n",
       "      <th>reads_filtered</th>\n",
       "      <th>clusters_total</th>\n",
       "      <th>clusters_kept</th>\n",
       "      <th>hetero_est</th>\n",
       "      <th>error_est</th>\n",
       "      <th>reads_consens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1A_0</th>\n",
       "      <td>3</td>\n",
       "      <td>20099</td>\n",
       "      <td>20099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19977</td>\n",
       "      <td>19977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1C_0</th>\n",
       "      <td>2</td>\n",
       "      <td>20114</td>\n",
       "      <td>20114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1D_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19895</td>\n",
       "      <td>19895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2E_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19928</td>\n",
       "      <td>19928</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2F_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19934</td>\n",
       "      <td>19934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2G_0</th>\n",
       "      <td>2</td>\n",
       "      <td>20026</td>\n",
       "      <td>20026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2H_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19936</td>\n",
       "      <td>19936</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3I_0</th>\n",
       "      <td>2</td>\n",
       "      <td>20084</td>\n",
       "      <td>20084</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3J_0</th>\n",
       "      <td>2</td>\n",
       "      <td>20011</td>\n",
       "      <td>20011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3K_0</th>\n",
       "      <td>2</td>\n",
       "      <td>20117</td>\n",
       "      <td>20117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3L_0</th>\n",
       "      <td>2</td>\n",
       "      <td>19901</td>\n",
       "      <td>19901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
       "1A_0      3      20099           20099               1              0   \n",
       "1B_0      2      19977           19977               1              0   \n",
       "1C_0      2      20114           20114               1              0   \n",
       "1D_0      2      19895           19895               1              0   \n",
       "2E_0      2      19928           19928               1              0   \n",
       "2F_0      2      19934           19934               1              0   \n",
       "2G_0      2      20026           20026               1              0   \n",
       "2H_0      2      19936           19936               1              0   \n",
       "3I_0      2      20084           20084               1              0   \n",
       "3J_0      2      20011           20011               1              0   \n",
       "3K_0      2      20117           20117               1              0   \n",
       "3L_0      2      19901           19901               1              0   \n",
       "\n",
       "      hetero_est  error_est  reads_consens  \n",
       "1A_0         NaN        NaN            NaN  \n",
       "1B_0         NaN        NaN            NaN  \n",
       "1C_0         NaN        NaN            NaN  \n",
       "1D_0         NaN        NaN            NaN  \n",
       "2E_0         NaN        NaN            NaN  \n",
       "2F_0         NaN        NaN            NaN  \n",
       "2G_0         NaN        NaN            NaN  \n",
       "2H_0         NaN        NaN            NaN  \n",
       "3I_0         NaN        NaN            NaN  \n",
       "3J_0         NaN        NaN            NaN  \n",
       "3K_0         NaN        NaN            NaN  \n",
       "3L_0         NaN        NaN            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyrad import assemble\n",
    "data2.step3([\"1A_0\"], preview=True, force=True)\n",
    "#assemble.cluster_within.derep_and_sort( data1, data1.samples[\"3L_0\"], 0 )\n",
    "data2.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#sample = data1.samples[\"3L_0\"]\n",
    "#handle = sample.files[\"edits\"]\n",
    "#print handle.replace(\".fasta\", \".derep\")\n",
    "data1.vsearch = \"/home/isaac/ipyrad-refseq/bin/vsearch-1.1.3-linux-x86_64\"\n",
    "data1.muscle = \"/home/isaac/ipyrad-refseq/bin/muscle3.8.31_i86linux64\"\n",
    "data1.smalt = \"/home/isaac/ipyrad-refseq/bin/smalt-0.7.6-linux-x86_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assemble.cluster_within.muscle_align( data1, data1.samples[\"1D_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.0\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 1024, 59049, 1048576, 9765625, 60466176, 282475249, 1073741824, 3486784401, 10000000000, 25937424601, 61917364224, 137858491849, 289254654976, 576650390625, 1099511627776, 2015993900449, 3570467226624, 6131066257801, 10240000000000, 16679880978201, 26559922791424, 41426511213649, 63403380965376, 95367431640625, 141167095653376, 205891132094649, 296196766695424, 420707233300201, 590490000000000, 819628286980801]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "print( ipyparallel.__version__)\n",
    "from ipyparallel import Client\n",
    "ipyclient = Client()\n",
    "print(ipyclient.ids)\n",
    "dview = ipyclient.load_balanced_view()\n",
    "parallel_result = dview.map_async(lambda x:x**10, range(32))\n",
    "print(parallel_result.get())\n",
    "#print(parallel_result)\n",
    "#res = dview.map_async(print, \"Hello, World\")\n",
    "#print(res)\n",
    "del dview\n",
    "ipyclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "['/private/tmp/ipyrad-test/test_edits/1A_0.fasta']\n"
     ]
    }
   ],
   "source": [
    "ipyclient = Client()\n",
    "print(ipyclient.ids)\n",
    "samp1=\"1A_0\"\n",
    "subsamples = []\n",
    "data2.samples[samp1].stats.state = 2\n",
    "subsamples.append((sample, data2.samples[samp1]))\n",
    "\n",
    "print data2.samples[samp1].files.edits\n",
    "assemble.cluster_within.run( data2, subsamples, ipyclient, True, True, True)\n",
    "ipyclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#data2.step2(force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipyrad.core.sample.Sample object at 0x112d8c990>\n",
      "preview: in run_full, using 4\n"
     ]
    }
   ],
   "source": [
    "# Debugging smalt code in cluster_within\n",
    "samp1=\"1A_0\"\n",
    "sample_obj=data2.samples[samp1]\n",
    "data2.samples[samp1].stats.state = 2\n",
    "sample = subsamples[0][1]\n",
    "print sample\n",
    "assemble.cluster_within.mapreads([data2, sample_obj, 1, 0, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/private/tmp/ipyrad-test/test_edits/1A_0.fasta']\n",
      "/usr/local/opt/anaconda/lib/python2.7/site-packages/ipyrad-0.0.65-py2.7.egg/bin/vsearch-1.1.3-osx-x86_64 -derep_fulllength /private/tmp/ipyrad-test/test_edits/1A_0.fasta  -output /private/tmp/ipyrad-test/test_edits/1A_0.derep -sizeout  -threads 4 -fasta_width 0\n"
     ]
    }
   ],
   "source": [
    "# Debug derep_and_sort\n",
    "samp1=\"1A_0\"\n",
    "sample_obj=data2.samples[samp1]\n",
    "data2.samples[samp1].stats.state = 2\n",
    "assemble.cluster_within.derep_and_sort(data2, sample_obj, 1, 4)\n",
    "print(sample_obj.files.edits)\n",
    "handle = sample_obj.files.edits[0]\n",
    "cmd = data2.vsearch+\\\n",
    "    \" -derep_fulllength \"+handle+\\\n",
    "    \" \"+\\\n",
    "    \" -output \"+os.path.join(data2.dirs.edits, sample_obj.name+\".derep\")+\\\n",
    "    \" -sizeout \"+\\\n",
    "    \" -threads \"+str(4)+\\\n",
    "    \" -fasta_width 0\"\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/tmp/ipyrad-test/test_edits/1A_0.fasta\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "samp1=\"1A_0\"\n",
    "sample=data2.samples[samp1]\n",
    "unmapped_fastq_handle=os.path.join(data2.dirs.edits, sample.name+\".fasta\")\n",
    "with open(os.path.realpath(unmapped_fastq_handle), 'rb') as fq:\n",
    "    quart1 = itertools.izip(*[iter(fq)]*4)\n",
    "    quarts = itertools.izip(quart1, iter(int, 1))\n",
    "    read1 = [i.strip() for i in quart[0]]\n",
    "    writing = []\n",
    "    while 1:\n",
    "        try:\n",
    "            quart = quarts.next()\n",
    "        except StopIteration:\n",
    "            break\n",
    "        read1 = [i.strip() for i in quart[0]]\n",
    "        sseq = \">\"+sample.name+\"_\"+str(0)+\\\n",
    "                           \"_c1\\n\"+read1[1]+\"\\n\"\n",
    "        writing.append(sseq)\n",
    "print(sample.files.edits[0])\n",
    "with open( sample.files.edits[0], 'w' ) as out:\n",
    "    out.write(\"\".join(writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/tmp/ipyrad-test/test_edits/3L_0.fastq\n"
     ]
    }
   ],
   "source": [
    "samp1=\"3L_0\"\n",
    "sample=data2.samples[samp1]\n",
    "unmapped_fastq_handle=os.path.join(data2.dirs.edits, sample.name+\".fastq\")\n",
    "print(unmapped_fastq_handle)\n",
    "if True:\n",
    "    writing = []\n",
    "    with open(os.path.realpath(unmapped_fastq_handle), 'rb') as fq:\n",
    "        quart1 = itertools.izip(*[iter(fq)]*4)\n",
    "        quarts = itertools.izip(quart1, iter(int, 1))\n",
    "        writing = []\n",
    "        while 1:\n",
    "            try:\n",
    "                quart = quarts.next()\n",
    "            except StopIteration:\n",
    "                break\n",
    "            read1 = [i.strip() for i in quart[0]]\n",
    "            sseq = \">\"+sample.name+\"_\"+str(0)+\\\n",
    "                           \"_c1\\n\"+read1[1]+\"\\n\"\n",
    "            writing.append(sseq)\n",
    "\n",
    "    with open( sample.files.edits[0], 'w' ) as out:\n",
    "        out.write(\"\".join(writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quart=[]\n",
    "quarts=[]\n",
    "quart1=[]\n",
    "nthreads=4\n",
    "preview=True\n",
    "samp1=\"3K_0\"\n",
    "sample=data2.samples[samp1]\n",
    "data=data2\n",
    "if True:\n",
    "    samhandle = os.path.join(data.dirs.edits, sample.name+\".sam\")\n",
    "    bamhandle = os.path.join(data.dirs.edits, sample.name+\".bam\")\n",
    "    unmapped_fastq_handle = os.path.join(data.dirs.edits, sample.name+\".fastq\")\n",
    "\n",
    "    ## get call string\n",
    "    cmd = data.smalt+\\\n",
    "        \" map -f sam -n \" + str(nthreads) +\\\n",
    "        \" -o \" + samhandle +\\\n",
    "        \" \" + data.get_params(27) +\\\n",
    "        \" \" + sample.files.fastq[0]\n",
    "\n",
    "    ## run smalt\n",
    "    if preview:\n",
    "        ## make this some kind of wait command that kills after a few mins\n",
    "        subprocess.call(cmd, shell=True,\n",
    "                             stderr=subprocess.STDOUT,\n",
    "                             stdout=subprocess.PIPE)\n",
    "    else:\n",
    "        subprocess.call(cmd, shell=True,\n",
    "                             stderr=subprocess.STDOUT,\n",
    "                             stdout=subprocess.PIPE)\n",
    "\n",
    "    cmd = data.samtools+\\\n",
    "        \" view -b -f 0x4 \"+samhandle+\\\n",
    "            \" > \" + bamhandle\n",
    "    subprocess.call(cmd, shell=True,\n",
    "                         stderr=subprocess.STDOUT,\n",
    "                         stdout=subprocess.PIPE)\n",
    "\n",
    "    cmd = data.samtools+\\\n",
    "        \" sort -T \"+samhandle+\".tmp\" +\\\n",
    "        \" -O bam \"+bamhandle+\\\n",
    "        \" -o \"+bamhandle+\".sorted\"\n",
    "    subprocess.call(cmd, shell=True,\n",
    "                         stderr=subprocess.STDOUT,\n",
    "                         stdout=subprocess.PIPE)\n",
    "    cmd = data.samtools+\\\n",
    "        \" bam2fq \"+bamhandle+\".sorted\"+\\\n",
    "        \" > \"+unmapped_fastq_handle\n",
    "    subprocess.call(cmd, shell=True,\n",
    "                         stderr=subprocess.STDOUT,\n",
    "                         stdout=subprocess.PIPE)\n",
    "\n",
    "    ## This is hax to get fastq to fasta to get this off the ground.\n",
    "    ## samtools bam2fq natively returns fastq, you just delete this code\n",
    "    ## when fastq pipleline is working\n",
    "    writing = []\n",
    "    with open(os.path.realpath(unmapped_fastq_handle), 'rb') as fq:\n",
    "        quart1 = itertools.izip(*[iter(fq)]*4)\n",
    "        quarts = itertools.izip(quart1, iter(int, 1))\n",
    "        writing = []\n",
    "        while 1:\n",
    "            try:\n",
    "                quart = quarts.next()\n",
    "            except StopIteration:\n",
    "                break\n",
    "            read1 = [i.strip() for i in quart[0]]\n",
    "            sseq = \">\"+sample.name+\"_\"+str(0)+\\\n",
    "                           \"_c1\\n\"+read1[1]+\"\\n\"\n",
    "            writing.append(sseq)\n",
    "\n",
    "    with open( sample.files.edits[0], 'w' ) as out:\n",
    "        out.write(\"\".join(writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
