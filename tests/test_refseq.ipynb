{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _ipyrad_ testing tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Import _ipyrad_ and remove previous test files if they are already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.65\n"
     ]
    }
   ],
   "source": [
    "## import modules\n",
    "import ipyrad as ip      ## for RADseq assembly\n",
    "print ip.__version__     ## print version\n",
    "\n",
    "## clear data from test directory if it already exists\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "#if os.path.exists(\"./test_refseq/\"):\n",
    "#    shutil.rmtree(\"./test_refseq/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize smalt (index reference sequence)\n",
    "This is preparation for indexing. It only ever needs to be done once so shoud be tested during initialization.\n",
    "\n",
    "`smalt index zf-ref ../zf/zf.sm.fa`\n",
    "\n",
    "There is an optional -s flag that could improve mapping accuracy. Consider the best default, probably not worth letting people pass it in, if they want to mess with it they can index their own reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1A_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eee2dfa41c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# TODO: create and link index files to Sample objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1A_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_smi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1A_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_sma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1A_0'"
     ]
    }
   ],
   "source": [
    "# hack the binary paths cuz the current egg doesn't have them in it\n",
    "#data1.muscle=\n",
    "#data1.vsearch\n",
    "#data1.smalt\n",
    "\n",
    "# Reference sequence directory (gzipped fasta files)\n",
    "# TODO: set this as a parameter\n",
    "# e.g., data1.set_params('refseq', \"./data/zf.fa.gz\")\n",
    "\n",
    "# TODO: push this example file to the data/ dir \n",
    "REFSEQ = \"./data/zf.fa.gz\"\n",
    "\n",
    "# Set the step size to 4 (default is 13)\n",
    "# This will slow down read mapping, but increase accuracy\n",
    "SMALT_INDEX_FLAGS = \" -s 4 \"\n",
    "\n",
    "# TODO: create and link a dir/ to the Assembly object for the reference data files\n",
    "data1.dirs.reference = '...'\n",
    "\n",
    "# TODO: create and link index files to Sample objects\n",
    "data1.samples['1A_0'].files.index_smi = '...'\n",
    "data1.samples['1A_0'].files.index_sma = '...'\n",
    "\n",
    "# Test if reference sequence is already indexed\n",
    "# Only index if the .smi and .sma files don't exist, saves lots of time\n",
    "if not os.path.isfile( REFSEQ+\".smi\" ):\n",
    "    # smalt indexing will create two files called REFSEQ.smi and .sma\n",
    "    # in the same directory as the reference sequence. \n",
    "    cmd = data1.smalt + \" index \" + SMALT_INDEX_FLAGS + REFSEQ + \" \" + REFSEQ\n",
    "    print cmd\n",
    "    subprocess.check_call(cmd, shell=True,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            stdout=subprocess.PIPE)\n",
    "    #output = subprocess.check_output( \" \".join(cmd), shell=True)\n",
    "else:\n",
    "    print \"Reference sequence index exists\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly and Sample objects\n",
    "\n",
    "Assembly and Sample objects are used by _ipyrad_ to access data stored on disk and to manipulate it. Each biological sample in a data set is represented in a Sample object, and these Samples are stored inside Assembly objects. The Assembly object contains functions to assemble the data, and stores a log of all steps performed and the resulting statistics of those steps. Assembly objects can be copied or merged to allow branching events where different parameters are applied to assemblies. \n",
    "\n",
    "To create an Assembly object call ip.Assembly and pass it a name for the data set. We could imagine that we planned to assemble and later combine data from multiple sequencing runs, but before combining them each group of samples has to be analyzed under a different set of parameters. As an example, we could call two data sets \"2014_data\" and \"2015_data\". These initially do not contain any Samples. Sample objects are created either by linking fastq files to the Assembly object or by running step 1 to demultiplex raw data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0 new Samples created in 2014_data.\n",
      "0 fastq files linked to Samples.\n",
      "[]\n",
      "0 new Samples created in 2015_data.\n",
      "0 fastq files linked to Samples.\n",
      "Assembly object named 2014_data\n",
      "Assembly object named 2015_data\n"
     ]
    }
   ],
   "source": [
    "## create an Assembly object called data1. \n",
    "## It takes an 'test'\n",
    "data1 = ip.Assembly(\"2014_data\")\n",
    "data2 = ip.Assembly(\"2015_data\")\n",
    "\n",
    "print \"Assembly object named\", data1.name\n",
    "print \"Assembly object named\", data2.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying assembly parameters\n",
    "All of the parameter settings are linked to an Assembly object, which has a set of default parameters when it is created. These can be viewed using the `get_params()` function. To get more detailed information about all paramteres use `ip.get_params_info()` or to select a single parameter use `ip.get_params_info(3)`. Assembly objects have a function `set_params()` that can be used to modify parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   working_directory             ./test_refseq                                \n",
      "  2   raw_fastq_path                ./data/sim_rad_test_R1_.fastq.gz             \n",
      "  3   barcodes_path                 ./data/sim_rad_test_barcodes.txt             \n",
      "  4   sorted_fastq_path                                                          \n",
      "  5   restriction_overhang          ('TGCAG', '')                                \n",
      "  6   max_low_qual_bases            5                                            \n",
      "  7   N_processors                  3                                            \n",
      "  8   mindepth_statistical          6                                            \n",
      "  9   mindepth_majrule              6                                            \n",
      "  10  datatype                      rad                                          \n",
      "  11  clust_threshold               0.85                                         \n",
      "  12  minsamp                       4                                            \n",
      "  13  max_shared_heterozygosity     0.25                                         \n",
      "  14  prefix_outname                2014_data                                    \n",
      "  15  phred_Qscore_offset           33                                           \n",
      "  16  max_barcode_mismatch          1                                            \n",
      "  17  filter_adapters               0                                            \n",
      "  18  filter_min_trim_len           35                                           \n",
      "  19  ploidy                        2                                            \n",
      "  20  max_stack_size                1000                                         \n",
      "  21  max_Ns_consens                5                                            \n",
      "  22  max_Hs_consens                8                                            \n",
      "  23  max_SNPs_locus                (100, 100)                                   \n",
      "  24  max_Indels_locus              (5, 99)                                      \n",
      "  25  trim_overhang                 (1, 2, 2, 1)                                 \n",
      "  26  hierarchical_clustering       0                                            \n",
      "  27  reference_sequence                                                         \n"
     ]
    }
   ],
   "source": [
    "## modify parameters for this Assembly object\n",
    "data1.set_params(1, \"./test_refseq\")\n",
    "data1.set_params(2, \"./data/sim_rad_test_R1_.fastq.gz\")\n",
    "data1.set_params(3, \"./data/sim_rad_test_barcodes.txt\")\n",
    "data1.set_params(7, 3)\n",
    "data1.set_params(10, 'rad')\n",
    "#data1.set_params(27, '/Volumes/WorkDrive/ipyrad/refhacking/MusChr1.fa')\n",
    "\n",
    "## print the new parameters to screen\n",
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting data assembly and Sample objects\n",
    "If the data are already demultiplexed then fastq files can be linked directly to the Data object, which in turn will create Sample objects for each fastq file (or pair of fastq files for paired data). The files may be gzip compressed. If the data are not demultiplexed then you will have to run the step1 function below to demultiplex the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0 new Samples created in 2014_data.\n",
      "0 fastq files linked to Samples.\n"
     ]
    }
   ],
   "source": [
    "## This would link fastq files from the 'sorted_fastq_path' if present\n",
    "## Here it does nothing b/c there are no files in the sorted_fastq_path\n",
    "data1.link_fastqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Demultiplex the raw data files\n",
    "This uses the barcodes information to demultiplex reads in data files found in the 'raw_fastq_path'. It will create a Sample object for each sample that will be stored in the Assembly object. The state of each sample will be set to 1, meaning that the sample has completed step 1 of the _ipyrad_ assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state  reads_raw  reads_filtered  clusters_total  clusters_kept  \\\n",
      "1A_0      1      20099             NaN             NaN            NaN   \n",
      "1B_0      1      19977             NaN             NaN            NaN   \n",
      "1C_0      1      20114             NaN             NaN            NaN   \n",
      "1D_0      1      19895             NaN             NaN            NaN   \n",
      "2E_0      1      19928             NaN             NaN            NaN   \n",
      "2F_0      1      19934             NaN             NaN            NaN   \n",
      "2G_0      1      20026             NaN             NaN            NaN   \n",
      "2H_0      1      19936             NaN             NaN            NaN   \n",
      "3I_0      1      20084             NaN             NaN            NaN   \n",
      "3J_0      1      20011             NaN             NaN            NaN   \n",
      "3K_0      1      20117             NaN             NaN            NaN   \n",
      "3L_0      1      19901             NaN             NaN            NaN   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0         NaN        NaN            NaN  \n",
      "1B_0         NaN        NaN            NaN  \n",
      "1C_0         NaN        NaN            NaN  \n",
      "1D_0         NaN        NaN            NaN  \n",
      "2E_0         NaN        NaN            NaN  \n",
      "2F_0         NaN        NaN            NaN  \n",
      "2G_0         NaN        NaN            NaN  \n",
      "2H_0         NaN        NaN            NaN  \n",
      "3I_0         NaN        NaN            NaN  \n",
      "3J_0         NaN        NaN            NaN  \n",
      "3K_0         NaN        NaN            NaN  \n",
      "3L_0         NaN        NaN            NaN  \n"
     ]
    }
   ],
   "source": [
    "## run step 1 to demultiplex the data\n",
    "data1.step1()\n",
    "\n",
    "## print the results for each Sample in data1\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter reads \n",
    "If for some reason we wanted to execute on just a subsample of our data, we could do this by selecting only certain samples to call the `step2` function on. Because `step2` is a function of `data`, it will always execute with the parameters that are linked to `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## example of ways to run step 2 to filter and trim reads\n",
    "#data1.step2(\"1A_0\")            ## run on a single sample\n",
    "data1.step2([\"1B_0\", \"1C_0\"])  ## run on one or more samples\n",
    "#data1.step2()                  ## run on all samples, skipping finished ones\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the read mapping (SE)\n",
    "Here's an example cmdline run with args explained below:\n",
    "\n",
    "smalt map -f sam -n 8 -l pp -o Arremon.sam zf-ref ../MarTum-fasta/ArremonR1.fa ../MarTum-fasta/ArremonR2.fa\n",
    "\n",
    "* -f sams - you can also output as 'bam' but it requires installing bambamc which is explained in the smalt docs, but which seems annoying, esp cuz samtools will do it for us.\n",
    "* -n sets the number of threads to 8, dramatically increases speed\n",
    "* -l pp tells smalt about the orientation of the paired reads, in this case pp means both reads are on the same strand in the 5' to 3' direction, I think the second read was originally from the second strand and pyrad reverse complemented it.\n",
    "* -o is the outfile\n",
    "* Next is the indexed reference sequence and the files containing reads\n",
    "\n",
    "Other options to look into:\n",
    "* -y minid Filters output alignments by a threshold in the number of exactly\n",
    "matching nucleotides.\n",
    "* -r seed Determines how reads or mate pairs with multiple best mappings are\n",
    "reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data1.paramsdict[\"working_directory\"]\n",
    "data1.dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = \"/tmp/wat\"\n",
    "\n",
    "# Check the input files\n",
    "SMALT_CMD = \"check \"\n",
    "## the read1 demultiplexed reads file\n",
    "fr1 = data1.get_params(1)+\"/fastq/1A_0_R1_.gz\"\n",
    "#data1.smalt = \"/usr/local/bin/smalt\"\n",
    "cmd = data1.smalt + \" \" + SMALT_CMD + \" \" + fr1\n",
    "print cmd\n",
    "subprocess.call(cmd, shell=True,\n",
    "                     stderr=subprocess.STDOUT,\n",
    "                     stdout=subprocess.PIPE)\n",
    "\n",
    "SMALT_CMD = \"map -f sam -n 8 -o \" + output\n",
    "## the read1 demultiplexed reads file\n",
    "\n",
    "## TODO: I recommend using parameter descriptions rather than numbers\n",
    "## in the code so it is more robust to potential reordering of parameters\n",
    "fr1 = data1.get_params('working_directory')+\"/fastq/1A_0_R1_.gz\"\n",
    "\n",
    "cmd = data1.smalt + \" \" + SMALT_CMD + \" \" + REFSEQ + \" \" + fr1\n",
    "print cmd\n",
    "subprocess.call(cmd, shell=True,\n",
    "                     stderr=subprocess.STDOUT,\n",
    "                     stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mapped and unmapped reads\n",
    "\n",
    "First get some info about our mapping.\n",
    "\n",
    "    samtools flagstat <yoursam>\n",
    "\n",
    "Get only the mapped reads. 0x4 is a bitmask for 'unmapped' reads, -F means get all not this mask. In both cases -b outputs as bam\n",
    "\n",
    "    samtools view -b -F 0x4 <your.sam> > mapped.bam\n",
    "\n",
    "Same as above, but in this case -f means just give me the ones with this flag set.\n",
    "\n",
    "    samtools view -b -f 0x4 <your.sam> > unmapped.bam\n",
    "\n",
    "## \n",
    "\n",
    "samtools sort -T /tmp/wat -O bam test.mapped.bam > test.mapped.sorted.bam\n",
    "samtools bam2fq test.mapped.sorted.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deren/Dropbox/ipyrad/bin/muscle3.8.31_i86linux64\n",
      "/home/deren/Dropbox/ipyrad/bin/vsearch-1.1.3-linux-x86_64\n",
      "/home/deren/Dropbox/ipyrad/bin/smalt-0.7.6-linux-x86_64\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "\n",
    "#This is junk\n",
    "\n",
    "print data1.muscle\n",
    "print data1.vsearch\n",
    "print data1.smalt\n",
    "print data1.samples[\"1B_0\"].files.edits\n",
    "#bam2py(\"\")\n",
    "#pysam.view(\"-b\", \"-S\", \"-o\") #, INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".sam\", catch_stdout=False)\n",
    "#pysam.sort( \"-O\", \"bam\", \"-o\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", \"-T\", \"tempfile\", INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", catch_stdout=False)\n",
    "#pysam.index( INDIVIDUALS_WORK_DIR+species+\"/\"+ind+\"-\"+refseq.split(\"/\")[-1]+\".bam\", catch_stdout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: clustering within-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## run step 3 to cluster reads within samples using vsearch\n",
    "#data1.step3(preview=1) #[\"2H_0\", \"2G_0\"], preview=1)\n",
    "data1.step3([\"1B_0\", \"1C_0\"], preview=1)\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of plotting with _ipyrad_\n",
    "There are a a few simple plotting functions in _ipyrad_ useful for visualizing results. These are in the module `ipyrad.plotting`. Below is an interactive plot for visualizing the distributions of coverages across the 12 samples in the test data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "import ipyrad.plotting as iplot\n",
    "\n",
    "## reload autosaved data. In case you quit and came back \n",
    "#data1 = ip.load_dataobj(\"test_rad/2014_data.dataobj\")\n",
    "\n",
    "## plot for one or more selected samples\n",
    "iplot.depthplot(data1, [\"1A_0\", \"1B_0\"])\n",
    "\n",
    "## plot for all samples in data1\n",
    "#iplot.depthplot(data1)\n",
    "\n",
    "## save plot as pdf and html\n",
    "iplot.depthplot(data1, outprefix=\"testfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Joint estimation of heterozygosity and error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## run step 4\n",
    "data1.step4() #\"2H_0\", \"2G_0\")\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Consensus base calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run step 5\n",
    "data1.step5([\"2H_0\"])\n",
    "\n",
    "## print the results\n",
    "print data1.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick parameter explanations are always on-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip.get_params_info(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history \n",
    "A common problem after struggling through an analysis is that you find you've completely forgotten what parameters you used at what point, and when you changed them. The log history time stamps all calls to `set_params()`, as well as calls to `step` methods. It also records copies/branching of data objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data1.log:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Assembly objects\n",
    "Assembly objects can be saved and loaded so that interactive analyses can be started, stopped, and returned to quite easily. The format of these saved files is a serialized 'dill' object used by Python. Individual Sample objects are saved within Assembly objects. These objects to not contain the actual sequence data, but only link to it, and so are not very large. The information contained includes parameters and the log of Assembly objects, and the statistics and state of Sample objects. Assembly objects are autosaved each time an assembly `step` function is called, but you can also create your own checkpoints with the `save` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save assembly object\n",
    "#ip.save_assembly(\"data1.p\")\n",
    "\n",
    "## load assembly object\n",
    "#data = ip.load_assembly(\"data1.p\")\n",
    "#print data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyrad import assemble\n",
    "\n",
    "assemble.cluster_within.derep_and_sort( data1, data1.samples[\"3L_0\"], 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample = data1.samples[\"3L_0\"]\n",
    "#handle = sample.files[\"edits\"]\n",
    "#print handle.replace(\".fasta\", \".derep\")\n",
    "data1.vsearch = \"/home/isaac/ipyrad-refseq/bin/vsearch-1.1.3-linux-x86_64\"\n",
    "data1.muscle = \"/home/isaac/ipyrad-refseq/bin/muscle3.8.31_i86linux64\"\n",
    "data1.smalt = \"/home/isaac/ipyrad-refseq/bin/smalt-0.7.6-linux-x86_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assemble.cluster_within.muscle_align( data1, data1.samples[\"1D_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print data1.paramsdict[\"sorted_fastq_path\"]\n",
    "data1.stats\n",
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data1.get_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
