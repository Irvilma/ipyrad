{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species-tree & species-delimitation using *bpp* (BP&P) or *ibpp*\n",
    "The program *bpp* by Rannala & Yang (2010; 2015) is a powerful tool for inferring species tree parameters and testing species delimitation hypotheses. It is *relatively* easy to use, and best of all, it's *quite fast*, although not easily parallelizable. This notebook describes a streamlined approach we've developed to easily setup input files for testing different hypthotheses in *bpp*, and to do so in a clear programmatic way that makes it easy to perform many tests over many different parameter settings. We also show how to submit many separate jobs to run in parallel on a cluster. This approach also works with the program *ibpp*, which allows integration of traits with sequence data. \n",
    "\n",
    "### Using Jupyter notebooks\n",
    "If you have not used Jupyter notebooks before, please see the other documentation for an introduction. This is a Jupyter notebook which contains documented code, in this case all Python, that can be used to replicate an analysis. The purpose of these notebooks is to produce a reproducible document that is easy to share, reproduce, and/or use as supplemental materials, by simply uploading it to a site such as github. You can execute the code in the cells to reproduce our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyrad v.0.5.10\n"
     ]
    }
   ],
   "source": [
    "## Start by importing a few python modules\n",
    "import ipyrad\n",
    "import ipyparallel as ipp\n",
    "import subprocess\n",
    "import socket\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## print versions\n",
    "print \"ipyrad v.{}\".format(ipyrad.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a new directory to store our tutorial files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make a new directory in our current directory called analysis_bpp/\n",
    "WDIR = \"./analysis_bpp\"\n",
    "if not os.path.exists(WDIR):\n",
    "    os.mkdir(WDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and install *bpp* v.3.3 locally (only tested on Linux)\n",
    "Copy and paste the code from the link below into a terminal (or a cell in this notebook along with a %%bash header) to install *bpp* locally. This will create a new directory if it does not already exist in `~/local/src/` and install *bpp* from source. This creates a binary file called **bpp**. Because we are installing it locally *you do not need administrator privileges to install it*. When finished it will print out the location where it is installed, which is `~/local/bin/bpp`. https://gist.github.com/dereneaton/73a377c643adaddc83635506a81180af\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Install *ibpp* (v.2.1)\n",
    "The *ibpp* installation follows a similar procedure and is installed in the same place. The source code in this case is downloaded (cloned) from github, so you will need to have the software *git* installed/loaded. This is usually available by default on a linux machine, and/or HPC cluster. Execute the code here, which will print out the location where it is installed `~/local/bin/ibpp`. https://gist.github.com/dereneaton/527b87488eede7b670222640fe26878d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input files (.seq.txt, .imap.txt, .ctl.txt, and .traits.txt) \n",
    "To run *bpp/ibpp* requires at least three input files, of which the CTL file is the most important, as it points to the location of the other files. We can create these files fairly easily by parsing the sequence information from the `.loci` file produced by ipyrad, and by providing some additional information about which samples should be grouped together into the same \"species\" using Python dictionaries. \n",
    "\n",
    "I show an example of this below, using a function from the ipyrad API (`loci2bpp`) that we've created for this purpose. This will create all of the dependency files for a bpp analysis. The first is the IMAP file (*.bpp.imap.txt*), which simply maps sample names to species groups. The second is the SEQ file (*.bpp.seq.txt*), which obviously contains the sequence data, properly formatted. And the third is the CTL file (*.bpp.ctl.txt*), which contains parameters for the bpp analysis. A final optional TRAITS file can also be produced for ibpp analyses. \n",
    "\n",
    "The `loci2bpp()` function contains many additional options for filtering loci or samples from the sequence data. For example, you can pass it arguments to keep only loci that have at least N samples in each species, or to keep only N total loci. It also removes any sample from the sequence data set that is not listed in your IMAP dictionary. You can set all of the CTL parameters using this function. We'll start by creating an IMAP dictionary that matches 'species' names to lists of sample names belonging to each species, a TREE stating our species tree hypothesis as a newick string, and one optional arguments that is likely to be used very often with RAD-seq data, the MINMAP dictionary. Much further down in this notebook we also show how to incorporate traits into a ibpp analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a mapping dictionary\n",
    "## The keys are 'species', i.e., clades/groups for your samples, \n",
    "## The values are lists of sample names that belong to each group\n",
    "\n",
    "IMAP = {\"A\": [\"1A_0\", \"1B_0\", \"1C_0\", \"1D_0\"], \n",
    "        \"B\": [\"2E_0\", \"2F_0\", \"2G_0\", \"2H_0\"],\n",
    "        \"C\": [\"3I_0\", \"3J_0\", \"3K_0\", \"3L_0\"]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Then you must write your tree hypothesis as a newick string.\n",
    "## This must include all 'species' names in the imap dictionary\n",
    "\n",
    "TREE = \"((A,B),C);\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(Optional): You can further designate an additional dictionary that will be used to subsample loci for inclusion in the *bpp* analysis. Below I call this dictionary MINMAP, and it will be used to filter loci so that we only include loci in the analysis that have at least N taxa with sequence data in a locus for each given 'species' group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## (Optional) Minimum sampling map\n",
    "## The keys are 'species', i.e., clade/group names \n",
    "## The values are the number of samples in each 'species' that must have data\n",
    "## for a given locus for it to be included in the data set. \n",
    "\n",
    "MINMAP = {\"A\": 4, \n",
    "          \"B\": 4, \n",
    "          \"C\": 4,\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run loci2bpp() to generate bpp input files\n",
    "The `loci2bpp()` function has four required arguments, a name, a LOCI file, an IMAP dictionary, and a TREE hypothesis. For additional arguements see documentation for the function by typing `?ipyrad.file_conversion.loci2bpp()` into a cell. We also have more examples below. The function returns the CTL filename as a string, which you will see later can be quite useful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ctl file\n",
      "--------\n",
      "seed = 12345\n",
      "seqfile = /home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.seq.txt\n",
      "Imapfile = /home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.imap.txt\n",
      "mcmcfile = /home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.mcmc.txt\n",
      "outfile = /home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.out.txt\n",
      "nloci = 1000\n",
      "usedata = 1\n",
      "cleandata = 0\n",
      "speciestree = 0\n",
      "speciesdelimitation = 0 0 5\n",
      "species&tree = 3 A C B\n",
      "                 4 4 4\n",
      "                 ((A,B),C);\n",
      "thetaprior = 5 5\n",
      "tauprior = 4 2 1\n",
      "finetune = 1: 1 0.002 0.01 0.01 0.02 0.005 1.0\n",
      "print = 1 0 0 0\n",
      "burnin = 1000\n",
      "sampfreq = 2\n",
      "nsample = 10000\n",
      "--------\n",
      "\n",
      "new files created (1000 loci, 3 species, 12 samples)\n",
      "  test.bpp.seq.txt\n",
      "  test.bpp.imap.txt\n",
      "  test.bpp.ctl.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.ctl.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## enter the path to your loci file\n",
    "LOCI = \"/home/deren/Documents/ipyrad/tests/cli/cli_outfiles/cli.loci\"\n",
    "\n",
    "## create bpp seq file with data for all samples in the loci file and IMAP dict.\n",
    "## if you tell it verbose=True then it will also print the ctl file info to the screen\n",
    "ipyrad.file_conversion.loci2bpp('test', LOCI, IMAP, TREE, \n",
    "                                wdir=WDIR, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOTS of extra arguments are available in *loci2bpp()*\n",
    "These can be used to filter the loci that will be included in the data set, as well as to modify the parameters that will be used in *bpp* and which are specified in the *.ctl* file. The *.ctl* file has a large range of options, and so for some advanced usage you may still need to modify the file by hand, but our intention with this function is to at least provide a fairly easy to use function to produce these files programatically, instead of having to always produce them by hand. You can see in the final example that we provided the traits dictionary, and that loci2bpp() created an extra .traits.txt file, and that all of the files produced have ibpp in their names instead of bpp. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (1000 loci, 3 species, 12 samples)\n",
      "  test.bpp.seq.txt\n",
      "  test.bpp.imap.txt\n",
      "  test.bpp.ctl.txt\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  test.bpp.seq.txt\n",
      "  test.bpp.imap.txt\n",
      "  test.bpp.ctl.txt\n",
      "new files created (1000 loci, 3 species, 12 samples)\n",
      "  test.bpp.seq.txt\n",
      "  test.bpp.imap.txt\n",
      "  test.bpp.ctl.txt\n",
      "new files created (1000 loci, 3 species, 12 samples)\n",
      "  test.bpp.seq.txt\n",
      "  test.bpp.imap.txt\n",
      "  test.bpp.ctl.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/ipyrad/tests/analysis_bpp/test.bpp.ctl.txt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create bpp seq file with data for all samples in the loci file and IMAP dict\n",
    "ipyrad.file_conversion.loci2bpp('test', LOCI, IMAP, TREE, wdir=WDIR)\n",
    "\n",
    "## Create bpp file with only the first 100 loci\n",
    "ipyrad.file_conversion.loci2bpp('test', LOCI, IMAP, TREE, wdir=WDIR, maxloci=100)\n",
    "\n",
    "## Only keep loci that have at least MINMAP samples for each species\n",
    "ipyrad.file_conversion.loci2bpp('test', LOCI, IMAP, TREE, wdir=WDIR, minmap=MINMAP)\n",
    "\n",
    "## Only keep loci that have at least MINMAP samples for each species\n",
    "## and write the ctl file so that we perform species delimitation\n",
    "ipyrad.file_conversion.loci2bpp('test', LOCI, IMAP, TREE, minmap=MINMAP, wdir=WDIR,\n",
    "                                infer_delimit=1, delimit_alg=(0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?\n",
    "You could of course alternatively create all of the bpp input files by hand but trust me, it's a pain. Besides, by making it programmatic in this way you can easily create a variety of input files for different jobs with different parameter settings. Furthermore, it will be easy to share your code with others to show how you created a range of analyses. It's certainly much easier to share a bit of code than it is to share 20 different ctl files that you produced. Below we show an example where we create bpp input files for a range of parameter values and submit them to run in parallel on a cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I don't want to run parallel jobs?\n",
    "Simple. You can just call bpp or ibpp on a single *.ctl.txt* file at a time. I would recommend running parallel code, however, since each job takes pretty long to run, and each bpp job can only run on a single CPU at a time. Although we can't parallelize a single run of *bpp*, we can run many jobs simultaneously, allowing us to test a bunch of different priors, or delimitation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## %%bash\n",
    "\n",
    "## I've commented the code out, but you could uncomment it to run a single job.\n",
    "## The '2>&1 bpp-log.txt` part saves all of the output to a file instead of to the screen \n",
    "# bpp test.ctl.txt 2>&1 bpp-log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a parallel client to submit parallel jobs through this notebook\n",
    "We need to know a few tricks to submit parallel jobs from this jupyter notebook. This is all handled by the ipyparallel library, which we loaded at the top of this notebook. We have a separate tuturial with more background about using ipyparallel. You will need to have an 'ipcluster' instance running in a separate terminal on your machine (or ideally, it is running on your HPC cluster). The code below simply connects to that cluster and prints how many CPUs are available for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute node: [4 cores] on oud\n"
     ]
    }
   ],
   "source": [
    "## Connect to the running ipcluster instance\n",
    "## (you need to start it in a separate terminal)\n",
    "ipyclient = ipp.Client()\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "\n",
    "## print some information about our cluster\n",
    "res = ipyclient[:].apply(socket.gethostname)\n",
    "for host in set(res.result_dict.values()):\n",
    "    print \"compute node: [{} cores] on {}\"\\\n",
    "          .format(res.result_dict.values().count(host), host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to run bpp/ibpp\n",
    "This function simply calls the bpp/ibpp binary. If you installed your binaries into a different location than the default in the install scripts at the beginning of this notebook then you will have to change the path to the binaries in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_bpp(ctlfile):\n",
    "    \"\"\" run bpp command line program \"\"\"\n",
    "    import subprocess, os\n",
    "    \n",
    "    ## binary paths\n",
    "    bpp = os.path.expanduser(\"~/local/bin/bpp\")\n",
    "    ibpp = os.path.expanduser(\"~/local/bin/ibpp\")\n",
    "    \n",
    "    ## which one to use\n",
    "    if \".ibpp\" in ctlfile:\n",
    "        cmd = [ibpp, ctlfile]\n",
    "    else:\n",
    "        cmd = [bpp, ctlfile]\n",
    "        \n",
    "    ## call the command\n",
    "    proc = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n",
    "    proc.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit jobs to run in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want each jobs that we submit to have a unique name. The code below is creating new jobs over a range of theta and tau prior values, and creating a name (rname) that stores those values, and passing these to the loci2bpp function to create new input files, and then it is submitting those jobs to run on the cluster. You could edit this code to iterate over a different range of parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a range of theta params (alpha, beta) to test over\n",
    "THETAS = [(5, 5), (5, 50), (5, 500)]\n",
    "\n",
    "## a range of tau params (alpha, beta, dirich) to test over\n",
    "TAUS = [(1, 1, 1), (1, 10, 1), (1, 100, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-5-1-1-1.bpp.seq.txt\n",
      "  TEST-5-5-1-1-1.bpp.imap.txt\n",
      "  TEST-5-5-1-1-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-5-1-1-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-5-1-10-1.bpp.seq.txt\n",
      "  TEST-5-5-1-10-1.bpp.imap.txt\n",
      "  TEST-5-5-1-10-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-5-1-10-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-5-1-100-1.bpp.seq.txt\n",
      "  TEST-5-5-1-100-1.bpp.imap.txt\n",
      "  TEST-5-5-1-100-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-5-1-100-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-50-1-1-1.bpp.seq.txt\n",
      "  TEST-5-50-1-1-1.bpp.imap.txt\n",
      "  TEST-5-50-1-1-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-50-1-1-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-50-1-10-1.bpp.seq.txt\n",
      "  TEST-5-50-1-10-1.bpp.imap.txt\n",
      "  TEST-5-50-1-10-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-50-1-10-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-50-1-100-1.bpp.seq.txt\n",
      "  TEST-5-50-1-100-1.bpp.imap.txt\n",
      "  TEST-5-50-1-100-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-50-1-100-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-500-1-1-1.bpp.seq.txt\n",
      "  TEST-5-500-1-1-1.bpp.imap.txt\n",
      "  TEST-5-500-1-1-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-500-1-1-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-500-1-10-1.bpp.seq.txt\n",
      "  TEST-5-500-1-10-1.bpp.imap.txt\n",
      "  TEST-5-500-1-10-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-500-1-10-1.bpp.ctl.txt\n",
      "\n",
      "new files created (100 loci, 3 species, 12 samples)\n",
      "  TEST-5-500-1-100-1.bpp.seq.txt\n",
      "  TEST-5-500-1-100-1.bpp.imap.txt\n",
      "  TEST-5-500-1-100-1.bpp.ctl.txt\n",
      "job submitted: bpp /home/deren/Documents/ipyrad/tests/TEST-5-500-1-100-1.bpp.ctl.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## a dictionary to store our results in\n",
    "asyncs = {}\n",
    "\n",
    "## send jobs to run 'asynchronously' using 'apply' over a range of values\n",
    "for theta in THETAS:\n",
    "    for tau in TAUS:\n",
    "        \n",
    "        ## name this run by its theta and tau params\n",
    "        rname = 'TEST-{}-{}-{}-{}-{}'.format(*theta+tau)\n",
    "    \n",
    "        ## create input files for this run, the function returns the ctl\n",
    "        ## file name as a string, which we will store and use below\n",
    "        ctlfile = ipyrad.file_conversion.loci2bpp(rname, LOCI, IMAP, TREE, \n",
    "                                                  wdir=WDIR,\n",
    "                                                  thetaprior=theta, \n",
    "                                                  tauprior=tau, \n",
    "                                                  nsample=100000, \n",
    "                                                  burnin=10000,\n",
    "                                                  maxloci=100)\n",
    "\n",
    "        ## submit job to the queue with ctlfile as the argument\n",
    "        asyncs[ctlfile] = lbview.apply(run_bpp, ctlfile)\n",
    "        \n",
    "        ## print that the job was submitted\n",
    "        sys.stderr.write('job submitted: bpp {}\\n\\n'.format(ctlfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress\n",
    "You could interrupt and/or restart this progress tracker without it interrupting the jobs that are running on the ipcluster engines. As you can see, we can still continue to work in this notebook while these jobs are running. We will have to wait for them to finish before we move on to analyzing the results, however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST-5-50-1-1-1.bpp.ctl.txt    -- finished\n",
      "TEST-5-500-1-10-1.bpp.ctl.txt  -- still running\n",
      "TEST-5-50-1-10-1.bpp.ctl.txt   -- still running\n",
      "TEST-5-500-1-1-1.bpp.ctl.txt   -- still running\n",
      "TEST-5-5-1-1-1.bpp.ctl.txt     -- finished\n",
      "TEST-5-5-1-10-1.bpp.ctl.txt    -- finished\n",
      "TEST-5-500-1-100-1.bpp.ctl.txt -- still running\n",
      "TEST-5-50-1-100-1.bpp.ctl.txt  -- still running\n",
      "TEST-5-5-1-100-1.bpp.ctl.txt   -- finished\n"
     ]
    }
   ],
   "source": [
    "## check success/failure of jobs\n",
    "for job in asyncs:\n",
    "    ## get shorter name for job\n",
    "    jobname = job.split(\"/\")[-1]\n",
    "    \n",
    "    ## print done or not\n",
    "    if asyncs[job].ready():\n",
    "        if asyncs[job].successful():\n",
    "            print \"{:<30} -- finished\".format(jobname)\n",
    "        else:\n",
    "            print \"{:<30} -- failed:\".format(asyncs[job].exception())\n",
    "    else:\n",
    "        print \"{:<30} -- still running\".format(jobname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting/analyzing results\n",
    "In this example we ran *bpp* under 10 different prior settings. We can compare the results of these analyses to investigate the effect of the prior on the estimated posterior distributions of the parameter estimates from the multi-species coalescent ($\\theta$ and $\\tau$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I'll leave that to you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what's a smart test to perform?\n",
    "Well, my interest in bpp was to perform species delimitation. And Rannala and Yang suggest that you try out both species delimitation algorithms and that you do so over a range of params for the two algorithms. They suggest that you run algorithm 0 with $\\epsilon$=(2, 5, 10, 20), and algorithm 1 with $\\alpha$=(1, 1.5, 2) and $m$=(1, 1.5, 2). And also to do this with different starting trees. So let's set up that test below for the example RAD data set from ipyrad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## set up a couple tests to perform\n",
    "DELIMIT_TESTS = [\n",
    "    (0, 2),\n",
    "    (0, 5),\n",
    "    (0, 10),\n",
    "    (1, 1.0, 1.0),\n",
    "    (1, 1.0, 1.5),\n",
    "    (1, 1.0, 2.0),\n",
    "    (1, 1.5, 1.0), \n",
    "    (1, 1.5, 1.5), \n",
    "    (1, 1.5, 2.0),\n",
    "    (1, 2.0, 1.0), \n",
    "    (1, 2.0, 1.5), \n",
    "    (1, 2.0, 2.0)\n",
    "]\n",
    "\n",
    "## Let's regroup the samples into more possible species\n",
    "IMAP = {\"A1\": [\"1A_0\", \"1B_0\", \"1C_0\"],\n",
    "        \"A2\": [\"1D_0\"], \n",
    "        \"B1\": [\"2E_0\", \"2F_0\"],\n",
    "        \"B2\": [\"2G_0\", \"2H_0\"],\n",
    "        \"C1\": [\"3I_0\", \"3J_0\", \"3K_0\", \"3L_0\"]\n",
    "       }\n",
    "\n",
    "\n",
    "## You can provide resolved and unresolved starting trees\n",
    "TREE_TESTS = [\n",
    "    \"(((A1,A2),(B1,B2)),C1);\"\n",
    "    \"((A1,A2),((B1,B2),C1));\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a dictionary to store our results in\n",
    "asyncs = {}\n",
    "\n",
    "## send jobs to run 'asynchronously', here we number the tests using 'enumerate'\n",
    "for tnum, tree in enumerate(TREE_TESTS):\n",
    "    for anum, alg in enumerate(DELIMIT_TESTS):\n",
    "        ## name this run by its theta and tau params\n",
    "        rname = 'TEST-{}-{}'.format(tnum, anum)\n",
    "\n",
    "        ## create input files for this run, the function returns the ctl\n",
    "        ## file name as a string, which we will store and use below\n",
    "        ctlfile = ipyrad.file_conversion.loci2bpp(rname, LOCI, IMAP, \n",
    "                                                  tree, \n",
    "                                                  infer_delimit=1, \n",
    "                                                  delimit_alg=alg,\n",
    "                                                  thetaprior=(2, 2000), \n",
    "                                                  tauprior=(2, 200, 1), \n",
    "                                                  nsample=10000, \n",
    "                                                  burnin=1000,\n",
    "                                                  maxloci=100)\n",
    "\n",
    "        ## submit job to the queue as args to run_bpp\n",
    "        asyncs[ctlfile] = lbview.apply(run_bpp, ctlfile)\n",
    "\n",
    "        ## print that the job was submitted\n",
    "        sys.stderr.write('job submitted: bpp {}\\n\\n'.format(ctlfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating trait data with iBPP\n",
    "Species delimitation can be further aided by trait information from the samples that are included in the study under a model of trait evolution as described by Solis-Lemus et al. (2015) in their software *ibpp*. This software was purposely made to be highly compatible with *bpp*, and so input files can be made using the same `loci2bpp` function. As usual, it is very important that these input files are created in exactly the correct way, and so we try to make that easy. \n",
    "\n",
    "To ensure that all of your input files are compatible, we remove individuals from the trait file that are not present in the IMAP dictionary. This allows you to easily remove taxa from an analysis to examine their influence. We will also mean-standardize the trait values and properly format missing data cells. Rather than use an input dictionary like we did above, here we will use a Pandas DataFrame, which is an easier way to work with data from a CSV file. You pass the DataFrame to `loci2bpp` and it will create a traits file for each named analysis. Although this creates some redundancy by making many files that may be the same, it is convenient for filtering taxa from one master trait list into a trait file that is correct for each given analysis. \n",
    "\n",
    "There are four requirements of the trait data when input to iBPP: (1) The first column should contain sample names and have \"Indiv\" as the header. (2) All trait values in the remaining columns should be quantitative. (3) Missing data should be listed as \"NA\" (we show below how to easily convert this from other values). (4) The data should be mean-standardized (we perform this for you in `loci2bpp`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in a CSV format trait file\n",
    "We use the `pandas.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t1    t2   t3\n",
      "Indiv                \n",
      "1A_0   3.0  40.1  0.9\n",
      "1B_0   3.0  38.8  1.0\n",
      "1C_0   4.0  35.4  1.2\n",
      "1D_0   4.0  37.0  1.0\n",
      "2E_0   5.0  33.0  0.7\n",
      "2F_0   5.0  32.4  0.7\n",
      "2G_0   NaN   NaN  0.5\n",
      "2H_0   NaN   NaN  0.5\n",
      "3I_0   8.0  65.0  0.6\n",
      "3J_0   8.0  67.4  0.4\n",
      "3K_0   8.0  68.2  0.3\n",
      "3L_0   9.0  59.9  0.3\n"
     ]
    }
   ],
   "source": [
    "## Here is example CSV data with missing data as \"\" or NA. \n",
    "## We're gonna make some small changes to it so it is compatible with ibpp\n",
    "CSV_DATA = \"\"\"\\\n",
    "Indiv, t1, t2, t3\n",
    "1A_0,3,40.1,0.9\n",
    "1B_0,3,38.8,1.0\n",
    "1C_0,4,35.4,1.2\n",
    "1D_0,4,37.0,1.0\n",
    "2E_0,5,33.0,0.7\n",
    "2F_0,5,32.4,0.7\n",
    "2G_0,,NA,0.5\n",
    "2H_0,,NA,0.5\n",
    "3I_0,8,65.0,0.6\n",
    "3J_0,8,67.4,0.4\n",
    "3K_0,8,68.2,0.3\n",
    "3L_0,9,59.9,0.3\n",
    "\"\"\"\n",
    "\n",
    "## For this example, I'll use the stringIO function to read the string data\n",
    "## above to act like it is a file. I'm doing this only for this tutorial. \n",
    "## For your data you could simply read in a saved CSV file from disk.\n",
    "import StringIO\n",
    "csv_file = StringIO.StringIO(CSV_DATA)\n",
    "\n",
    "## Load the csv_file using the pandas.read_csv() function, use the 'na_values=' \n",
    "## option to indicate missing data values that will be re-coded as NaN.\n",
    "import pandas\n",
    "traits = pandas.read_csv(csv_file, delimiter=\",\", na_values=[\"\", \"NA\"], index_col=0)\n",
    "\n",
    "## If your data are properly formatted they should like something like below.\n",
    "print traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `loci2bpp` going to do with the trait dataframe?\n",
    "We will filter it to remove sample that are not in IMAP, and we will mean-standardize the values in each column based on the samples that are present, then save it to a file. You can see this below, where the values are now scaled around 0, and NaN is converted to \"NA\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             t1        t2        t3\n",
      "Indiv                              \n",
      "1A_0   -1.16792 -0.497734  0.760639\n",
      "1B_0   -1.16792 -0.582649  1.098701\n",
      "1C_0  -0.735356 -0.804735  1.774824\n",
      "1D_0  -0.735356 -0.700224  1.098701\n",
      "2E_0  -0.302794 -0.961502  0.084515\n",
      "2F_0  -0.302794  -1.00069  0.084515\n",
      "2G_0         NA        NA -0.591608\n",
      "2H_0         NA        NA -0.591608\n",
      "3I_0   0.994893   1.12872 -0.253546\n",
      "3J_0   0.994893   1.28549 -0.929670\n",
      "3K_0   0.994893   1.33774 -1.267731\n",
      "3L_0    1.42746   0.79559 -1.267731\n"
     ]
    }
   ],
   "source": [
    "## mean standardize data in each column\n",
    "straits = traits.apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "## convert NaN (true missing) to NA strings, b/c that's what ibpp wants.\n",
    "ftraits = straits.fillna(\"NA\")\n",
    "\n",
    "## Now save as a new filename (TRAITFILE)\n",
    "ftraits.to_csv(\"./traits_standardized.csv\")\n",
    "\n",
    "## print mean standardized trait values for our records\n",
    "print ftraits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (1000 loci, 3 species, 12 samples)\n",
      "  delim_with_traits.ibpp.seq.txt\n",
      "  delim_with_traits.ibpp.imap.txt\n",
      "  delim_with_traits.ibpp.ctl.txt\n",
      "  delim_with_traits.ibpp.traits.txtnew files created (1000 loci, 3 species, 12 samples)\n",
      "  delim_no_traits.ibpp.seq.txt\n",
      "  delim_no_traits.ibpp.imap.txt\n",
      "  delim_no_traits.ibpp.ctl.txt\n",
      "  delim_no_traits.ibpp.traits.txtnew files created (1000 loci, 3 species, 12 samples)\n",
      "  delim_only_traits.ibpp.seq.txt\n",
      "  delim_only_traits.ibpp.imap.txt\n",
      "  delim_only_traits.ibpp.ctl.txt\n",
      "  delim_only_traits.ibpp.traits.txt"
     ]
    }
   ],
   "source": [
    "### Let's run species delimitation with traits\n",
    "ctl1 = ipyrad.file_conversion.loci2bpp(\"delim_with_traits\", LOCI, IMAP, TREE, \n",
    "                                       wdir=WDIR,\n",
    "                                       infer_delimit=1, \n",
    "                                       traits_df=traits,\n",
    "                                       useseqdata=1,\n",
    "                                       usetraitdata=1)\n",
    "\n",
    "### And compare it to when the traits are not used\n",
    "ctl2 = ipyrad.file_conversion.loci2bpp(\"delim_no_traits\", LOCI, IMAP, TREE, \n",
    "                                       wdir=WDIR,\n",
    "                                       infer_delimit=1,  \n",
    "                                       traits_df=traits,\n",
    "                                       useseqdata=1,\n",
    "                                       usetraitdata=0)\n",
    "\n",
    "### And compare it to when only traits are used\n",
    "ctl3 = ipyrad.file_conversion.loci2bpp(\"delim_only_traits\", LOCI, IMAP, TREE, \n",
    "                                       wdir=WDIR,\n",
    "                                       infer_delimit=1,  \n",
    "                                       traits_df=traits,\n",
    "                                       useseqdata=0,\n",
    "                                       usetraitdata=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
