{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Species-tree & species-delimitation using *bpp* (BP&P)\n",
    "The program *bpp* by Rannala & Yang (2010; 2015) is a powerful tool for inferring species tree parameters and testing species delimitation hypotheses. It is *relatively* easy to use, and best of all, it's *quite fast*, although not highly parallelizable. This notebook describes a streamlined approach we've developed to easily setup input files for testing different hypthotheses in *bpp*, and to do so in a clear programmatic way that makes it easy to perform many tests over many different parameter settings. We also show how to submit many separate jobs to run in parallel on a cluster. \n",
    "\n",
    "### Using Jupyter notebooks\n",
    "If you have not used Jupyter notebooks before, please see our other documentation for an introduction. The purpose of these notebooks is to create a reproducible document that is easy to share, reproduce, and/or use as supplemental materials, by simply uploading it to a site such as github. You can execute the code (in this case written in Python) in the cells below to reproduce our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Install required software\n",
    "All software required for this notebook can be installed using conda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## conda install -c ipyrad ipyrad\n",
    "## conda install -c ipyrad bpp\n",
    "## conda install -c etetoolkit ete3\n",
    "## pip install toyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipa 0.6.10\n",
      "ipp 6.0.2\n"
     ]
    }
   ],
   "source": [
    "import ipyrad.analysis as ipa         ## ipyrad analysis tools\n",
    "import ipyparallel as ipp             ## parallelization\n",
    "\n",
    "## print version\n",
    "print 'ipa', ipa.__version__\n",
    "print 'ipp', ipp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Connect to an ipyparallel cluster\n",
    "We will use the `ipyparallel` library to submit jobs to run in parallel on a cluster. We have a separate tutorial with more background about using ipyparallel. You will need to have an `ipcluster` instance running in a separate terminal on your machine (or ideally, it is running on your HPC cluster). The code below simply connects to that cluster and prints how many CPUs are available for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to 4 cores\n"
     ]
    }
   ],
   "source": [
    "## Connect to a running ipcluster instance and create load-balancer\n",
    "ipyclient = ipp.Client()\n",
    "\n",
    "## print information about our cluster\n",
    "print \"Connected to {} cores\".format(len(ipyclient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Enter paths and input files  (I/O) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## set the location of our input .loci file\n",
    "LOCIFILE = \"./branch-test/pedtest_outfiles/pedtest.loci\"\n",
    "\n",
    "## set the name of the output directory. It will be created if it doesn't exist.\n",
    "WORKDIR = \"./analysis-bpp\"\n",
    "\n",
    "## a tree hypothesis (guidetree) for our analyses (here based on tetrad results)\n",
    "NEWICK = \"((((sup, cya), cys), ((rex, rck), tha)), prz);\"\n",
    "\n",
    "## a dictionary mapping sample names to 'species' names\n",
    "IMAP = {\n",
    "    \"prz\": [\"32082_przewalskii\", \"33588_przewalskii\"], \n",
    "    \"sup\": [\"29154_superba\"],\n",
    "    \"cya\": [\"30686_cyathophylla\"],\n",
    "    \"cys\": [\"41478_cyathophylloides\", \"41954_cyathophylloides\"],\n",
    "    \"tha\": [\"33413_thamno\"], \n",
    "    \"rck\": [\"30556_thamno\", \"35236_rex\"],\n",
    "    \"rex\": [\"35236_rex\", \"35236_rex\", \"39618_rex\", \"38362_rex\"],  \n",
    "}\n",
    "\n",
    "MINMAP = {\n",
    "    \"prz\": 2, \n",
    "    \"sup\": 1,\n",
    "    \"cya\": 1,\n",
    "    \"cys\": 2,\n",
    "    \"tha\": 1, \n",
    "    \"rck\": 2,\n",
    "    \"rex\": 4,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   /-prz\n",
      "  |\n",
      "  |      /-cys\n",
      "--|   /-|\n",
      "  |  |  |   /-sup\n",
      "  |  |   \\-|\n",
      "   \\-|      \\-cya\n",
      "     |\n",
      "     |   /-tha\n",
      "      \\-|\n",
      "        |   /-rex\n",
      "         \\-|\n",
      "            \\-rck\n"
     ]
    }
   ],
   "source": [
    "## print tree \n",
    "tree = ipa.tree(NEWICK)\n",
    "print tree.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create an `ipa.bpp()` object\n",
    "\n",
    "Running *bpp* requires three input files (.ctl, .imap, and .seq) of which the .ctl file is the most important, since it contains the parameters for the run and points to the location of the other two files. Consequently, if we plan to run analyses under a range of parameter settings and to run multiple replicates this ends up requiring that you create dozens of input files, which if done by hand is a huge pain in the butt. Thus, we have created a convenience function for creating these input files, and, if so desired, to submit them to run in parallel on a cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create a bpp analysis object with the required args passed to it.\n",
    "bppo = ipa.bpp(locifile=LOCIFILE, \n",
    "               guidetree=NEWICK,\n",
    "               imap=IMAP,\n",
    "               workdir=WORKDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxloci   500                 \n",
      "minmap    {'cys': 2, 'rex': 4, 'sup': 1, 'cya': 1, 'rck': 2, 'tha': 1, 'prz': 2}\n",
      "minsnps   2                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## set filtering parameters\n",
    "bppo.filters.maxloci = 500\n",
    "bppo.filters.minsnps = 2\n",
    "bppo.filters.minmap = MINMAP\n",
    "print bppo.filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burnin          2500                \n",
      "cleandata       0                   \n",
      "delimit_alg     (0, 5)              \n",
      "finetune        (0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01)\n",
      "infer_delimit   0                   \n",
      "infer_sptree    0                   \n",
      "nsample         25000               \n",
      "sampfreq        10                  \n",
      "seed            12345               \n",
      "tauprior        (2, 2000, 1)        \n",
      "thetaprior      (2, 2000)           \n",
      "usedata         1                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## set bpp run parameters (~6 hours)\n",
    "bppo.params.burnin = 2500\n",
    "bppo.params.nsample = 25000\n",
    "bppo.params.sampfreq = 10\n",
    "bppo.params.tauprior = (2, 2000, 1)\n",
    "bppo.params.thetaprior = (2, 2000)\n",
    "print bppo.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Option 1: simply write the bpp files\n",
    "You can simply write the bpp files using the `write_bpp_files()` function and then execute them yourself by calling the `bpp` executable on the .ctl file. If you do it this way, it is up to you to parallelize the code yourself. Try running this first and take a look at the files that were produced in your working directory (`bpp-00.ctl.txt`, `tmp.seqfile.txt`, and `tmp.imapfile.txt`). You can change the settings above and look at their effect on these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## we'll name this test 'bpp-00'\n",
    "bppo.write_bpp_files(\"test-00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Option 2: Submit many jobs to run in parallel\n",
    "Or, we have a function called `submit_bpp_jobs()` which can be used to submit a number of replicate jobs to run on a load-balanced job scheduler by passing it an `ipyparallel` client object. If submitting multiple replicates each will start from a different random seed, but you can still set the initial seed to make the runs reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted 1 bpp jobs [test-00] (500 loci)\n"
     ]
    }
   ],
   "source": [
    "## submit many reps of the same job\n",
    "bppo.submit_bpp_jobs(prefix=\"test-00\", \n",
    "                     nreps=10, \n",
    "                     seed=98765, \n",
    "                     ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Similarly, you can submit many jobs with different params using a for-loop. If you do this, remember to assign a new name to each job so that it writes the output to differently named files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted 1 bpp jobs [tbpp-00-tau-2] (500 loci)\n",
      "submitted 1 bpp jobs [tbpp-00-tau-20] (500 loci)\n",
      "submitted 1 bpp jobs [tbpp-00-tau-200] (500 loci)\n"
     ]
    }
   ],
   "source": [
    "## or, submit many jobs with different params using a for-loop\n",
    "for tauprior in [2, 20, 200]:\n",
    "    bppo.params.tauprior = (2, tauprior, 1)\n",
    "    bppo.submit_bpp_jobs(prefix=\"tbpp-00-tau-{}\".format(tauprior),\n",
    "                         nreps=1, \n",
    "                         seed=123, \n",
    "                         ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You should also always run at least one job with the `usedata=0` option turned on. This will give you results that are dictated entirely by the prior settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted 1 bpp jobs [prior] (500 loci)\n"
     ]
    }
   ],
   "source": [
    "## again, remember to set a different name for the job.\n",
    "bppo.params.usedata = 0\n",
    "bppo.submit_bpp_jobs(prefix=\"prior\", \n",
    "                     nreps=1, \n",
    "                     seed=123,\n",
    "                     ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### wait for parallel jobs to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4/4 tasks finished after 22109 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## block until all jobs are finished\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Running other algorithms (species tree inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "burnin          10000               \n",
       "cleandata       0                   \n",
       "delimit_alg     (0, 5)              \n",
       "finetune        (0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01)\n",
       "infer_delimit   0                   \n",
       "infer_sptree    1                   \n",
       "nsample         100000              \n",
       "sampfreq        10                  \n",
       "seed            12345               \n",
       "tauprior        (4, 2, 1)           \n",
       "thetaprior      (5, 5)              \n",
       "usedata         1                   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a separate new bpp object\n",
    "bp01 = ipa.bpp(locifile=LOCIFILE, \n",
    "               guidetree=NEWICK, \n",
    "               imap=IMAP)\n",
    "\n",
    "## set limits on data size\n",
    "bp01.filters.minmap = MINMAP\n",
    "bp01.filters.maxloci = 500\n",
    "bp01.filters.minsnps = 2\n",
    "\n",
    "## set bpp run params\n",
    "bp01.usedata = 1\n",
    "bp01.params.burnin = 10000\n",
    "bp01.params.nsample = 100000\n",
    "bp01.params.sampfreq = 10\n",
    "bp01.params.infer_sptree = 1\n",
    "\n",
    "## print it\n",
    "bp01.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted 1 bpp jobs [bp-01] (500 loci)\n",
      "submitted 1 bpp jobs [bp-01-prior] (500 loci)\n"
     ]
    }
   ],
   "source": [
    "## submit jobs\n",
    "bp01.submit_bpp_jobs(\"bp-01\", \n",
    "                     nreps=1,\n",
    "                     seed=123,\n",
    "                     ipyclient=ipyclient)\n",
    "\n",
    "## and submit a job w/o data.\n",
    "bp01.usedata = 0\n",
    "bp01.submit_bpp_jobs(\"bp-01-prior\", \n",
    "                     nreps=1, \n",
    "                     seed=123, \n",
    "                     ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### So what's a smart test to perform?\n",
    "Well, my interest in bpp was to perform species delimitation. And Rannala and Yang suggest that you try out both species delimitation algorithms and that you do so over a range of params for the two algorithms. They suggest that you run algorithm 0 with $\\epsilon$=(2, 5, 10, 20), and algorithm 1 with $\\alpha$=(1, 1.5, 2) and $m$=(1, 1.5, 2). And also to do this with different starting trees. See if you can set up an efficient for-loop to submit tests over a range of prior settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## set up a couple tests to perform\n",
    "## delimit arg is a tuple with (algorithm, param) or (alg, param, param)\n",
    "DELIMIT_TESTS = [\n",
    "    (0, 2),\n",
    "    (0, 5),\n",
    "    (0, 10),\n",
    "    (1, 1.0, 1.0),\n",
    "    (1, 1.0, 1.5),\n",
    "    (1, 1.0, 2.0),\n",
    "    (1, 1.5, 1.0), \n",
    "    (1, 1.5, 1.5), \n",
    "    (1, 1.5, 2.0),\n",
    "    (1, 2.0, 1.0), \n",
    "    (1, 2.0, 1.5), \n",
    "    (1, 2.0, 2.0)\n",
    "]\n",
    "\n",
    "bppo.usedata = 1\n",
    "\n",
    "for test in DELIMIT_TESTS:\n",
    "    bppo.params.delimit_alg = test\n",
    "    prefix = \"delim-\" + \"-\".join([str(i) for i in test])\n",
    "    bppo.submit_bpp_jobs(prefix=prefix, \n",
    "                         nreps=1, \n",
    "                         seed=123, \n",
    "                         ipyclient=ipyclient)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
